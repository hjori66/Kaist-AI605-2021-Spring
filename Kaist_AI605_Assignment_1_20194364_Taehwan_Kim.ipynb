{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaist AI605 Assignment 1_20194364 Taehwan Kim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjori66/Kaist-AI605-2021-Spring/blob/main/Kaist_AI605_Assignment_1_20194364_Taehwan_Kim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbGnNWI1lRy_"
      },
      "source": [
        "# KAIST AI605 Assignment 1: Text Classification with RNNs\n",
        "Authors: Hyeong-Gwon Hong (honggudrnjs@kaist.ac.kr) and Minjoon Seo (minjoon@kaist.ac.kr)\n",
        "\n",
        "**Due Date:** March 31 (Wed) 11:00pm, 2021\n",
        "\n",
        "## Assignment Objectives\n",
        "- Verify theoretically and empirically why gating mechanism (LSTM, GRU) helps in Recurrent Neural Networks (RNNs)\n",
        "- Design an LSTM-based text classification model from scratch using PyTorch.\n",
        "- Apply the classification model to a popular classification task, Stanford Sentiment Treebank v2 (SST-2).\n",
        "- Achieve higher accuracy by applying common machine learning strategies, including Dropout.\n",
        "- Utilize pretrained word embedding (e.g. GloVe) to leverage self-supervision over a large text corpus.\n",
        "- (Bonus) Use Hugging Face library (`transformers`) to leverage self-supervision via large language models.\n",
        "\n",
        "## Your Submission\n",
        "Your submission will be a link to a Colab notebook that has all written answers and is fully executable. You will submtit your assignment via KLMS. Use in-line LaTeX (see below) for mathematical expressions. Collaboration among students is allowed but it is not a group assignment so make sure your answer and code are your own. Make sure to mention your collaborators in yoru assignment with their names and their student ids.\n",
        "\n",
        "## Grading\n",
        "The entire assignment is out of 100 points. There are four bonus questions with 10 points each (two bonus questions added on Mar 19). Your final score can be higher than 100 points.\n",
        "\n",
        "\n",
        "## Environment\n",
        "You will only use Python 3.7 and PyTorch 1.8, which is already available on Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYxEp1XMpxem",
        "outputId": "23b41c0d-7c9e-4239-9f64-93dcb5bbd4ce"
      },
      "source": [
        "from platform import python_version\n",
        "import torch\n",
        "\n",
        "print(\"python\", python_version())\n",
        "print(\"torch\", torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python 3.7.10\n",
            "torch 1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB7xyzIgnnkA"
      },
      "source": [
        "## 1. Limitations of Vanilla RNNs\n",
        "In Lecture 04 and 05, we saw how RNNs suffer from exploding or vanishing gradients. We mathematically showed that, if the recurrent relation is\n",
        "$$ \\textbf{h}_t = \\sigma (\\textbf{V}\\textbf{h}_{t-1} + \\textbf{U}\\textbf{x}_t + \\textbf{b}) $$\n",
        "then\n",
        "$$ \\frac{\\partial \\textbf{h}_t}{\\partial \\textbf{h}_{t-1}} = \\text{diag}(\\sigma' (\\textbf{V}\\textbf{h}_{t-1} + \\textbf{U}\\textbf{x}_t + \\textbf{b}))\\textbf{V}$$\n",
        "so\n",
        "$$\\frac{\\partial \\textbf{h}_T}{\\partial \\textbf{h}_1} \\propto \\textbf{V}^{T-1}$$\n",
        "which means this term will be very close to zero if the norm of $\\bf{V}$ is smaller than 1 and really big otherwise.\n",
        "\n",
        "**Problem 1.1** *(10 points)* Explain how exploding gradient can be mitigated if we use gradient clipping.\n",
        "\n",
        "**Answer 1.1** \\\\\n",
        "\n",
        "The definition of the gradient clipping is followed.\n",
        "\n",
        "$$ \\begin{aligned}\n",
        "\\frac{\\partial \\textbf{h}}{\\partial \\theta} \\leftarrow &\\left\\{\\begin{array}{ll}\n",
        "\\frac{\\text { threshold }}{\\|\\hat{g}\\|} \\hat{g} & \\text { if }\\|\\hat{g}\\| \\geq \\text { threshold }\n",
        "\\\\\n",
        "\\hat{g} & \\text { otherwise }\n",
        "\\end{array}\\right\n",
        ".\\\\\n",
        "& \\text { where } \\hat{g}=\\frac{\\partial \\textbf{h}}{\\partial \\theta}\n",
        "\\end{aligned} $$\n",
        "\n",
        "If the gradient exploded, weights of the model can be NaN value (either overflow or underflow). So, rescaling the error derivative before propagating it backward through the network to update the weights can be one of the solution. If we do that, we can decrease the likelihood of an over or underflow.\n",
        "\n",
        "\n",
        "**Problem 1.2** *(10 points)* Explain how vanishing gradient can be mitigated if we use LSTM. See the Lecture 04 and 05 slides for the definition of LSTM.\n",
        "\n",
        "**Answer 1.2** \\\\\n",
        "\n",
        "The formulation of LSTM is followed.\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "f_{t} &=\\sigma_{g}\\left(W_{f} x_{t}+U_{f} h_{t-1}+b_{f}\\right) \\\\\n",
        "i_{t} &=\\sigma_{g}\\left(W_{i} x_{t}+U_{i} h_{t-1}+b_{i}\\right) \\\\\n",
        "o_{t} &=\\sigma_{g}\\left(W_{o} x_{t}+U_{o} h_{t-1}+b_{o}\\right) \\\\\n",
        "\\tilde{c}_{t} &=\\sigma_{c}\\left(W_{c} x_{t}+U_{c} h_{t-1}+b_{c}\\right) \\\\\n",
        "c_{t} &=f_{t} \\circ c_{t-1}+i_{t} \\circ \\tilde{c}_{t} \\\\\n",
        "h_{t} &=o_{t} \\circ \\sigma_{h}\\left(c_{t}\\right)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Then,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial c_{T}}{\\partial c_{t}}=\n",
        "\\frac{\\partial c_{T}}{\\partial c_{T-1}} * \n",
        "\\frac{\\partial c_{T-1}}{\\partial c_{T-2}} * \n",
        "\\ldots * \n",
        "\\frac{\\partial c_{t+1}}{\\partial c_{t}}\n",
        "$$\n",
        "and\n",
        "$$\n",
        "\\frac{\\partial c_{T}}{\\partial c_{t}}=\\prod_{i=t+1}^{T} f_{i}\n",
        "$$\n",
        "\n",
        "Now, $f_{i}$ is sigmoid function. so, it is larger than 0 and \"smaller than 1\". If $f_{i}$ was closed to 1, cell state ($c_{i}$) considers the long term memory. Otherwise, it doesn't consider the long term memory. This formulation mitigates the vanishing gradient. \n",
        "\n",
        "Similary, \n",
        "$$\n",
        "\\frac{\\partial c_{T}}{\\partial \\tilde{c}_{t}}=\\prod_{j=t+1}^{T} i_{j} \\text { and } \\frac{\\partial h_{T}}{\\partial h_{t}}\n",
        "$$\n",
        "mitigates the vanishing, too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0AmoAT3wA1J"
      },
      "source": [
        "## 2. Creating Vocabulary from Training Data\n",
        "Creating the vocabulary is the first step for every natural language processing model. In this section, you will use Stanford Sentiment Treebank v2, a popular dataset for sentiment classification, to create your vocabulary.\n",
        "\n",
        "### Obtaining SST-2 via GLUE\n",
        "General Language Understanding Evaluation (GLUE) benchmark is a collection of tools for evaluating the performance of models across a diverse set of existing natural language understanding (NLU) tasks. See GLUE website (https://gluebenchmark.com/) and the GLUE paper (https://openreview.net/pdf?id=rJ4km2R5t7) for more details. GLUE provides an easy way to access the datasets, including SST-2.\n",
        "You can download SST-2 dataset by following the steps below:\n",
        "\n",
        "1. Clone GitHub repository:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK0S_VTJxds4",
        "outputId": "8772526a-67fb-4183-a176-f0b91e7df104"
      },
      "source": [
        "!git clone https://github.com/nyu-mll/GLUE-baselines.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GLUE-baselines'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 891 (delta 1), reused 2 (delta 0), pack-reused 886\u001b[K\n",
            "Receiving objects: 100% (891/891), 1.48 MiB | 4.76 MiB/s, done.\n",
            "Resolving deltas: 100% (610/610), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8eWbt2yxb3H"
      },
      "source": [
        "2. Download SST-2 only:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6drFIvgxxjgI",
        "outputId": "df407fef-dabc-4938-9602-783b963d3fbc"
      },
      "source": [
        "%cd GLUE-baselines/\n",
        "!python download_glue_data.py --data_dir glue_data --tasks SST"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GLUE-baselines\n",
            "Downloading and extracting SST...\n",
            "\tCompleted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAVQyYWkxib6"
      },
      "source": [
        "Your training, dev, and test data can be found at `glue_data/SST-2`. Note that each file is in a tsv format, where the first column is the sentence and the second column is the label (either 0 or 1, where 1 means positive sentiment). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElsgL-Piz7ck",
        "outputId": "dddda72b-99fd-4110-d95b-4cad016961c6"
      },
      "source": [
        "!head -10 glue_data/SST-2/train.tsv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence\tlabel\n",
            "hide new secretions from the parental units \t0\n",
            "contains no wit , only labored gags \t0\n",
            "that loves its characters and communicates something rather beautiful about human nature \t1\n",
            "remains utterly satisfied to remain the same throughout \t0\n",
            "on the worst revenge-of-the-nerds clich√©s the filmmakers could dredge up \t0\n",
            "that 's far too tragic to merit such superficial treatment \t0\n",
            "demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . \t1\n",
            "of saucy \t1\n",
            "a depressed fifteen-year-old 's suicidal poetry \t0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s0T6qk6x78s"
      },
      "source": [
        "**Problem 2.1** *(10 points)* Using space tokenizer, create the vocabulary for the training data and report the vocabulary size here. Make sure that you add an `UNK` token to the vocabulary to account for words (during inference time) that you haven't seen. See below for an example with a short text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOsxkEpyxTW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194c9ec3-d880-4351-a630-f663de45441d"
      },
      "source": [
        "# Space tokenization\n",
        "text = \"Hello world!\"\n",
        "tokens = text.split(' ')\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hello', 'world!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "_iCTn95_pK7i",
        "outputId": "7b0300f8-b4bc-4dc2-84b4-51defbc567ad"
      },
      "source": [
        "# Constructing vocabulary with `UNK`\n",
        "vocab = ['UNK'] + list(set(text.split(' ')))\n",
        "word2id = {word: id_ for id_, word in enumerate(vocab)}\n",
        "print(vocab)\n",
        "print(word2id['Hello'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7c9b9c5cd151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Constructing vocabulary with `UNK`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'UNK'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mword2id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mid_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hello'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "If7O5GZ3S6Nc"
      },
      "source": [
        "**Answer 2.1** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsfTJ1_XFDxR",
        "outputId": "a2d33145-9d7b-4435-909f-3cf28f887f10"
      },
      "source": [
        "# Constructing vocabulary using space tokenizer and 'UNK'\n",
        "import pandas as pd\n",
        "\n",
        "def make_vocab(fname):\n",
        "    df = pd.read_csv(fname, sep='\\t')\n",
        "    tokens = list()\n",
        "    token_occur = dict()\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        for token in row['sentence'].strip().split(' '):\n",
        "            if token in token_occur:\n",
        "                token_occur[token] += 1\n",
        "            else:\n",
        "                token_occur[token] = 1\n",
        "                tokens.append(token)\n",
        "\n",
        "    vocab = ['UNK'] + tokens\n",
        "    return vocab\n",
        "\n",
        "vocab = make_vocab('glue_data/SST-2/train.tsv')\n",
        "print(\"The size of the vocabulary is \", len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the vocabulary is  14817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqVv57zy1OZ0"
      },
      "source": [
        "**Problem 2.2** *(10 points)* Using all words in the training data will make the vocabulary very big. Reduce its size by only including words that occur at least 2 times. How does the size of the vocabulary change?\n",
        "\n",
        "**Answer 2.2** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq1GvSHXJGEF",
        "outputId": "c78f78ed-2373-4708-ace8-dffe5b8af686"
      },
      "source": [
        "# Constructing reduced vocabulary (occur at least twice)\n",
        "import pandas as pd\n",
        "\n",
        "def make_reduced_vocab(fname, min_occur=0):\n",
        "    df = pd.read_csv(fname, sep='\\t')\n",
        "    # tokens = list()\n",
        "    token_occur = dict()\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        for token in row['sentence'].strip().split(' '):\n",
        "            if token in token_occur:\n",
        "                token_occur[token] += 1\n",
        "            else:\n",
        "                token_occur[token] = 1\n",
        "                # tokens.append(token)\n",
        "\n",
        "    vocab = ['UNK', 'PAD']\n",
        "    for token, occur in token_occur.items():\n",
        "        if occur >= min_occur:\n",
        "            vocab.append(token)\n",
        "    word2id = {word: id_ for id_, word in enumerate(vocab)}\n",
        "    return vocab, word2id\n",
        "\n",
        "train_fname = 'glue_data/SST-2/train.tsv'\n",
        "dev_fname = 'glue_data/SST-2/dev.tsv'\n",
        "vocab, word2id = make_reduced_vocab(train_fname)\n",
        "reduced_vocab, word2id = make_reduced_vocab(train_fname, min_occur=2)\n",
        "print(len(vocab))\n",
        "print(len(reduced_vocab))\n",
        "print(\"The size of the vocabulary change is \", len(vocab) - len(reduced_vocab))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14818\n",
            "14311\n",
            "The size of the vocabulary change is  507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDQbmM3W2Im3"
      },
      "source": [
        "## 3. Text Classification Baselines\n",
        "\n",
        "You can now use the vocabulary constructed from the training data to create an embedding matrix. You will use the embedding matrix to map each input sequence of tokens to a list of embedding vectors. One of the simplest baseline is to go through one layer of neural network and then average the outputs, and finally classify the average embedding: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFIAvGS5pQXC",
        "outputId": "398454bb-b1a8-4e60-f84a-14c5fe936a82"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "input_ = \"hi world!\"\n",
        "input_tokens = input_.split(' ')\n",
        "input_ids = [word2id[word] if word in word2id else 0 for word in input_tokens]\n",
        "input_tensor = torch.LongTensor([input_ids]) # the first dimension is minibatch size\n",
        "print(input_tensor)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vUmITCFqMit",
        "outputId": "d248838a-5903-41c0-9d54-b7b3b7749877"
      },
      "source": [
        "# One layer, average pooling and classification\n",
        "class Baseline(nn.Module):\n",
        "  def __init__(self, d):\n",
        "    super(Baseline, self).__init__()\n",
        "    self.embedding = nn.Embedding(len(vocab), d)\n",
        "    self.layer = nn.Linear(d, d, bias=True)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.class_layer = nn.Linear(d, 2, bias=True)\n",
        "\n",
        "  def forward(self, input_tensor):\n",
        "    emb = self.embedding(input_tensor)\n",
        "    out = self.relu(self.layer(emb))\n",
        "    avg = out.mean(1)\n",
        "    logits = self.class_layer(avg)\n",
        "    return logits\n",
        "\n",
        "d = 3 # usually bigger, e.g. 128\n",
        "baseline = Baseline(d)\n",
        "logits = baseline(input_tensor)\n",
        "softmax = nn.Softmax(1)\n",
        "print(softmax(logits)) # probability for each class"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4660, 0.5340]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9UuMWCG9YNs"
      },
      "source": [
        "Now we will compute the loss, which is the negative log probability of the input text's label being the target label (`1`), which in fact turns out to be equivalent to the cross entropy (https://en.wikipedia.org/wiki/Cross_entropy) between the probability distribution and a one-hot distribution of the target label (note that we use `logits` instead of `softmax(logits)` as the input to the cross entropy, which allow us to avoid numerical instability). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nxgYNzQqaPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11810301-3af9-468e-9fd7-8d1be309e3ee"
      },
      "source": [
        "cel = nn.CrossEntropyLoss()\n",
        "label = torch.LongTensor([1]) # The ground truth label for \"hi world!\" is positive.\n",
        "loss = cel(logits, label) # Loss, a.k.a L\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.7606, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKR99jZ2-wZW"
      },
      "source": [
        "Once we have the loss defined, only one step remains! We compute the gradients of parameters with respective to the loss and update. Fortunately, PyTorch does this for us in a very convenient way. Note that we used only one example to update the model, which is basically a Stochastic Gradient Descent (SGD) with minibatch size of 1. A recommended minibatch size in this exercise is at least 16. It is also recommended that you reuse your training data at least 10 times (i.e. 10 *epochs*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8JjhgQ071d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "54601585-d99e-4b95-970e-fa4477cd8f24"
      },
      "source": [
        "optimizer = torch.optim.SGD(baseline.parameters(), lr=0.1)\n",
        "optimizer.zero_grad() # reset process\n",
        "loss.backward() # compute gradients\n",
        "optimizer.step() # update parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c7eefcc7af90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reset process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8M0fhFf_LbG"
      },
      "source": [
        "Once you have done this, all weight parameters will have `grad` attributes that contain their gradients with respect to the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpwOavsD8mpn",
        "outputId": "2abb5256-5965-4ec5-a026-06fa5aa13178"
      },
      "source": [
        "print(baseline.layer.weight.grad) # dL/dw of weights in the linear layer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RZMjI5HOEqg"
      },
      "source": [
        "**Problem 3.1** *(10 points)* Properly train this average-pooling baseline model on SST-2 and report the model's accuracy on the dev data.\n",
        "\n",
        "**Answer 3.1** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss89gtyFwFPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad191d7-0b4d-44af-9f27-6fba98451ddf"
      },
      "source": [
        "# Constructing the dataset\n",
        "import random\n",
        "\n",
        "vocab, word2id = make_reduced_vocab(train_fname, min_occur=2)\n",
        "vocab_size = len(vocab)\n",
        "batch_size = 128\n",
        "shuffle = False\n",
        "\n",
        "UNK_TOKEN = 0\n",
        "\n",
        "def unk_preprocessing(word, word2id_):\n",
        "    # one_hot = torch.zeros(len(word2id_))\n",
        "    if word in word2id_:\n",
        "        index = word2id_[word]\n",
        "    else:\n",
        "        index = UNK_TOKEN\n",
        "    # one_hot[index]=1.\n",
        "    return index\n",
        "    # return one_hot\n",
        "\n",
        "def seq2id(seq, word2id_):\n",
        "    sentence = seq.strip().split(' ')\n",
        "    source = [unk_preprocessing(word, word2id_) for word in sentence]\n",
        "    return source\n",
        "\n",
        "train_df = pd.read_csv(train_fname, sep='\\t')\n",
        "train_src = [seq2id(seq, word2id) for seq in train_df['sentence'].tolist()]\n",
        "train_tgt = train_df['label'].tolist()\n",
        "\n",
        "dev_df = pd.read_csv(dev_fname, sep='\\t')\n",
        "dev_src = [seq2id(seq, word2id) for seq in dev_df['sentence'].tolist()]\n",
        "dev_tgt = dev_df['label'].tolist()\n",
        "\n",
        "\n",
        "# for sentence in dev_src:\n",
        "#     print(sentence.count(0))\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, src, tgt, batch_size, pad_idx, shuffle=False):\n",
        "        assert len(src) == len(tgt)\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "        self.size = len(src)\n",
        "        self.batch_size = batch_size\n",
        "        self.pad_idx = pad_idx\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.index = 0\n",
        "        if self.shuffle:\n",
        "            index = list(range(self.size))\n",
        "            random.shuffle(index)\n",
        "\n",
        "            shuffle_src = list()\n",
        "            shuffle_tgt = list()\n",
        "\n",
        "            for i in index:\n",
        "                shuffle_src.append(self.src[i])\n",
        "                shuffle_tgt.append(self.tgt[i])\n",
        "\n",
        "            self.src = shuffle_src\n",
        "            self.tgt = shuffle_tgt\n",
        "\n",
        "        return self\n",
        "\n",
        "    def pad(self, batch):\n",
        "        max_len = 0\n",
        "        for seq in batch:\n",
        "            if max_len < len(seq):\n",
        "                max_len = len(seq)\n",
        "\n",
        "        for i, seq in enumerate(batch):\n",
        "            if max_len > len(seq):\n",
        "                batch[i] += [self.pad_idx] * (max_len - len(seq))\n",
        "        seq_lens = torch.LongTensor([(batch[i] + [self.pad_idx]).index(self.pad_idx) for i in range(len(batch))])\n",
        "\n",
        "        return batch, seq_lens\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.batch_size * self.index >= self.size:\n",
        "            raise StopIteration\n",
        "\n",
        "        src_batch = self.src[self.batch_size * self.index : self.batch_size * (self.index+1)]\n",
        "        tgt_batch = self.tgt[self.batch_size * self.index : self.batch_size * (self.index+1)]\n",
        "\n",
        "        padded_src_batch, src_seq_lens = self.pad(src_batch)\n",
        "\n",
        "        self.index += 1\n",
        "\n",
        "        return padded_src_batch, src_seq_lens, tgt_batch\n",
        "\n",
        "train_data_loader = DataLoader(train_src, train_tgt, batch_size=batch_size, pad_idx=1, shuffle=shuffle)\n",
        "dev_data_loader = DataLoader(dev_src, dev_tgt, batch_size=batch_size, pad_idx=1, shuffle=shuffle)\n",
        "\n",
        "print(len(train_src))\n",
        "print(len(dev_src))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67349\n",
            "872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2yaWThpgpWJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "5b9a0ea3-9c5f-4f58-f010-fa76893e0f4c"
      },
      "source": [
        "# Training the baseline model on SST-2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "d = 128 # usually bigger, e.g. 128\n",
        "baseline = Baseline(d).to(device)\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(baseline.parameters(), lr=0.1)\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0.0\n",
        "    train_data_num = 0\n",
        "    for i, (source, src_seq_lens, target) in enumerate(train_data_loader):\n",
        "        train_tensor_src = torch.LongTensor(source).to(device)\n",
        "        train_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "        logits = baseline(train_tensor_src)\n",
        "\n",
        "        optimizer.zero_grad() # reset process\n",
        "        loss = cel(logits, train_tensor_tgt) # Loss, a.k.a L\n",
        "        loss.backward() # compute gradients\n",
        "        optimizer.step() # update parameters\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, train_preds = torch.max(logits, 1)\n",
        "        train_accuracy += (train_preds == train_tensor_tgt).sum().float()\n",
        "\n",
        "        train_data_num += train_tensor_tgt.shape[0]\n",
        "\n",
        "    print('train:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(train_loss / train_data_num), \n",
        "                'acc =', '{:.6f}'.format(train_accuracy / train_data_num))\n",
        "    \n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0\n",
        "            valid_accuracy = 0.0\n",
        "            valid_data_num = 0\n",
        "            for i, (source, src_seq_lens, target) in enumerate(dev_data_loader):\n",
        "                dev_tensor_src = torch.LongTensor(source).to(device)\n",
        "                dev_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "                logits = baseline(dev_tensor_src)\n",
        "                loss = cel(logits, dev_tensor_tgt) # Loss, a.k.a L\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                _, valid_preds = torch.max(logits, 1)\n",
        "                valid_accuracy += (valid_preds == dev_tensor_tgt).sum().float()\n",
        "\n",
        "                valid_data_num += dev_tensor_tgt.shape[0]\n",
        "                \n",
        "            print('valid:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(valid_loss / valid_data_num), \n",
        "                'acc =', '{:.6f}'.format(valid_accuracy / valid_data_num))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:: Epoch: 0001 cost = 0.005359, acc = 0.558910\n",
            "valid:: Epoch: 0001 cost = 0.005538, acc = 0.527523\n",
            "train:: Epoch: 0002 cost = 0.005306, acc = 0.573743\n",
            "valid:: Epoch: 0002 cost = 0.005425, acc = 0.567661\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a367a302d269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtrain_tensor_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_tensor_tgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tensor_src\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reset process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-5260faefc50d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neN_jLl2XOJO"
      },
      "source": [
        "I used d = 128, batch_size = 128, epoch = 100, for the baseline. The result is followed.\n",
        "\n",
        "After 30 Iteration, It converges. (Validation Loss begins to increase)\n",
        "train:: Epoch: 0030 cost = 0.003190 ,acc = 0.823991\n",
        "valid:: Epoch: 0030 cost = 0.003767 ,acc = 0.770642"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejqZv3GNOHPl"
      },
      "source": [
        "**Problem 3.2** *(10 points)* Implement a recurrent neural network (without using PyTorch's RNN module) where the output of the linear layer not only depends on the current input but also the previous output. Report the model's accuracy on the dev data. Is it better or worse than the baseline? Why?\n",
        "\n",
        "**Answer 3.2** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr18IO7s6XS8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "41121fd7-b690-4ca7-979e-60a3a08a8249"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# One RNN layer and classification\n",
        "class RNNNode(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(RNNNode, self).__init__()\n",
        "\n",
        "        self.W_h2h = torch.nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.W_h2y = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "    \n",
        "    def forward(self, input, hidden, src_batch_sizes):\n",
        "        h_t = hidden.squeeze(0)\n",
        "        h_last = h_t\n",
        "        y_list = list()\n",
        "        batch_size = int(src_batch_sizes[0])\n",
        "        for i, batch in enumerate(src_batch_sizes):\n",
        "            batch = int(batch)\n",
        "            token = input[i][:batch, :]\n",
        "            combined_input = torch.cat([token, h_t[:batch, :]], dim=1)\n",
        "            h_last[:batch, :] = h_t = self.tanh(self.W_h2h(combined_input))\n",
        "            y_t = self.W_h2y(h_t)\n",
        "            y_list.append(nn.ZeroPad2d((0, 0, batch_size - batch, 0))(y_t)) # Zero-padding\n",
        "        y = torch.stack(y_list, dim=0) # \n",
        "        return y, h_last.unsqueeze(0)\n",
        "\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, n_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim, padding_idx=1)\n",
        "\n",
        "        # nn.RNN\n",
        "        # self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers)\n",
        "\n",
        "        # my RNN\n",
        "        self.rnn = RNNNode(input_size=embedding_dim, hidden_size=hidden_dim)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * n_layers, 2)\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "\n",
        "    def forward(self, input_tensor, src_seq_lens, hidden):\n",
        "        emb = self.embedding(input_tensor) # emb.shape = batch * len * hidden\n",
        "        emb = emb.transpose(0, 1) # emb.shape = len * batch * hidden\n",
        "\n",
        "        # nn.RNN\n",
        "        # packed = pack_padded_sequence(emb, src_seq_lens.tolist(), batch_first=False)\n",
        "        # outs, hidden = self.rnn(packed, hidden) # h0 = zero initialization\n",
        "        # outs, out_lens = pad_packed_sequence(outs, batch_first=False)\n",
        "\n",
        "        # my RNN\n",
        "        # print(\"input shape : \", emb.shape, hidden.shape) # len * batch * emb, 1 * batch * hidden\n",
        "        src_batch_sizes = seqs2batches(src_seq_lens)\n",
        "        outs, hidden = self.rnn(emb, hidden, src_batch_sizes) # h0 = zero initialization\n",
        "        # print(\"output shape : \", outs.shape, hidden.shape) # len * batch * hidden, 1 * batch * hidden\n",
        "\n",
        "        hidden = hidden.transpose(0, 1)\n",
        "        hidden = hidden.contiguous().view(hidden.shape[0], -1)\n",
        "        logits = self.fc(hidden)\n",
        "        # logits = self.fc(outs[-1])\n",
        "        return logits\n",
        "\n",
        "\n",
        "def seqs2batches(src_seq_lens):\n",
        "    \"\"\"\n",
        "    This is same with batches2seqs() \n",
        "    \"\"\"\n",
        "    assert src_seq_lens is not None\n",
        "    assert src_seq_lens[-1] > 0\n",
        "    src_batch_sizes = torch.zeros(int(src_seq_lens[0]))\n",
        "    pointer = int(src_seq_lens[0]) - 1\n",
        "    for i, seq_len in enumerate(src_seq_lens.tolist() + [0]):\n",
        "        while seq_len <= pointer:\n",
        "            src_batch_sizes[pointer] = i\n",
        "            pointer -= 1\n",
        "    return src_batch_sizes\n",
        "\n",
        "\n",
        "# Training the baseline model on SST-2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "embedding_dim = 128 # usually bigger, e.g. 128\n",
        "hidden_dim = 256\n",
        "n_layers = 1\n",
        "rnnmodel = RNNModel(embedding_dim, hidden_dim, n_layers).to(device)\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "cel = cel.to(device)\n",
        "# optimizer = torch.optim.SGD(rnnmodel.parameters(), lr=1e-1)\n",
        "optimizer = torch.optim.Adam(rnnmodel.parameters(), lr=2e-4)\n",
        "\n",
        "epochs = 50\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0.0\n",
        "    train_data_num = 0\n",
        "    for i, (source, src_seq_lens, target) in enumerate(train_data_loader):\n",
        "        train_tensor_src = torch.LongTensor(source).to(device)\n",
        "        train_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "\n",
        "        sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "        train_sorted_src = train_tensor_src[sorted_indices]\n",
        "        train_sorted_tgt = train_tensor_tgt[sorted_indices]\n",
        "        b_size = train_sorted_src.shape[0]\n",
        "\n",
        "        # print(src_seq_lens.shape, src_batch_sizes.shape, seqs2batches(src_batch_sizes).shape)\n",
        "        h0 = torch.zeros(n_layers, b_size, hidden_dim, requires_grad=True).to(device)\n",
        "        # logits = rnnmodel(train_tensor_src, src_seq_lens, h0)\n",
        "        logits = rnnmodel(train_sorted_src, sorted_seq_lens, h0)\n",
        "\n",
        "        # print(train_tensor_src.shape, train_sorted_tgt.shape, logits.shape)\n",
        "\n",
        "        optimizer.zero_grad() # reset process\n",
        "        loss = cel(logits, train_sorted_tgt) # Loss, a.k.a L\n",
        "        loss.backward() # compute gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), 5) # gradent clipping\n",
        "        optimizer.step() # update parameters\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, train_preds = torch.max(logits, 1)\n",
        "        train_accuracy += (train_preds == train_sorted_tgt).sum().float()\n",
        "\n",
        "        train_data_num += train_sorted_tgt.shape[0]\n",
        "\n",
        "    print('train:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(train_loss / train_data_num), \n",
        "                'acc =', '{:.6f}'.format(train_accuracy / train_data_num))\n",
        "    \n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0\n",
        "            valid_accuracy = 0.0\n",
        "            valid_data_num = 0\n",
        "            for i, (source, src_seq_lens, target) in enumerate(dev_data_loader):\n",
        "                dev_tensor_src = torch.LongTensor(source).to(device)\n",
        "                dev_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "            \n",
        "                sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "                dev_sorted_src = dev_tensor_src[sorted_indices]\n",
        "                dev_sorted_tgt = dev_tensor_tgt[sorted_indices]\n",
        "\n",
        "                h0 = torch.zeros(n_layers, dev_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "                logits = rnnmodel(dev_sorted_src, sorted_seq_lens, h0)\n",
        "\n",
        "                loss = cel(logits, dev_sorted_tgt) # Loss, a.k.a L\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                _, valid_preds = torch.max(logits, 1)\n",
        "                valid_accuracy += (valid_preds == dev_sorted_tgt).sum().float()\n",
        "\n",
        "                valid_data_num += dev_sorted_tgt.shape[0]\n",
        "                \n",
        "            print('valid:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(valid_loss / valid_data_num), \n",
        "                'acc =', '{:.6f}'.format(valid_accuracy / valid_data_num))\n",
        "        "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:: Epoch: 0001 cost = 0.005026, acc = 0.623142\n",
            "valid:: Epoch: 0001 cost = 0.005065, acc = 0.642202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-57e9c464a58a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reset process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sorted_tgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Loss, a.k.a L\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), 5) # gradent clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ92ZQUVczxo"
      },
      "source": [
        "It is slightly better than the baseline. (Either cases, nn.RNN or my code)\n",
        "RNN can read the context between words. (time-series data)\n",
        "\n",
        "\n",
        "After 10 Iter, It converges. (Validation Loss begins to increase at 6th iter)\n",
        "...\n",
        "train:: Epoch: 0001 cost = 0.005095, acc = 0.610655\n",
        "valid:: Epoch: 0001 cost = 0.005056, acc = 0.646789\n",
        "train:: Epoch: 0002 cost = 0.004459, acc = 0.700203\n",
        "valid:: Epoch: 0002 cost = 0.004732, acc = 0.685780\n",
        "train:: Epoch: 0003 cost = 0.003854, acc = 0.760976\n",
        "valid:: Epoch: 0003 cost = 0.004496, acc = 0.735092\n",
        "train:: Epoch: 0004 cost = 0.003335, acc = 0.804229\n",
        "valid:: Epoch: 0004 cost = 0.004379, acc = 0.751147\n",
        "train:: Epoch: 0005 cost = 0.002910, acc = 0.837340\n",
        "valid:: Epoch: 0005 cost = 0.004287, acc = 0.769495\n",
        "train:: Epoch: 0006 cost = 0.002569, acc = 0.860696\n",
        "valid:: Epoch: 0006 cost = 0.004296, acc = 0.770642 -> Minimal Val Loss\n",
        "train:: Epoch: 0007 cost = 0.002291, acc = 0.878899\n",
        "valid:: Epoch: 0007 cost = 0.004403, acc = 0.780963\n",
        "train:: Epoch: 0008 cost = 0.002055, acc = 0.893644\n",
        "valid:: Epoch: 0008 cost = 0.004595, acc = 0.784404\n",
        "train:: Epoch: 0009 cost = 0.001855, acc = 0.905670\n",
        "valid:: Epoch: 0009 cost = 0.004847, acc = 0.791284\n",
        "train:: Epoch: 0010 cost = 0.001684, acc = 0.915366\n",
        "valid:: Epoch: 0010 cost = 0.005108, acc = 0.791284 -> Maximal Val Acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyU1H34rOJS7"
      },
      "source": [
        "**Problem 3.3 (bonus)** *(10 points)* Show that the cross entropy computed above is equivalent to the negative log likelihood of the probability distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRxraGxm-lVq"
      },
      "source": [
        "**Answer 3.3** \\\\\n",
        " \n",
        "We assume that the probability distribution follows bernoulli's distribution. \n",
        "\n",
        "$$\n",
        "P\\left(Y=y_{i}\\right)=p^{y_{i}}(1-p)^{1-y_{i}} \\quad\\left(y_{i}=0,1\\right)\n",
        "$$\n",
        "\n",
        "\n",
        "Therefore, the likelihood function is product of pdfs.\n",
        "\n",
        "$$\n",
        "L=\\prod_{i} p^{y_{i}}(1-p)^{1-y_{i}}\n",
        "$$\n",
        "\n",
        "Then, \"negative\" \"log\" likelihood function is \n",
        "$$\n",
        "l=-\\log L=-\\log [\\prod_{i} p^{y_{i}}(1-p)^{1-y_{i}}]\n",
        "\\\\\n",
        "= -\\sum_{i} \\log [p^{y_{i}}(1-p)^{1-y_{i}}]\n",
        "\\\\\n",
        "= -\\sum_{i} [{y_{i}}\\log p + ({1-y_{i}})\\log(1-p)]\n",
        "$$\n",
        "\n",
        "Actually, this is the binary cross-entropy. \\\\\n",
        "\n",
        "The definition of cross-entropy is\n",
        "\n",
        "$$\n",
        "\\sum_{x} g(x) \\log \\frac{1}{f(x)}=-\\sum_{x} g(x) \\log f(x)\n",
        "$$\n",
        "\n",
        "So, in the binary classification problem, negative log likelihood is equvalent to (binary) cross-entropy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-O9D26U_aEB"
      },
      "source": [
        "**Problem 3.4 (bonus)** *(10 points)* Why is it numerically unstable if you compute log on top of softmax?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OASLPeiU-qm7"
      },
      "source": [
        "**Answer 3.4**  \\\\\n",
        "\n",
        "Softmax function is numerically unstable when too large numbers(or too small number, << 1) are approximated as infinity (or zero).\n",
        "\n",
        "There is an example code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "113TCXOmK2de",
        "outputId": "c08e0440-2dc5-4bf3-ed53-bc46de8ed76e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    prob = np.exp(x) / np.sum(np.exp(x))\n",
        "    return prob\n",
        "\n",
        "outs = np.array([10.0, 20.0, 30.0, 9000.0])\n",
        "print(softmax(outs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.  0.  0. nan]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP0dXNWJMM6T"
      },
      "source": [
        "The result is [ 0.  0.  0. nan].\n",
        "To avoid this, we need to use other softmax function.\n",
        "\n",
        "There is an example code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q2UwKSCMhH5",
        "outputId": "943a8599-3800-40af-fd13-7ed029a71d63"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    # prob = np.exp(x) / np.sum(np.exp(x))\n",
        "    z = x - np.max(x) # It makes the softmax function is numerically stable.\n",
        "    prob = np.exp(z) / np.sum(np.exp(z)) \n",
        "    return prob\n",
        "\n",
        "outs = np.array([10.0, 20.0, 30.0, 9000.0])\n",
        "print(softmax(outs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBLmpKJRAd1h"
      },
      "source": [
        "## 4. Text Classification with LSTM and Dropout\n",
        "\n",
        "Now it is time to improve your baselines! Replace your RNN module with an LSTM module. See Lecture slides 04 and 05 for the formal definition of LSTMs. \n",
        "\n",
        "You will also use Dropout, which randomly makes each dimension zero with the probability of `p` and scale it by `1/(1-p)` if it is not zero during training. Put it either at the input or the output of the LSTM to prevent it from overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8H0F-csCCk0",
        "outputId": "9d38711e-dba9-4bf6-f5bc-c421aafebb8f"
      },
      "source": [
        "a = torch.FloatTensor([0.1, 0.3, 0.5, 0.7, 0.9])\n",
        "dropout = nn.Dropout(0.5) # p=0.5\n",
        "print(dropout(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.0000, 0.0000, 0.0000, 1.8000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAduhDj-Iva2"
      },
      "source": [
        "Problem 4.1 (20 points) Implement and use LSTM (without using PyTorch's LSTM module) instead of vanilla RNN to improve your model. Report the accuracy on the dev data.\n",
        "\n",
        "**Answer 4.1** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMF_9_0MKe8m"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# One LSTM layer and classification\n",
        "class LSTMNode(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(LSTMNode, self).__init__()\n",
        "\n",
        "        self.W_ft = torch.nn.Linear(input_size + hidden_size, hidden_size) # forget gate\n",
        "        self.W_it = torch.nn.Linear(input_size + hidden_size, hidden_size) # input gate\n",
        "        self.W_ot = torch.nn.Linear(input_size + hidden_size, hidden_size) # output gate\n",
        "        self.W_ct = torch.nn.Linear(input_size + hidden_size, hidden_size) # cell state\n",
        "        self.W_ht = torch.nn.Linear(hidden_size, hidden_size) # hidden state\n",
        "        self.W_h2y = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "    \n",
        "    def forward(self, input, hidden, cell, src_batch_sizes):\n",
        "        h_t = hidden.squeeze(0)\n",
        "        c_t = cell.squeeze(0)\n",
        "        h_last = h_t\n",
        "        c_last = c_t\n",
        "        y_list = list()\n",
        "        batch_size = int(src_batch_sizes[0])\n",
        "\n",
        "        for i, batch in enumerate(src_batch_sizes):\n",
        "            batch = int(batch)\n",
        "            token = input[i][:batch, :].clone()\n",
        "            combined_input = torch.cat([token, h_t[:batch, :]], dim=1)\n",
        "\n",
        "            f_t = self.sigmoid(self.W_ft(combined_input))\n",
        "            i_t = self.sigmoid(self.W_it(combined_input))\n",
        "            o_t = self.sigmoid(self.W_ot(combined_input))\n",
        "            c_hat_t = self.tanh(self.W_ct(combined_input))\n",
        "            \n",
        "            c_last[:batch, :] = c_t = f_t*c_t[:batch, :].clone() + i_t*c_hat_t\n",
        "            h_last[:batch, :] = h_t = o_t*self.tanh(c_t)\n",
        "\n",
        "            y_t = self.W_h2y(h_t)\n",
        "            y_list.append(nn.ZeroPad2d((0, 0, batch_size - batch, 0))(y_t)) # Zero-padding\n",
        "        y = torch.stack(y_list, dim=0)\n",
        "\n",
        "        return y, c_last.unsqueeze(0), h_last.unsqueeze(0)\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, n_layers, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "\n",
        "        # nn.LSTM\n",
        "        # self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers)\n",
        "\n",
        "        # my LSTM\n",
        "        self.lstm = LSTMNode(input_size=embedding_dim, hidden_size=hidden_dim)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * n_layers, 2, bias=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_tensor, src_seq_lens, hidden, cell):\n",
        "        emb = self.embedding(input_tensor) # emb.shape = batch * len * hidden\n",
        "        # emb = self.dropout(emb)\n",
        "        emb = emb.transpose(0, 1) # emb.shape = len * batch * hidden\n",
        "\n",
        "        # nn.LSTM\n",
        "        # packed = pack_padded_sequence(emb, src_seq_lens.tolist(), batch_first=False)\n",
        "        # outs, (hidden, cell) = self.lstm(packed) # h0 = zero initialization\n",
        "        # outs, out_lens = pad_packed_sequence(outs, batch_first=False)\n",
        "\n",
        "        # my LSTM\n",
        "        # print(hidden.shape, cell.shape)\n",
        "        # print(\"input shape : \", emb.shape, hidden.shape) # len * batch * emb, 1 * batch * hidden\n",
        "        src_batch_sizes = seqs2batches(src_seq_lens)\n",
        "        outs, cell, hidden = self.lstm(emb, hidden, cell, src_batch_sizes) # h0 = zero initialization\n",
        "        # print(\"output shape : \", outs.shape, cell.shape, hidden.shape) # len * batch * hidden, 1 * batch * hidden, 1 * batch * hidden\n",
        "\n",
        "        hidden = hidden.transpose(0, 1)\n",
        "        hidden = hidden.contiguous().view(hidden.shape[0], -1)\n",
        "\n",
        "        # hidden = self.dropout(hidden)\n",
        "        logits = self.fc(hidden)\n",
        "        # logits = self.fc(outs[-1])\n",
        "        return logits\n",
        "\n",
        "\n",
        "def seqs2batches(src_seq_lens):\n",
        "    \"\"\"\n",
        "    This is same with batches2seqs() \n",
        "    \"\"\"\n",
        "    assert src_seq_lens is not None\n",
        "    assert src_seq_lens[-1] > 0\n",
        "    src_batch_sizes = torch.zeros(int(src_seq_lens[0]))\n",
        "    pointer = int(src_seq_lens[0]) - 1\n",
        "    for i, seq_len in enumerate(src_seq_lens.tolist() + [0]):\n",
        "        while seq_len <= pointer:\n",
        "            src_batch_sizes[pointer] = i\n",
        "            pointer -= 1\n",
        "    return src_batch_sizes\n",
        "\n",
        "\n",
        "# Training the baseline model on SST-2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "embedding_dim = 128 # usually bigger, e.g. 128\n",
        "hidden_dim = 256\n",
        "n_layers = 1\n",
        "dropout = 0.5\n",
        "rnnmodel = LSTMModel(embedding_dim, hidden_dim, n_layers, dropout).to(device)\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(rnnmodel.parameters(), lr=1e-1)\n",
        "optimizer = torch.optim.Adam(rnnmodel.parameters(), lr=1e-4)\n",
        "\n",
        "epochs = 150\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0.0\n",
        "    train_data_num = 0\n",
        "    for i, (source, src_seq_lens, target) in enumerate(train_data_loader):\n",
        "        train_tensor_src = torch.LongTensor(source).to(device)\n",
        "        train_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "\n",
        "        sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "        train_sorted_src = train_tensor_src[sorted_indices]\n",
        "        train_sorted_tgt = train_tensor_tgt[sorted_indices]\n",
        "\n",
        "        # print(src_seq_lens.shape, src_batch_sizes.shape, seqs2batches(src_batch_sizes).shape)\n",
        "        h0 = torch.zeros(1, train_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "        c0 = torch.zeros(1, train_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "        logits = rnnmodel(train_sorted_src, sorted_seq_lens, h0, c0)\n",
        "\n",
        "        # print(train_tensor_src.shape, train_tensor_tgt.shape, logits.shape)\n",
        "\n",
        "        optimizer.zero_grad() # reset process\n",
        "        loss = cel(logits, train_sorted_tgt) # Loss, a.k.a L\n",
        "        loss.backward() # compute gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), 5) # gradent clipping\n",
        "        optimizer.step() # update parameters\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, train_preds = torch.max(logits, 1)\n",
        "        train_accuracy += (train_preds == train_sorted_tgt).sum().float()\n",
        "\n",
        "        train_data_num += train_sorted_tgt.shape[0]\n",
        "\n",
        "    print('train:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(train_loss / train_data_num), \n",
        "                'acc =', '{:.6f}'.format(train_accuracy / train_data_num))\n",
        "    \n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0\n",
        "            valid_accuracy = 0.0\n",
        "            valid_data_num = 0\n",
        "            for i, (source, src_seq_lens, target) in enumerate(dev_data_loader):\n",
        "                dev_tensor_src = torch.LongTensor(source).to(device)\n",
        "                dev_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "            \n",
        "                sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "                dev_sorted_src = dev_tensor_src[sorted_indices]\n",
        "                dev_sorted_tgt = dev_tensor_tgt[sorted_indices]\n",
        "\n",
        "                h0 = torch.zeros(1, dev_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "                c0 = torch.zeros(1, dev_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "                logits = rnnmodel(dev_sorted_src, sorted_seq_lens, h0, c0)\n",
        "\n",
        "                loss = cel(logits, dev_sorted_tgt) # Loss, a.k.a L\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                _, valid_preds = torch.max(logits, 1)\n",
        "                valid_accuracy += (valid_preds == dev_sorted_tgt).sum().float()\n",
        "\n",
        "                valid_data_num += dev_sorted_tgt.shape[0]\n",
        "                \n",
        "            print('valid:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(valid_loss / valid_data_num), \n",
        "                'acc =', '{:.6f}'.format(valid_accuracy / valid_data_num))\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAOVpSQoAz46"
      },
      "source": [
        "It is slightly better than the RNN. (Either cases, nn.LSTM or my code)\n",
        "LSTM also read the context between words. (time-series data)\n",
        "\n",
        "nn.LSTM is slightly better than my code.\n",
        "But, both are overfit too fast. we need the regularization (ex. Dropout)\n",
        "\n",
        "# my LSTM\n",
        "After 2 Iter, It converges. (Validation Loss begins to increase at 2th iter)\n",
        "train:: Epoch: 0001 cost = 0.005046, acc = 0.620276\n",
        "valid:: Epoch: 0001 cost = 0.004601, acc = 0.706422\n",
        "train:: Epoch: 0002 cost = 0.004217, acc = 0.728266\n",
        "valid:: Epoch: 0002 cost = 0.004331, acc = 0.731651 -> Minimal Val Loss\n",
        "train:: Epoch: 0003 cost = 0.003472, acc = 0.792142\n",
        "valid:: Epoch: 0003 cost = 0.004532, acc = 0.754587\n",
        "train:: Epoch: 0004 cost = 0.002940, acc = 0.831430\n",
        "valid:: Epoch: 0004 cost = 0.004979, acc = 0.756881\n",
        "train:: Epoch: 0005 cost = 0.002581, acc = 0.856256\n",
        "valid:: Epoch: 0005 cost = 0.004944, acc = 0.769495\n",
        "train:: Epoch: 0006 cost = 0.002306, acc = 0.873985\n",
        "valid:: Epoch: 0006 cost = 0.005360, acc = 0.776376\n",
        "train:: Epoch: 0007 cost = 0.002091, acc = 0.887066\n",
        "valid:: Epoch: 0007 cost = 0.005567, acc = 0.780963\n",
        "train:: Epoch: 0008 cost = 0.001913, acc = 0.899152\n",
        "valid:: Epoch: 0008 cost = 0.005734, acc = 0.775229\n",
        "train:: Epoch: 0009 cost = 0.001777, acc = 0.906888\n",
        "valid:: Epoch: 0009 cost = 0.005808, acc = 0.769495\n",
        "train:: Epoch: 0010 cost = 0.001653, acc = 0.915158\n",
        "valid:: Epoch: 0010 cost = 0.006519, acc = 0.774083\n",
        "train:: Epoch: 0011 cost = 0.001562, acc = 0.920637\n",
        "valid:: Epoch: 0011 cost = 0.006924, acc = 0.783257\n",
        "train:: Epoch: 0012 cost = 0.001464, acc = 0.926205\n",
        "valid:: Epoch: 0012 cost = 0.007025, acc = 0.802752 -> Maximal Val Acc\n",
        "\n",
        "# nn.LSTM\n",
        "After 3 Iter, It converges. (Validation Loss begins to increase at 3th iter)\n",
        "train:: Epoch: 0001 cost = 0.005045, acc = 0.621464\n",
        "valid:: Epoch: 0001 cost = 0.004841, acc = 0.677752\n",
        "train:: Epoch: 0002 cost = 0.004179, acc = 0.731533\n",
        "valid:: Epoch: 0002 cost = 0.004319, acc = 0.721330\n",
        "train:: Epoch: 0003 cost = 0.003417, acc = 0.796849\n",
        "valid:: Epoch: 0003 cost = 0.004258, acc = 0.753440 -> Minimal Val Loss\n",
        "train:: Epoch: 0004 cost = 0.002875, acc = 0.835454\n",
        "valid:: Epoch: 0004 cost = 0.004336, acc = 0.764908\n",
        "train:: Epoch: 0005 cost = 0.002508, acc = 0.860354\n",
        "valid:: Epoch: 0005 cost = 0.004433, acc = 0.780963\n",
        "train:: Epoch: 0006 cost = 0.002240, acc = 0.878320\n",
        "valid:: Epoch: 0006 cost = 0.004692, acc = 0.790138\n",
        "train:: Epoch: 0007 cost = 0.002028, acc = 0.892070\n",
        "valid:: Epoch: 0007 cost = 0.004736, acc = 0.792431\n",
        "train:: Epoch: 0008 cost = 0.001864, acc = 0.901840\n",
        "valid:: Epoch: 0008 cost = 0.004864, acc = 0.797018\n",
        "train:: Epoch: 0009 cost = 0.001728, acc = 0.909947\n",
        "valid:: Epoch: 0009 cost = 0.005114, acc = 0.798165\n",
        "train:: Epoch: 0010 cost = 0.001621, acc = 0.916020\n",
        "valid:: Epoch: 0010 cost = 0.005273, acc = 0.801605\n",
        "train:: Epoch: 0011 cost = 0.001515, acc = 0.922167\n",
        "valid:: Epoch: 0011 cost = 0.005428, acc = 0.801605\n",
        "train:: Epoch: 0012 cost = 0.001436, acc = 0.927230\n",
        "valid:: Epoch: 0012 cost = 0.005878, acc = 0.803899 -> Maximal Val Acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHDodvqvIx4W"
      },
      "source": [
        "Problem 4.2 (10 points) Use Dropout on LSTM (either at input or output). Report the accuracy on the dev data and briefly describe how it differs from 4.1.\n",
        "\n",
        "**Answer 4.2** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "K8e6B_LTA08W",
        "outputId": "d2253d93-71e7-4192-eba0-01ca6528328d"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# One LSTM layer and classification\n",
        "class LSTMNode(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(LSTMNode, self).__init__()\n",
        "\n",
        "        self.W_ft = torch.nn.Linear(input_size + hidden_size, hidden_size) # forget gate\n",
        "        self.W_it = torch.nn.Linear(input_size + hidden_size, hidden_size) # input gate\n",
        "        self.W_ot = torch.nn.Linear(input_size + hidden_size, hidden_size) # output gate\n",
        "        self.W_ct = torch.nn.Linear(input_size + hidden_size, hidden_size) # cell state\n",
        "        self.W_ht = torch.nn.Linear(hidden_size, hidden_size) # hidden state\n",
        "        self.W_h2y = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "    \n",
        "    def forward(self, input, hidden, cell, src_batch_sizes):\n",
        "        h_t = hidden.squeeze(0)\n",
        "        c_t = cell.squeeze(0)\n",
        "        h_last = h_t\n",
        "        c_last = c_t\n",
        "        y_list = list()\n",
        "        batch_size = int(src_batch_sizes[0])\n",
        "\n",
        "        for i, batch in enumerate(src_batch_sizes):\n",
        "            batch = int(batch)\n",
        "            token = input[i][:batch, :].clone()\n",
        "            combined_input = torch.cat([token, h_t[:batch, :]], dim=1)\n",
        "\n",
        "            f_t = self.sigmoid(self.W_ft(combined_input))\n",
        "            i_t = self.sigmoid(self.W_it(combined_input))\n",
        "            o_t = self.sigmoid(self.W_ot(combined_input))\n",
        "            c_hat_t = self.tanh(self.W_ct(combined_input))\n",
        "            \n",
        "            c_last[:batch, :] = c_t = f_t*c_t[:batch, :].clone() + i_t*c_hat_t\n",
        "            h_last[:batch, :] = h_t = o_t*self.tanh(c_t)\n",
        "\n",
        "            y_t = self.W_h2y(h_t)\n",
        "            y_list.append(nn.ZeroPad2d((0, 0, batch_size - batch, 0))(y_t)) # Zero-padding\n",
        "        y = torch.stack(y_list, dim=0)\n",
        "\n",
        "        return y, c_last.unsqueeze(0), h_last.unsqueeze(0)\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, n_layers, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "\n",
        "        # nn.LSTM\n",
        "        # self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, dropout=dropout)\n",
        "\n",
        "        # my LSTM\n",
        "        self.lstm = LSTMNode(input_size=embedding_dim, hidden_size=hidden_dim)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * n_layers, 2, bias=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_tensor, src_seq_lens, hidden, cell):\n",
        "        emb = self.embedding(input_tensor) # emb.shape = batch * len * hidden\n",
        "        emb = self.dropout(emb)\n",
        "        emb = emb.transpose(0, 1) # emb.shape = len * batch * hidden\n",
        "\n",
        "        # nn.LSTM\n",
        "        # packed = pack_padded_sequence(emb, src_seq_lens.tolist(), batch_first=False)\n",
        "        # outs, (hidden, cell) = self.lstm(packed) # h0 = zero initialization\n",
        "        # outs, out_lens = pad_packed_sequence(outs, batch_first=False)\n",
        "\n",
        "        # my LSTM\n",
        "        # print(hidden.shape, cell.shape)\n",
        "        # print(\"input shape : \", emb.shape, hidden.shape) # len * batch * emb, 1 * batch * hidden\n",
        "        src_batch_sizes = seqs2batches(src_seq_lens)\n",
        "        outs, cell, hidden = self.lstm(emb, hidden, cell, src_batch_sizes) # h0 = zero initialization\n",
        "        # print(\"output shape : \", outs.shape, cell.shape, hidden.shape) # len * batch * hidden, 1 * batch * hidden, 1 * batch * hidden\n",
        "\n",
        "        hidden = hidden.transpose(0, 1)\n",
        "        hidden = hidden.contiguous().view(hidden.shape[0], -1)\n",
        "\n",
        "        hidden = self.dropout(hidden)\n",
        "        logits = self.fc(hidden)\n",
        "        # logits = self.fc(outs[-1])\n",
        "        return logits\n",
        "\n",
        "\n",
        "def seqs2batches(src_seq_lens):\n",
        "    \"\"\"\n",
        "    This is same with batches2seqs() \n",
        "    \"\"\"\n",
        "    assert src_seq_lens is not None\n",
        "    assert src_seq_lens[-1] > 0\n",
        "    src_batch_sizes = torch.zeros(int(src_seq_lens[0]))\n",
        "    pointer = int(src_seq_lens[0]) - 1\n",
        "    for i, seq_len in enumerate(src_seq_lens.tolist() + [0]):\n",
        "        while seq_len <= pointer:\n",
        "            src_batch_sizes[pointer] = i\n",
        "            pointer -= 1\n",
        "    return src_batch_sizes\n",
        "\n",
        "\n",
        "# Training the baseline model on SST-2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "embedding_dim = 128 # usually bigger, e.g. 128\n",
        "hidden_dim = 256\n",
        "n_layers = 1\n",
        "dropout = 0.5\n",
        "rnnmodel = LSTMModel(embedding_dim, hidden_dim, n_layers, dropout).to(device)\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(rnnmodel.parameters(), lr=1e-1)\n",
        "optimizer = torch.optim.Adam(rnnmodel.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0.0\n",
        "    train_data_num = 0\n",
        "    for i, (source, src_seq_lens, target) in enumerate(train_data_loader):\n",
        "        train_tensor_src = torch.LongTensor(source).to(device)\n",
        "        train_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "\n",
        "        sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "        train_sorted_src = train_tensor_src[sorted_indices]\n",
        "        train_sorted_tgt = train_tensor_tgt[sorted_indices]\n",
        "\n",
        "        # print(src_seq_lens.shape, src_batch_sizes.shape, seqs2batches(src_batch_sizes).shape)\n",
        "        h0 = torch.zeros(1, train_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "        c0 = torch.zeros(1, train_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "        logits = rnnmodel(train_sorted_src, sorted_seq_lens, h0, c0)\n",
        "\n",
        "        # print(train_tensor_src.shape, train_tensor_tgt.shape, logits.shape)\n",
        "\n",
        "        optimizer.zero_grad() # reset process\n",
        "        loss = cel(logits, train_sorted_tgt) # Loss, a.k.a L\n",
        "        loss.backward() # compute gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), 5) # gradent clipping\n",
        "        optimizer.step() # update parameters\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, train_preds = torch.max(logits, 1)\n",
        "        train_accuracy += (train_preds == train_sorted_tgt).sum().float()\n",
        "\n",
        "        train_data_num += train_sorted_tgt.shape[0]\n",
        "\n",
        "    print('train:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(train_loss / train_data_num), \n",
        "                'acc =', '{:.6f}'.format(train_accuracy / train_data_num))\n",
        "    \n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0\n",
        "            valid_accuracy = 0.0\n",
        "            valid_data_num = 0\n",
        "            for i, (source, src_seq_lens, target) in enumerate(dev_data_loader):\n",
        "                dev_tensor_src = torch.LongTensor(source).to(device)\n",
        "                dev_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "            \n",
        "                sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "                dev_sorted_src = dev_tensor_src[sorted_indices]\n",
        "                dev_sorted_tgt = dev_tensor_tgt[sorted_indices]\n",
        "\n",
        "                h0 = torch.zeros(1, dev_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "                c0 = torch.zeros(1, dev_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "                logits = rnnmodel(dev_sorted_src, sorted_seq_lens, h0, c0)\n",
        "\n",
        "                loss = cel(logits, dev_sorted_tgt) # Loss, a.k.a L\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                _, valid_preds = torch.max(logits, 1)\n",
        "                valid_accuracy += (valid_preds == dev_sorted_tgt).sum().float()\n",
        "\n",
        "                valid_data_num += dev_sorted_tgt.shape[0]\n",
        "                \n",
        "            print('valid:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(valid_loss / valid_data_num), \n",
        "                'acc =', '{:.6f}'.format(valid_accuracy / valid_data_num))\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-d8592feed656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mn_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mrnnmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mcel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnJUx3kCT0MO"
      },
      "source": [
        "It is better than the vanilla LSTM. (Accuracy)\n",
        "and it takes more time for training.\n",
        "Dropout works as regularizer, so the model does not overfit too fast.\n",
        "(The validation loss of this model is lower than others model.)\n",
        "\n",
        "# my LSTM\n",
        "After 5 Iter, It converges. (Validation Loss begins to increase at 5th iter)\n",
        "train:: Epoch: 0001 cost = 0.004816, acc = 0.649646\n",
        "valid:: Epoch: 0001 cost = 0.004635, acc = 0.717890\n",
        "train:: Epoch: 0002 cost = 0.003708, acc = 0.770687\n",
        "valid:: Epoch: 0002 cost = 0.004408, acc = 0.744266\n",
        "train:: Epoch: 0003 cost = 0.003049, acc = 0.823724\n",
        "valid:: Epoch: 0003 cost = 0.003992, acc = 0.776376\n",
        "train:: Epoch: 0004 cost = 0.002638, acc = 0.851609\n",
        "valid:: Epoch: 0004 cost = 0.003777, acc = 0.785550\n",
        "train:: Epoch: 0005 cost = 0.002331, acc = 0.872916\n",
        "valid:: Epoch: 0005 cost = 0.003772, acc = 0.800459 -> Minimal Val Loss\n",
        "train:: Epoch: 0006 cost = 0.002082, acc = 0.889382\n",
        "valid:: Epoch: 0006 cost = 0.003856, acc = 0.798165\n",
        "train:: Epoch: 0007 cost = 0.001931, acc = 0.898053\n",
        "valid:: Epoch: 0007 cost = 0.003924, acc = 0.807339\n",
        "train:: Epoch: 0008 cost = 0.001785, acc = 0.906591\n",
        "valid:: Epoch: 0008 cost = 0.003915, acc = 0.805046\n",
        "train:: Epoch: 0009 cost = 0.001650, acc = 0.914861\n",
        "valid:: Epoch: 0009 cost = 0.003891, acc = 0.810780\n",
        "train:: Epoch: 0010 cost = 0.001551, acc = 0.919910\n",
        "valid:: Epoch: 0010 cost = 0.003962, acc = 0.806193\n",
        "train:: Epoch: 0011 cost = 0.001486, acc = 0.923830\n",
        "valid:: Epoch: 0011 cost = 0.004208, acc = 0.825688\n",
        "train:: Epoch: 0012 cost = 0.001389, acc = 0.930095\n",
        "valid:: Epoch: 0012 cost = 0.004485, acc = 0.809633\n",
        "train:: Epoch: 0013 cost = 0.001314, acc = 0.935218\n",
        "valid:: Epoch: 0013 cost = 0.004200, acc = 0.814220\n",
        "train:: Epoch: 0013 cost = 0.001314, acc = 0.935218\n",
        "valid:: Epoch: 0013 cost = 0.004200, acc = 0.814220\n",
        "train:: Epoch: 0014 cost = 0.001282, acc = 0.935946\n",
        "valid:: Epoch: 0014 cost = 0.004002, acc = 0.830275\n",
        "train:: Epoch: 0015 cost = 0.001205, acc = 0.939331\n",
        "valid:: Epoch: 0015 cost = 0.004838, acc = 0.808486\n",
        "train:: Epoch: 0016 cost = 0.001151, acc = 0.943785\n",
        "valid:: Epoch: 0016 cost = 0.004312, acc = 0.823394\n",
        "train:: Epoch: 0017 cost = 0.001083, acc = 0.946161\n",
        "valid:: Epoch: 0017 cost = 0.004074, acc = 0.832569\n",
        "train:: Epoch: 0018 cost = 0.001050, acc = 0.947557\n",
        "valid:: Epoch: 0018 cost = 0.004598, acc = 0.826835\n",
        "train:: Epoch: 0019 cost = 0.001021, acc = 0.949650\n",
        "valid:: Epoch: 0019 cost = 0.003923, acc = 0.837156 -> Maximal Val Acc\n",
        "train:: Epoch: 0020 cost = 0.000978, acc = 0.952264\n",
        "valid:: Epoch: 0020 cost = 0.004235, acc = 0.825688\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dbUZ0wCIzHq"
      },
      "source": [
        "Problem 4.3 (bonus) (10 points) Consider implementing bidirectional LSTM and two layers of LSTM to further improve your model. Report your accuracy on dev data.\n",
        "\n",
        "**Answer 4.3** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vycv-i0LA3Sh"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# Two bidirectional LSTM layer and classification\n",
        "class BidirectionalLSTMNode(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, n_layers):\n",
        "        super(LSTMNode, self).__init__()\n",
        "\n",
        "        self.W_ft = torch.nn.Linear(input_size + hidden_size, hidden_size) # forget gate\n",
        "        self.W_it = torch.nn.Linear(input_size + hidden_size, hidden_size) # input gate\n",
        "        self.W_ot = torch.nn.Linear(input_size + hidden_size, hidden_size) # output gate\n",
        "        self.W_ct = torch.nn.Linear(input_size + hidden_size, hidden_size) # cell state\n",
        "        self.W_ht = torch.nn.Linear(hidden_size, hidden_size) # hidden state\n",
        "        self.W_h2y = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "    \n",
        "    def forward(self, input, hidden, cell, src_batch_sizes):\n",
        "        h_t = hidden.squeeze(0)\n",
        "        c_t = cell.squeeze(0)\n",
        "        h_last = h_t\n",
        "        c_last = c_t\n",
        "        y_list = list()\n",
        "        batch_size = int(src_batch_sizes[0])\n",
        "\n",
        "        for i, batch in enumerate(src_batch_sizes):\n",
        "            batch = int(batch)\n",
        "            token = input[i][:batch, :].clone()\n",
        "            combined_input = torch.cat([token, h_t[:batch, :]], dim=1)\n",
        "\n",
        "            f_t = self.sigmoid(self.W_ft(combined_input))\n",
        "            i_t = self.sigmoid(self.W_it(combined_input))\n",
        "            o_t = self.sigmoid(self.W_ot(combined_input))\n",
        "            c_hat_t = self.tanh(self.W_ct(combined_input))\n",
        "            \n",
        "            c_last[:batch, :] = c_t = f_t*c_t[:batch, :].clone() + i_t*c_hat_t\n",
        "            h_last[:batch, :] = h_t = o_t*self.tanh(c_t)\n",
        "\n",
        "            y_t = self.W_h2y(h_t)\n",
        "            y_list.append(nn.ZeroPad2d((0, 0, batch_size - batch, 0))(y_t)) # Zero-padding\n",
        "        y = torch.stack(y_list, dim=0)\n",
        "\n",
        "        return y, c_last.unsqueeze(0), h_last.unsqueeze(0)\n",
        "\n",
        "\n",
        "class BidirectionalLSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, n_layers, dropout, bidirectional):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "\n",
        "        # nn.LSTM\n",
        "        # self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, dropout=dropout, bidirectional=bidirectional)\n",
        "\n",
        "        # my LSTM\n",
        "        self.lstm = LSTMNode(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * n_layers, 2, bias=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_tensor, src_seq_lens, hidden, cell):\n",
        "        emb = self.embedding(input_tensor) # emb.shape = batch * len * hidden\n",
        "        emb = self.dropout(emb)\n",
        "        emb = emb.transpose(0, 1) # emb.shape = len * batch * hidden\n",
        "\n",
        "        # nn.LSTM\n",
        "        # packed = pack_padded_sequence(emb, src_seq_lens.tolist(), batch_first=False)\n",
        "        # outs, (hidden, cell) = self.lstm(packed) # h0 = zero initialization\n",
        "        # outs, out_lens = pad_packed_sequence(outs, batch_first=False)\n",
        "\n",
        "        # my LSTM\n",
        "        # print(hidden.shape, cell.shape)\n",
        "        # print(\"input shape : \", emb.shape, hidden.shape) # len * batch * emb, 1 * batch * hidden\n",
        "        src_batch_sizes = seqs2batches(src_seq_lens)\n",
        "        outs, cell, hidden = self.lstm(emb, hidden, cell, src_batch_sizes) # h0 = zero initialization\n",
        "        # print(\"output shape : \", outs.shape, cell.shape, hidden.shape) # len * batch * hidden, 1 * batch * hidden, 1 * batch * hidden\n",
        "\n",
        "        hidden = hidden.transpose(0, 1)\n",
        "        hidden = hidden.contiguous().view(hidden.shape[0], -1)\n",
        "\n",
        "        hidden = self.dropout(hidden)\n",
        "        logits = self.fc(hidden)\n",
        "        # logits = self.fc(outs[-1])\n",
        "        return logits\n",
        "\n",
        "\n",
        "def seqs2batches(src_seq_lens):\n",
        "    \"\"\"\n",
        "    This is same with batches2seqs() \n",
        "    \"\"\"\n",
        "    assert src_seq_lens is not None\n",
        "    assert src_seq_lens[-1] > 0\n",
        "    src_batch_sizes = torch.zeros(int(src_seq_lens[0]))\n",
        "    pointer = int(src_seq_lens[0]) - 1\n",
        "    for i, seq_len in enumerate(src_seq_lens.tolist() + [0]):\n",
        "        while seq_len <= pointer:\n",
        "            src_batch_sizes[pointer] = i\n",
        "            pointer -= 1\n",
        "    return src_batch_sizes\n",
        "\n",
        "\n",
        "# Training the baseline model on SST-2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "embedding_dim = 128 # usually bigger, e.g. 128\n",
        "hidden_dim = 256\n",
        "n_layers = 1\n",
        "dropout = 0.5\n",
        "bidirectional = True\n",
        "rnnmodel = BidirectionalLSTMModel(embedding_dim, hidden_dim, n_layers, dropout, bidirectional).to(device)\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(rnnmodel.parameters(), lr=1e-1)\n",
        "optimizer = torch.optim.Adam(rnnmodel.parameters(), lr=2e-4)\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0.0\n",
        "    train_data_num = 0\n",
        "    for i, (source, src_seq_lens, target) in enumerate(train_data_loader):\n",
        "        train_tensor_src = torch.LongTensor(source).to(device)\n",
        "        train_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "\n",
        "        sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "        train_sorted_src = train_tensor_src[sorted_indices]\n",
        "        train_sorted_tgt = train_tensor_tgt[sorted_indices]\n",
        "\n",
        "        # print(src_seq_lens.shape, src_batch_sizes.shape, seqs2batches(src_batch_sizes).shape)\n",
        "        h0 = torch.zeros(1, train_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "        c0 = torch.zeros(1, train_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "        logits = rnnmodel(train_sorted_src, sorted_seq_lens, h0, c0)\n",
        "\n",
        "        # print(train_tensor_src.shape, train_tensor_tgt.shape, logits.shape)\n",
        "\n",
        "        optimizer.zero_grad() # reset process\n",
        "        loss = cel(logits, train_sorted_tgt) # Loss, a.k.a L\n",
        "        loss.backward() # compute gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), 5) # gradent clipping\n",
        "        optimizer.step() # update parameters\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, train_preds = torch.max(logits, 1)\n",
        "        train_accuracy += (train_preds == train_sorted_tgt).sum().float()\n",
        "\n",
        "        train_data_num += train_sorted_tgt.shape[0]\n",
        "\n",
        "    print('train:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(train_loss / train_data_num), \n",
        "                'acc =', '{:.6f}'.format(train_accuracy / train_data_num))\n",
        "    \n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0\n",
        "            valid_accuracy = 0.0\n",
        "            valid_data_num = 0\n",
        "            for i, (source, src_seq_lens, target) in enumerate(dev_data_loader):\n",
        "                dev_tensor_src = torch.LongTensor(source).to(device)\n",
        "                dev_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "            \n",
        "                sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "                dev_sorted_src = dev_tensor_src[sorted_indices]\n",
        "                dev_sorted_tgt = dev_tensor_tgt[sorted_indices]\n",
        "\n",
        "                h0 = torch.zeros(1, dev_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "                c0 = torch.zeros(1, dev_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "                logits = rnnmodel(dev_sorted_src, sorted_seq_lens, h0, c0)\n",
        "\n",
        "                loss = cel(logits, dev_sorted_tgt) # Loss, a.k.a L\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                _, valid_preds = torch.max(logits, 1)\n",
        "                valid_accuracy += (valid_preds == dev_sorted_tgt).sum().float()\n",
        "\n",
        "                valid_data_num += dev_sorted_tgt.shape[0]\n",
        "                \n",
        "            print('valid:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(valid_loss / valid_data_num), \n",
        "                'acc =', '{:.6f}'.format(valid_accuracy / valid_data_num))\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855DrT78DXps"
      },
      "source": [
        "## 5. Pretrained Word Vectors\n",
        "The last step is to use pretrained vocabulary and word vectors. The prebuilt vocabulary will replace the vocabulary you built with SST-2 training data, and the word vectors will replace the embedding vectors. You will observe the power of leveraging self-supservised pretrained models.\n",
        "\n",
        "**Problem 5.1** *(10 points)* Go to https://nlp.stanford.edu/projects/glove/ and download `glove.6B.zip`. Use these pretrained word vectors to further improve your model from 4.2. Report the model's accuracy on the dev data.\n",
        "\n",
        "**Answer 5.1** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygmmqBu4ZSqQ",
        "outputId": "c2e69b1b-bfa5-4159-c213-4d01e4b96742"
      },
      "source": [
        "!git clone https://github.com/stanfordnlp/glove"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'glove'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 595 (delta 0), reused 1 (delta 0), pack-reused 592\u001b[K\n",
            "Receiving objects: 100% (595/595), 222.33 KiB | 14.82 MiB/s, done.\n",
            "Resolving deltas: 100% (338/338), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05Mgqo6scXfQ",
        "outputId": "db52c7a0-d90e-46ee-c819-d403a7b82a55"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-02 11:57:00--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-04-02 11:57:00--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-04-02 11:57:01--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‚Äòglove.6B.zip‚Äô\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.06MB/s    in 2m 41s  \n",
            "\n",
            "2021-04-02 11:59:42 (5.11 MB/s) - ‚Äòglove.6B.zip‚Äô saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSb5JKtGcPhO"
      },
      "source": [
        "import zipfile\n",
        "path_to_zip_file = \"glove.6B.zip\"\n",
        "zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq3woSZyaml7",
        "outputId": "6733981f-afc2-4f34-a81a-20285d0bc80c"
      },
      "source": [
        "!head -10 glove.6B.200d.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the -0.071549 0.093459 0.023738 -0.090339 0.056123 0.32547 -0.39796 -0.092139 0.061181 -0.1895 0.13061 0.14349 0.011479 0.38158 0.5403 -0.14088 0.24315 0.23036 -0.55339 0.048154 0.45662 3.2338 0.020199 0.049019 -0.014132 0.076017 -0.11527 0.2006 -0.077657 0.24328 0.16368 -0.34118 -0.06607 0.10152 0.038232 -0.17668 -0.88153 -0.33895 -0.035481 -0.55095 -0.016899 -0.43982 0.039004 0.40447 -0.2588 0.64594 0.26641 0.28009 -0.024625 0.63302 -0.317 0.10271 0.30886 0.097792 -0.38227 0.086552 0.047075 0.23511 -0.32127 -0.28538 0.1667 -0.0049707 -0.62714 -0.24904 0.29713 0.14379 -0.12325 -0.058178 -0.001029 -0.082126 0.36935 -0.00058442 0.34286 0.28426 -0.068599 0.65747 -0.029087 0.16184 0.073672 -0.30343 0.095733 -0.5286 -0.22898 0.064079 0.015218 0.34921 -0.4396 -0.43983 0.77515 -0.87767 -0.087504 0.39598 0.62362 -0.26211 -0.30539 -0.022964 0.30567 0.06766 0.15383 -0.11211 -0.09154 0.082562 0.16897 -0.032952 -0.28775 -0.2232 -0.090426 1.2407 -0.18244 -0.0075219 -0.041388 -0.011083 0.078186 0.38511 0.23334 0.14414 -0.0009107 -0.26388 -0.20481 0.10099 0.14076 0.28834 -0.045429 0.37247 0.13645 -0.67457 0.22786 0.12599 0.029091 0.030428 -0.13028 0.19408 0.49014 -0.39121 -0.075952 0.074731 0.18902 -0.16922 -0.26019 -0.039771 -0.24153 0.10875 0.30434 0.036009 1.4264 0.12759 -0.073811 -0.20418 0.0080016 0.15381 0.20223 0.28274 0.096206 -0.33634 0.50983 0.32625 -0.26535 0.374 -0.30388 -0.40033 -0.04291 -0.067897 -0.29332 0.10978 -0.045365 0.23222 -0.31134 -0.28983 -0.66687 0.53097 0.19461 0.3667 0.26185 -0.65187 0.10266 0.11363 -0.12953 -0.68246 -0.18751 0.1476 1.0765 -0.22908 -0.0093435 -0.20651 -0.35225 -0.2672 -0.0034307 0.25906 0.21759 0.66158 0.1218 0.19957 -0.20303 0.34474 -0.24328 0.13139 -0.0088767 0.33617 0.030591 0.25577\n",
            ", 0.17651 0.29208 -0.0020768 -0.37523 0.0049139 0.23979 -0.28893 -0.014643 -0.10993 0.15592 0.20627 0.47675 0.099907 -0.14058 0.21114 0.12126 -0.31831 -0.089433 -0.090553 -0.31962 0.21319 2.4844 -0.077521 -0.084279 0.20186 0.26084 -0.40411 -0.19127 0.24715 0.22394 -0.063437 0.20379 -0.18463 -0.088413 0.024169 -0.28769 -0.61246 -0.12683 -0.088273 0.18331 -0.53161 -0.1997 -0.26703 0.15312 -0.015239 -0.082844 0.47856 -0.29612 0.11168 -0.02579 -0.011697 0.19923 -0.14267 0.6625 -0.051739 -0.16938 -0.15635 0.092806 0.32548 0.11724 0.28788 -0.060651 -0.14153 0.16668 0.26861 -0.031001 -0.39665 0.35304 0.2385 0.12388 0.45698 -0.12559 -0.12804 0.37449 0.2446 0.23073 0.20808 0.051258 -0.21816 -0.036409 -0.0388 -0.042487 -0.30779 -0.025449 0.22532 0.045538 -0.48934 -0.13988 0.17394 -0.46137 -0.26555 0.15473 0.063816 -0.17022 -0.15762 0.075765 0.12151 -0.4934 -0.10909 0.034487 0.29947 0.01869 -0.16534 0.016679 0.16341 -0.27418 0.077797 1.4023 0.025275 0.094725 -0.040735 -0.10642 0.023364 0.079143 -0.16615 -0.23013 -0.14071 0.40159 -0.34951 0.018545 0.22434 0.76922 0.24722 0.14936 0.42368 -0.72059 -0.038541 0.15522 0.33596 -0.43077 -0.026925 -0.37733 0.24271 -0.46495 0.45783 0.23693 0.079361 -0.32244 -0.42434 -0.11138 0.55426 0.085153 -0.020581 -0.046386 1.2467 0.13177 0.067092 -0.5778 0.013586 -0.071274 0.017311 0.089781 0.19857 -0.032205 0.64843 -0.23797 -0.19676 0.20203 0.21074 -0.50347 0.026823 -0.045444 -0.22642 -0.19977 -0.12138 0.16941 0.061998 0.42631 -0.088383 0.45756 0.077774 0.061342 0.4571 -0.17787 -0.14597 0.32654 0.002443 -0.11886 0.10081 -0.020011 1.0366 -0.39814 -0.6818 0.23685 -0.20396 -0.17668 -0.31385 0.14834 -0.052187 0.0613 -0.32582 0.19153 -0.15469 -0.14679 0.046971 0.032325 -0.22006 -0.20774 -0.23189 -0.10814\n",
            ". 0.12289 0.58037 -0.069635 -0.50288 0.10503 0.39945 -0.38635 -0.084279 0.12219 0.080312 0.32337 0.47579 -0.038375 -0.00709 0.41524 0.32121 -0.21185 0.36144 -0.055623 -0.030512 0.42854 2.8547 -0.14623 -0.17557 0.31197 -0.13118 0.033298 0.13093 0.089889 -0.12417 0.0023396 -0.068954 -0.10754 -0.11551 -0.31052 -0.12097 -0.46691 -0.0836 -0.037664 -0.071779 -0.11899 -0.20381 -0.12424 0.46339 -0.19828 -0.0080365 0.53718 0.031739 0.34331 0.0079704 0.0048744 0.030592 -0.17615 0.82342 -0.13793 -0.10075 -0.12686 0.074735 -0.088719 -0.042719 0.076624 0.089263 0.064445 -0.031958 0.15254 -0.10384 0.076604 0.34099 0.24331 -0.10452 0.40714 -0.1826 -0.040667 0.50878 0.08076 0.22759 -0.042162 -0.18171 -0.095025 0.030334 0.088202 -3.9843e-06 -0.0039877 0.15724 0.33167 0.08471 -0.25919 -0.41384 0.2992 -0.54255 0.032129 0.1003 0.44202 0.044682 -0.090681 -0.10481 -0.1186 -0.31972 -0.2079 -0.040203 -0.022988 0.22824 0.0055238 0.12568 -0.1464 -0.14904 -0.11561 1.0517 -0.19498 0.083958 0.044812 -0.12965 -0.093468 0.21237 -0.088332 -0.1868 0.26521 0.13097 -0.048102 -0.22467 0.28412 0.34907 0.34833 0.017877 0.30504 -0.83453 0.048856 -0.1933 0.20764 -0.49701 -0.18747 -0.076801 0.15558 -0.46844 0.40944 0.21386 0.082392 -0.26491 -0.21224 -0.13293 0.14738 -0.14192 0.18994 -0.15587 1.0738 0.40789 -0.27452 -0.18431 0.00068679 -0.087115 0.19672 0.40918 -0.35462 -0.06326 0.4492 -0.060568 -0.041636 0.20531 0.017025 -0.58448 0.075441 0.082116 -0.46008 0.012393 -0.02531 0.14177 -0.092192 0.34505 -0.52136 0.57304 0.011973 0.033196 0.29672 -0.27899 0.19979 0.25666 0.082079 -0.078436 0.093719 0.24202 1.3495 -0.30434 -0.30936 0.42047 -0.079068 -0.14819 -0.089404 0.0668 0.22405 0.27226 -0.035236 0.17688 -0.0536 0.0070031 -0.033006 -0.080021 -0.24451 -0.039174 -0.16236 -0.096652\n",
            "of 0.052924 0.25427 0.31353 -0.35613 0.029629 0.51034 -0.10716 0.15195 0.057698 0.06149 0.06116 0.39911 -0.00029018 0.31978 0.43257 -0.14708 0.054842 0.27079 -0.14051 -0.30101 0.16313 3.0013 0.22231 -0.14279 0.083705 0.089866 -0.52706 -0.089661 0.27311 0.31413 -0.04081 0.060557 -0.042656 0.24178 -0.29187 0.22575 -0.6298 -0.14641 -0.22429 -0.056621 -0.17776 -0.64269 0.51626 0.22305 0.12124 0.48074 0.41743 0.54805 0.40955 0.42407 0.049906 -0.32574 0.46298 0.19245 0.28143 0.2966 0.063593 -0.11906 -0.15016 -0.04984 0.40675 0.010675 -0.69127 0.048729 0.26391 0.30961 -0.11921 0.25548 -0.28219 -0.037413 0.36461 0.027129 0.20786 0.53325 0.50148 0.72381 0.065292 -0.078716 -0.10537 -0.08081 -0.2096 0.040902 -0.88101 0.24715 0.16146 0.10361 0.19705 -0.27365 0.89902 -0.29981 0.036165 0.041238 0.60105 -0.18911 -0.43887 -0.14097 0.44073 -0.19999 0.28834 -0.25458 -0.10985 -0.0027379 0.091735 0.17021 -0.16305 -0.57439 0.37063 1.7262 -0.24656 0.51681 -0.15355 -0.15553 0.019783 0.1803 0.38178 0.094443 -0.55158 -0.20242 -0.4386 -0.42108 0.27525 0.58977 0.026655 0.16401 0.13893 -0.68692 0.51071 0.29278 0.022041 -0.18156 -0.64905 0.16923 -0.01059 0.21785 -0.27242 0.27967 0.1395 -0.70559 -0.26034 -0.44017 0.15303 0.19693 -0.096838 0.14827 1.1294 -0.31267 0.0099916 -0.48623 0.080584 0.35608 -0.19925 0.19306 -0.2004 -0.44194 0.75766 0.24487 -0.18903 0.26653 -0.21339 -0.54083 0.40532 -0.02796 -0.13398 -0.11086 0.059506 0.24052 -0.59739 -0.0024069 -0.18593 1.042 -0.12969 0.20813 0.33305 -0.1278 0.085662 -0.076422 0.31407 -0.23784 -0.054838 0.011369 0.845 -0.34165 0.093983 0.082445 -0.27777 -0.44226 -0.063078 0.37274 0.054468 0.24197 -0.040886 0.3894 -0.10509 0.23372 0.096027 -0.30324 0.24488 -0.086254 -0.41917 0.46496\n",
            "to 0.57346 0.5417 -0.23477 -0.3624 0.4037 0.11386 -0.44933 -0.30991 -0.0053411 0.58426 -0.025956 0.49393 -0.037209 -0.28428 0.097696 -0.48907 0.026027 0.37649 0.057788 -0.46807 0.081288 3.2825 -0.6369 0.37956 0.0038167 0.093607 -0.12855 0.1738 0.10522 0.28648 0.21089 -0.47076 0.027733 -0.19803 0.076328 -0.84629 -0.79708 -0.38743 -0.030422 -0.26849 0.48585 0.12895 0.38354 0.38722 -0.38524 0.19075 0.48998 0.13278 0.010792 0.2677 0.17812 -0.11433 -0.33494 0.87306 0.75875 -0.30378 -0.15626 0.0012085 0.23322 0.27953 -0.18494 -0.14146 -0.18969 -0.038386 0.35874 0.065513 0.060565 0.66339 -0.083252 0.065163 0.51761 0.16171 0.46011 0.16388 -0.12399 0.31122 -0.15412 -0.10917 -0.42551 0.11418 0.25137 -0.056158 -0.25927 0.28163 -0.018094 0.16065 -0.48506 -0.98903 0.25022 -0.16736 0.41474 0.17701 0.42407 0.11088 -0.1836 -0.1241 -0.3478 0.099078 -0.22381 -0.11245 -0.21156 0.0030706 -0.23607 0.027261 0.3643 0.039922 -0.18369 1.2266 -0.7764 -0.66225 0.015724 -0.14969 0.084649 0.26814 -0.16765 -0.31942 0.28494 -0.07 0.01201 -0.12219 0.5631 -0.32 0.50109 -0.10209 0.46575 -0.71542 0.17293 0.58259 0.078384 -0.033844 -0.25129 0.36503 0.031578 -0.65778 0.05475 0.87189 0.12455 -0.45877 -0.26965 -0.46779 -0.0028578 0.1781 0.63969 0.13995 0.97596 0.11836 -0.63904 -0.15416 0.065262 0.24329 0.66476 0.25069 -0.10252 -0.32839 -0.085559 -0.012774 -0.19431 0.56139 -0.35733 -0.20344 -0.12413 -0.34431 -0.23296 -0.21187 0.085387 0.070063 -0.19803 -0.026023 -0.39037 0.80002 0.40577 -0.079863 0.35263 -0.34043 0.39676 0.22862 -0.35028 -0.47344 0.59742 -0.11657 1.0552 -0.4157 -0.080552 -0.056571 -0.16622 0.19274 -0.095175 -0.20781 0.1562 0.050231 -0.27915 0.43742 -0.31237 0.13194 -0.33278 0.18877 -0.23422 0.54418 -0.23069 0.34947\n",
            "and 0.20327 0.47348 0.050877 0.002103 0.060547 0.33066 0.048486 0.021504 -0.53631 0.21312 0.19983 0.51408 0.00070422 0.094641 0.068724 0.27424 -0.20493 0.23268 0.3249 -0.19444 0.64693 2.8342 0.14004 -0.26868 0.27325 0.015312 -0.27975 -0.26423 0.14183 -0.026064 0.11349 0.25039 -0.24972 -0.16882 -0.31039 -0.44458 -0.34789 -0.20181 -0.013405 0.23635 0.17741 -0.10535 -0.20716 0.37856 0.10507 -0.3097 0.46782 -0.50021 0.26643 0.51564 0.054247 0.50546 -0.24959 0.54021 0.17268 -0.03865 0.02373 0.24111 0.1721 0.078734 0.31275 0.187 -0.45933 0.55853 0.22511 0.16761 -0.045662 0.55918 -0.24065 -0.24904 0.38718 -0.21586 -0.10332 0.24157 -0.1844 0.31295 -0.16315 -0.21771 0.18137 -0.045089 0.068367 -0.17317 -0.79639 0.24492 0.12389 0.11703 -0.088345 -0.37042 0.43759 -0.47564 -0.095386 -0.15975 0.1838 0.25664 -0.41276 0.047558 0.16437 -0.26353 -0.27328 -0.089788 0.31598 -0.11246 -0.18703 0.20422 0.068352 0.011667 0.13657 1.1524 0.024065 -0.11591 -0.18142 -0.36441 -0.010051 0.19956 0.2685 -0.095357 -0.11906 0.32378 -0.19527 -0.368 -0.0038172 0.396 0.24194 0.31296 0.24128 -0.7612 0.071389 0.42396 0.26369 -0.091366 -0.13438 -0.17673 0.013168 -0.624 0.17744 0.38957 -0.037665 -0.12586 -0.14862 -0.29635 0.40572 -0.071653 -0.11642 -0.16958 1.0982 0.39618 -0.16874 -0.6036 0.41394 0.28977 0.11419 -0.047337 -0.0033519 -0.42435 0.61701 -0.01048 -0.28841 0.42077 -0.075991 -0.38083 0.57339 0.18044 -0.11781 0.35162 0.1622 0.55483 0.14 0.2321 -0.20205 0.60227 -0.15379 0.21907 0.28405 0.011906 0.10622 0.5067 -0.43201 -0.40887 -0.17819 0.22042 1.0775 -0.39381 -0.35828 0.36302 0.14872 0.035555 -0.030339 -0.11273 0.023382 0.15904 -0.14389 -0.11754 -0.63655 -0.12197 0.043809 0.14716 0.07375 -0.21358 -0.62249 0.14386\n",
            "in -0.10272 0.3041 -0.13577 -0.27979 -0.40926 -0.26553 0.10492 -0.044101 0.062731 -0.0416 0.35588 0.40757 -0.14295 -0.036534 0.42512 0.014823 0.00030443 0.2915 -0.20416 -0.10039 0.30767 3.1815 0.045614 0.094457 0.25545 0.27528 -0.29939 0.045123 0.44681 0.015012 -0.10785 -0.38988 -0.20562 0.26306 -0.018163 -0.14244 -0.5661 -0.12168 0.28749 -0.30581 -0.4482 -0.15317 -0.19445 0.35335 -0.015209 0.23061 0.13566 -0.26385 0.066084 0.16075 0.12168 0.72758 0.32453 0.82149 -0.13693 -0.2006 -0.097958 -0.15446 -0.38003 0.15699 0.041498 -0.22766 -0.40033 0.25514 0.13092 0.24261 -0.48639 -0.27622 -0.21293 -0.11668 0.014564 0.21658 0.19006 0.40863 0.48486 0.4037 0.20366 -0.096563 0.19522 -0.16715 -0.31923 -0.35499 -0.34792 0.59981 -0.046506 -0.27371 0.013404 -0.36558 0.69315 -0.2407 -0.0137 0.22596 0.21897 0.010207 -0.23484 -0.36304 0.1029 -0.4278 0.28864 -0.43645 -0.083785 0.1183 0.20385 0.40474 -0.079155 -0.12931 0.077845 1.2303 -0.55546 0.1562 0.0063933 -0.46652 0.013173 0.52646 -0.23626 0.013833 0.10002 0.090947 -0.25318 -0.64795 0.063422 0.74095 0.2902 0.22642 0.33915 -0.80488 0.21889 0.19193 0.05539 -0.39976 0.0094308 0.26978 0.63166 -0.41242 0.20485 0.33116 0.11562 -0.45671 -0.48083 0.46172 0.27319 0.243 0.12328 0.2307 1.2257 0.037079 0.23077 -0.31092 -0.099628 0.41876 -0.093834 -0.24741 -0.49863 -0.74542 0.16518 0.069734 0.066691 -0.092037 0.21124 -0.28236 0.20825 -0.17163 -0.32025 -0.27537 -0.30774 0.18184 -0.02626 -0.062733 -0.43666 0.57954 -0.32348 -0.13457 0.38565 -0.30198 0.26197 -0.10034 -0.146 -0.3417 0.16671 -0.23599 1.2467 -0.0059839 -0.56967 0.5264 -0.21024 -0.29861 -0.293 0.15889 0.17254 -0.0023984 0.071749 0.053166 -0.23429 -0.084927 0.15539 0.4182 -0.15216 0.36951 0.19039 -0.12266\n",
            "a 0.24169 -0.34534 -0.22307 -1.2907 0.25285 -0.55128 -0.080336 -0.0081767 0.31136 -0.45101 0.24661 0.36441 0.94336 -0.03542 0.78048 -0.39765 0.31125 -0.17743 -0.41989 -0.37815 0.6723 3.1716 0.032496 -0.03164 0.58068 -0.44458 -0.055612 0.18052 0.28572 0.09587 0.21437 0.049731 0.1872 0.11914 0.027408 -0.80608 -0.30835 -0.89737 -0.19772 0.026741 -0.38765 0.11659 -0.2011 0.20101 -0.079133 -0.050954 0.0060189 0.3347 -0.21118 0.074042 -0.28141 -0.059615 -0.35296 0.64748 0.053908 -0.31376 -0.36622 -0.27755 0.022676 0.048811 0.14312 -0.1858 -0.56964 -0.54119 0.18616 0.18854 0.27521 -0.17835 -0.37438 0.12109 0.001861 -0.0092127 0.10186 0.098081 -0.37245 0.66415 0.057366 -0.43845 -0.40525 -0.55959 -0.11343 -0.54987 -0.26321 -0.28471 0.14411 0.1036 -0.32198 -0.2153 0.98668 -0.41937 0.3119 0.3338 0.16018 0.33137 -0.025494 -0.03788 -0.12048 -0.12175 0.094766 0.26158 0.029931 -0.29625 0.43401 -0.036536 -0.42852 -0.39638 -0.24973 1.1018 -0.22812 0.24324 0.083857 -0.48881 -0.21316 0.040249 -0.40516 -0.12411 -0.19728 -0.73696 -0.44582 -0.44992 -0.073707 -0.16454 0.16011 -0.41952 0.41417 -0.57277 0.51367 0.081118 0.029288 0.35309 -0.10803 0.13702 0.38828 -0.28813 0.68203 0.17412 -0.08854 -0.29785 -0.28455 0.1357 0.15232 0.22037 0.68812 -0.131 1.8197 -0.45153 0.39553 -0.60817 0.33698 0.1109 -0.28476 0.30461 -0.21606 -0.058111 0.44172 -0.24231 -0.12758 -0.048793 -0.15495 -0.85491 0.092912 -0.060809 0.029073 -0.38735 -0.070853 -0.65975 -0.38157 0.5017 -0.7356 0.41521 0.21328 -0.33779 0.66902 0.42486 -0.12148 -0.010626 0.12745 -0.13561 0.23423 0.3511 1.2841 0.12982 0.21357 0.32857 0.16567 -0.21458 -0.44275 0.3285 0.18001 0.064865 -0.3588 -0.014226 0.31125 -0.22049 0.032829 0.38525 -0.10512 0.27801 -0.10171 -0.071521\n",
            "\" 0.0010318 0.31201 -0.59768 -0.12583 -0.27524 0.29145 -0.30431 0.037122 0.94468 0.088085 -0.096273 0.40542 -0.6524 0.37716 0.53001 -0.30819 -0.27478 0.81041 0.53635 0.08759 0.35288 2.8857 -0.12505 -0.035968 0.1355 -0.29932 0.56154 -0.59429 -0.34991 0.68559 -0.11537 0.088894 -0.29829 -0.20768 0.6911 0.068548 -0.50814 -0.97722 0.035782 -0.54053 -0.16178 0.47542 -0.71652 0.31939 -0.049291 0.32565 0.5551 -0.42967 1.0137 0.30304 0.44503 0.46987 0.074292 -0.35762 -0.13736 -0.16066 -0.28606 0.00012358 -0.043422 -0.36702 0.40895 -0.40467 -0.51635 0.28044 -0.27625 -0.20352 0.084837 0.078145 0.32895 0.20482 0.17551 -0.2309 -0.066328 0.46467 -0.38932 -0.23018 -0.098122 -0.12376 -0.028503 0.040342 0.71158 -0.27804 0.10137 0.51113 -0.42648 -0.12535 -0.39139 0.29972 0.1868 -0.58113 0.38192 0.1654 0.33566 -0.47696 -0.24135 -0.33114 0.34815 -0.087061 -0.16406 -0.1023 0.53301 0.45604 0.33281 -0.33851 0.30248 -0.15048 -0.33033 0.6668 -0.28609 1.0374 -0.70909 -0.084268 0.47584 -0.16125 0.19906 0.51991 0.026676 -0.25567 -0.32363 0.13236 0.54006 0.093419 0.12268 -0.62967 0.00074921 -0.53441 0.25609 0.39963 0.80527 -0.41176 0.18955 0.024526 -0.20222 0.33781 0.007872 -0.64424 -0.5309 0.027875 0.088964 0.29687 -0.038186 0.77967 -0.069213 -0.58387 1.1816 0.60791 -0.4021 -0.32223 -0.071283 -0.022764 -0.46393 0.99797 -0.15308 0.4712 0.73921 -0.12487 -0.38275 -0.39598 0.12852 -0.4951 0.19752 -0.25436 0.16616 -0.18135 0.16374 -0.16194 -0.32013 -0.33111 0.53662 0.53301 -0.32166 -0.64362 1.0576 -0.18019 -0.40932 -0.16084 -1.0094 0.22972 0.5431 0.05891 1.7502 -0.19753 -0.05401 0.016083 -0.55523 -0.20231 -0.32613 -0.38783 0.61428 -0.11216 0.42319 -0.44729 -0.35638 -0.32698 -0.12662 -0.28858 0.08092 0.14493 0.052563 0.75007\n",
            "'s -0.0059614 0.45148 0.0045495 0.020727 0.53877 0.49453 -0.35369 -0.056286 0.057851 -0.2045 -0.3064 0.37904 0.26388 0.36036 0.68715 0.11629 -0.57005 0.084364 -0.67184 0.21706 0.60084 3.1461 0.21839 0.1883 -0.011606 0.7028 -0.054734 -0.57602 -0.50561 0.13275 -0.37349 -0.22315 0.18934 -0.38835 -0.44616 0.25078 -0.24067 -0.27303 -0.63587 0.071991 -0.30948 -0.65413 -0.075834 0.40565 -0.28402 0.44169 -0.22619 0.10845 -0.015489 -0.30989 -0.02178 -0.11869 0.17083 -0.099277 0.30043 0.18093 -0.25603 0.084124 0.052387 0.61726 0.214 -0.22772 -0.87764 -0.14982 -0.23043 -0.00035754 -0.32101 0.027185 0.21575 0.36466 0.6246 -0.12043 0.05141 0.91292 0.18761 0.93069 -0.35316 -0.17359 -0.29801 -0.47032 -0.30814 -0.030579 0.0010451 -0.4248 0.025234 0.10384 -0.48836 -0.052485 0.40014 -0.7495 -0.13414 0.4474 -0.29949 0.09747 -0.55787 0.20784 0.07845 -0.018413 0.51101 -0.081727 -0.12922 0.26656 0.019702 0.32468 -0.0065269 -0.61234 0.16835 1.4625 -0.69953 -0.4955 -0.14897 -0.31528 -0.84419 0.015958 -0.32832 0.17431 -0.17892 0.19392 -0.18366 0.025364 0.26547 0.44295 0.38296 -0.087653 0.72418 -0.48724 0.014929 -0.2459 -0.026036 0.13949 0.12917 -0.29052 0.24795 -0.74504 -0.12584 0.66134 0.14745 0.020824 -0.17371 -0.10235 -0.38495 0.85243 0.34448 0.46187 1.2913 0.085984 -0.13995 -0.77678 0.33022 0.4462 0.4717 0.11727 0.61142 0.39587 0.34127 -0.084882 -0.18584 0.076045 -0.33183 0.052621 0.66403 -0.19629 -0.066911 0.20812 0.29366 0.3302 -0.21909 -0.27987 0.11026 0.47563 0.49742 0.071567 0.19419 -0.13688 -0.069569 0.49701 -0.84327 -0.44757 0.50253 0.60596 0.86543 0.47559 -0.0093512 0.00081187 -0.59952 -0.12317 -0.30361 0.17132 0.82369 0.2679 0.33455 0.35521 -0.56247 0.37289 0.51554 -0.0036403 0.076358 0.39947 0.29621 0.053627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWnF4e2ddg-P",
        "outputId": "cbc92deb-d208-4e4d-fcf5-29dc8f61589c"
      },
      "source": [
        "glove_vocab = ['UNK', 'PAD']\n",
        "glove_embeddings_dict = dict()\n",
        "vector_size = 200\n",
        "\n",
        "glove_embeddings_dict[0] = torch.zeros(vector_size)\n",
        "glove_embeddings_dict[1] = torch.zeros(vector_size)\n",
        "\n",
        "word2id = {word: id_ for id_, word in enumerate(vocab)}\n",
        "idx = 2\n",
        "\n",
        "with open(\"glove.6B.100d.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "    line = f.readline()\n",
        "    while line is not None:\n",
        "        values = line.strip().split()\n",
        "        if not values:\n",
        "            break\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "\n",
        "        glove_vocab.append(word)\n",
        "        glove_embeddings_dict[word] = torch.FloatTensor(vector)\n",
        "        idx += 1\n",
        "        line = f.readline()\n",
        "if 'UNK' in glove_vocab:\n",
        "    print(\"UNK\")\n",
        "if 'PAD' in glove_vocab:\n",
        "    print(\"PAD\")\n",
        "print(len(glove_vocab))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UNK\n",
            "PAD\n",
            "400002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb43ERKlhqEg",
        "outputId": "0ecd2680-f2bd-416f-f911-61bd7b211c75"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtHwZ_fxhzlQ"
      },
      "source": [
        "import pickle\n",
        "\n",
        "filename = '/content/drive/My Drive/Kaist_ÏÑùÏÇ¨_2021_Ïó¨Î¶Ñ_AI605_Assignment/glove_vectors.pkl'\n",
        "pickle.dump({'glove_embeddings_dict' : glove_embeddings_dict, 'glove_vocab' : glove_vocab} , open(filename, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-mcmP5llBB0"
      },
      "source": [
        "import pickle\n",
        "\n",
        "filename = '/content/drive/My Drive/Kaist_ÏÑùÏÇ¨_2021_Ïó¨Î¶Ñ_AI605_Assignment/glove_vectors.pkl'\n",
        "\n",
        "glove_data = dict()\n",
        "with open(filename, 'rb') as f:\n",
        "    glove_data = pickle.load(f)\n",
        "\n",
        "glove_embeddings_dict = glove_data['glove_embeddings_dict']\n",
        "glove_vocab = glove_data['glove_vocab']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "pDScRiRWTQuk",
        "outputId": "ebbb0598-5eff-4337-d516-899f1157f99e"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "filename = '/content/drive/My Drive/Kaist_ÏÑùÏÇ¨_2021_Ïó¨Î¶Ñ_AI605_Assignment/glove_vectors.pkl'\n",
        "train_fname = 'glue_data/SST-2/train.tsv'\n",
        "dev_fname = 'glue_data/SST-2/dev.tsv'\n",
        "\n",
        "vocab, word2id = make_reduced_vocab(train_fname)\n",
        "glove_vocab_size = len(glove_vocab)\n",
        "\n",
        "vector_size = 200\n",
        "\n",
        "embedding_matrix = torch.zeros((len(vocab), vector_size))\n",
        "for i, word in enumerate(vocab):\n",
        "    temp = glove_embeddings_dict.get(word)\n",
        "    if temp is not None:\n",
        "        embedding_matrix[i] = temp\n",
        "    elif i > 0:\n",
        "        embedding_matrix[i] = torch.rand(vector_size)\n",
        "\n",
        "\n",
        "# One LSTM layer and classification with glove.\n",
        "class LSTMNode(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(LSTMNode, self).__init__()\n",
        "\n",
        "        self.W_ft = torch.nn.Linear(input_size + hidden_size, hidden_size) # forget gate\n",
        "        self.W_it = torch.nn.Linear(input_size + hidden_size, hidden_size) # input gate\n",
        "        self.W_ot = torch.nn.Linear(input_size + hidden_size, hidden_size) # output gate\n",
        "        self.W_ct = torch.nn.Linear(input_size + hidden_size, hidden_size) # cell state\n",
        "        self.W_ht = torch.nn.Linear(hidden_size, hidden_size) # hidden state\n",
        "        self.W_h2y = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "    \n",
        "    def forward(self, input, hidden, cell, src_batch_sizes):\n",
        "        h_t = hidden.squeeze(0)\n",
        "        c_t = cell.squeeze(0)\n",
        "        h_last = h_t\n",
        "        c_last = c_t\n",
        "        y_list = list()\n",
        "        batch_size = int(src_batch_sizes[0])\n",
        "\n",
        "        for i, batch in enumerate(src_batch_sizes):\n",
        "            batch = int(batch)\n",
        "            token = input[i][:batch, :].clone()\n",
        "            combined_input = torch.cat([token, h_t[:batch, :]], dim=1)\n",
        "\n",
        "            f_t = self.sigmoid(self.W_ft(combined_input))\n",
        "            i_t = self.sigmoid(self.W_it(combined_input))\n",
        "            o_t = self.sigmoid(self.W_ot(combined_input))\n",
        "            c_hat_t = self.tanh(self.W_ct(combined_input))\n",
        "            \n",
        "            c_last[:batch, :] = c_t = f_t*c_t[:batch, :].clone() + i_t*c_hat_t\n",
        "            h_last[:batch, :] = h_t = o_t*self.tanh(c_t)\n",
        "\n",
        "            y_t = self.W_h2y(h_t)\n",
        "            y_list.append(nn.ZeroPad2d((0, 0, batch_size - batch, 0))(y_t)) # Zero-padding\n",
        "        y = torch.stack(y_list, dim=0)\n",
        "\n",
        "        return y, c_last.unsqueeze(0), h_last.unsqueeze(0)\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, n_layers, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix)\n",
        "        \n",
        "        # nn.LSTM\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, dropout=dropout)\n",
        "\n",
        "        # my LSTM\n",
        "        # self.lstm = LSTMNode(input_size=embedding_dim, hidden_size=hidden_dim)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * n_layers, 2, bias=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_tensor, src_seq_lens, hidden, cell):\n",
        "        emb = self.embedding(input_tensor) # emb.shape = batch * len * hidden\n",
        "        emb = self.dropout(emb)\n",
        "        emb = emb.transpose(0, 1) # emb.shape = len * batch * hidden\n",
        "\n",
        "        # nn.LSTM\n",
        "        packed = pack_padded_sequence(emb, src_seq_lens.tolist(), batch_first=False)\n",
        "        outs, (hidden, cell) = self.lstm(packed) # h0 = zero initialization\n",
        "        outs, out_lens = pad_packed_sequence(outs, batch_first=False)\n",
        "\n",
        "        # my LSTM\n",
        "        # print(hidden.shape, cell.shape)\n",
        "        # print(\"input shape : \", emb.shape, hidden.shape) # len * batch * emb, 1 * batch * hidden\n",
        "        # src_batch_sizes = seqs2batches(src_seq_lens)\n",
        "        # outs, cell, hidden = self.lstm(emb, hidden, cell, src_batch_sizes) # h0 = zero initialization\n",
        "        # print(\"output shape : \", outs.shape, cell.shape, hidden.shape) # len * batch * hidden, 1 * batch * hidden, 1 * batch * hidden\n",
        "\n",
        "        hidden = hidden.transpose(0, 1)\n",
        "        hidden = hidden.contiguous().view(hidden.shape[0], -1)\n",
        "\n",
        "        hidden = self.dropout(hidden)\n",
        "        logits = self.fc(hidden)\n",
        "        # logits = self.fc(outs[-1])\n",
        "        return logits\n",
        "\n",
        "\n",
        "def seqs2batches(src_seq_lens):\n",
        "    \"\"\"\n",
        "    This is same with batches2seqs() \n",
        "    \"\"\"\n",
        "    assert src_seq_lens is not None\n",
        "    assert src_seq_lens[-1] > 0\n",
        "    src_batch_sizes = torch.zeros(int(src_seq_lens[0]))\n",
        "    pointer = int(src_seq_lens[0]) - 1\n",
        "    for i, seq_len in enumerate(src_seq_lens.tolist() + [0]):\n",
        "        while seq_len <= pointer:\n",
        "            src_batch_sizes[pointer] = i\n",
        "            pointer -= 1\n",
        "    return src_batch_sizes\n",
        "\n",
        "\n",
        "# Training the baseline model on SST-2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "embedding_dim = vector_size # usually bigger, e.g. 128\n",
        "hidden_dim = 512\n",
        "n_layers = 1\n",
        "dropout = 0.5\n",
        "rnnmodel = LSTMModel(embedding_dim, hidden_dim, n_layers, dropout).to(device)\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(rnnmodel.parameters(), lr=1e-1)\n",
        "optimizer = torch.optim.Adam(rnnmodel.parameters(), lr=2e-4)\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0.0\n",
        "    train_data_num = 0\n",
        "    for i, (source, src_seq_lens, target) in enumerate(train_data_loader):\n",
        "        train_tensor_src = torch.LongTensor(source).to(device)\n",
        "        train_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "\n",
        "        sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "        train_sorted_src = train_tensor_src[sorted_indices]\n",
        "        train_sorted_tgt = train_tensor_tgt[sorted_indices]\n",
        "\n",
        "        # print(src_seq_lens.shape, src_batch_sizes.shape, seqs2batches(src_batch_sizes).shape)\n",
        "        h0 = torch.zeros(1, train_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "        c0 = torch.zeros(1, train_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "        logits = rnnmodel(train_sorted_src, sorted_seq_lens, h0, c0)\n",
        "\n",
        "        # print(train_tensor_src.shape, train_tensor_tgt.shape, logits.shape)\n",
        "\n",
        "        optimizer.zero_grad() # reset process\n",
        "        loss = cel(logits, train_sorted_tgt) # Loss, a.k.a L\n",
        "        loss.backward() # compute gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), 5) # gradent clipping\n",
        "        optimizer.step() # update parameters\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, train_preds = torch.max(logits, 1)\n",
        "        train_accuracy += (train_preds == train_sorted_tgt).sum().float()\n",
        "\n",
        "        train_data_num += train_sorted_tgt.shape[0]\n",
        "\n",
        "    print('train:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(train_loss / train_data_num), \n",
        "                'acc =', '{:.6f}'.format(train_accuracy / train_data_num))\n",
        "    \n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0\n",
        "            valid_accuracy = 0.0\n",
        "            valid_data_num = 0\n",
        "            for i, (source, src_seq_lens, target) in enumerate(dev_data_loader):\n",
        "                dev_tensor_src = torch.LongTensor(source).to(device)\n",
        "                dev_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "            \n",
        "                sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "                dev_sorted_src = dev_tensor_src[sorted_indices]\n",
        "                dev_sorted_tgt = dev_tensor_tgt[sorted_indices]\n",
        "\n",
        "                h0 = torch.zeros(1, dev_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "                c0 = torch.zeros(1, dev_sorted_src.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "                logits = rnnmodel(dev_sorted_src, sorted_seq_lens, h0, c0)\n",
        "\n",
        "                loss = cel(logits, dev_sorted_tgt) # Loss, a.k.a L\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                _, valid_preds = torch.max(logits, 1)\n",
        "                valid_accuracy += (valid_preds == dev_sorted_tgt).sum().float()\n",
        "\n",
        "                valid_data_num += dev_sorted_tgt.shape[0]\n",
        "                \n",
        "            print('valid:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(valid_loss / valid_data_num), \n",
        "                'acc =', '{:.6f}'.format(valid_accuracy / valid_data_num))\n",
        "        \n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train:: Epoch: 0001 cost = 0.005226, acc = 0.589496\n",
            "valid:: Epoch: 0001 cost = 0.005301, acc = 0.606651\n",
            "train:: Epoch: 0002 cost = 0.005099, acc = 0.612199\n",
            "valid:: Epoch: 0002 cost = 0.005313, acc = 0.618119\n",
            "train:: Epoch: 0003 cost = 0.005011, acc = 0.628131\n",
            "valid:: Epoch: 0003 cost = 0.005222, acc = 0.639908\n",
            "train:: Epoch: 0004 cost = 0.004844, acc = 0.650715\n",
            "valid:: Epoch: 0004 cost = 0.005139, acc = 0.644495\n",
            "train:: Epoch: 0005 cost = 0.004574, acc = 0.685741\n",
            "valid:: Epoch: 0005 cost = 0.004743, acc = 0.700688\n",
            "train:: Epoch: 0006 cost = 0.004331, acc = 0.709409\n",
            "valid:: Epoch: 0006 cost = 0.004617, acc = 0.719037\n",
            "train:: Epoch: 0007 cost = 0.004141, acc = 0.723648\n",
            "valid:: Epoch: 0007 cost = 0.004763, acc = 0.730505\n",
            "train:: Epoch: 0008 cost = 0.003944, acc = 0.744480\n",
            "valid:: Epoch: 0008 cost = 0.004847, acc = 0.685780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c8256f2923ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), 5) # gradent clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCiT8KLFml2Q"
      },
      "source": [
        "train:: Epoch: 0001 cost = 0.005256, acc = 0.581271\n",
        "valid:: Epoch: 0001 cost = 0.005354, acc = 0.606651\n",
        "train:: Epoch: 0002 cost = 0.005129, acc = 0.609259\n",
        "valid:: Epoch: 0002 cost = 0.005264, acc = 0.595183\n",
        "train:: Epoch: 0003 cost = 0.005034, acc = 0.625043\n",
        "valid:: Epoch: 0003 cost = 0.005212, acc = 0.626147\n",
        "train:: Epoch: 0004 cost = 0.004888, acc = 0.646958\n",
        "valid:: Epoch: 0004 cost = 0.004962, acc = 0.662844\n",
        "train:: Epoch: 0005 cost = 0.004645, acc = 0.672972\n",
        "valid:: Epoch: 0005 cost = 0.004899, acc = 0.680046\n",
        "train:: Epoch: 0006 cost = 0.004435, acc = 0.697457\n",
        "valid:: Epoch: 0006 cost = 0.004754, acc = 0.682339\n",
        "train:: Epoch: 0007 cost = 0.004286, acc = 0.715927\n",
        "valid:: Epoch: 0007 cost = 0.004898, acc = 0.692661\n",
        "train:: Epoch: 0008 cost = 0.004149, acc = 0.727672\n",
        "valid:: Epoch: 0008 cost = 0.004482, acc = 0.730505\n",
        "train:: Epoch: 0009 cost = 0.004053, acc = 0.735467\n",
        "valid:: Epoch: 0009 cost = 0.004775, acc = 0.716743\n",
        "train:: Epoch: 0010 cost = 0.003946, acc = 0.744599\n",
        "valid:: Epoch: 0010 cost = 0.004714, acc = 0.712156\n",
        "train:: Epoch: 0011 cost = 0.003872, acc = 0.751192\n",
        "valid:: Epoch: 0011 cost = 0.004655, acc = 0.716743\n",
        "train:: Epoch: 0012 cost = 0.003791, acc = 0.759150\n",
        "valid:: Epoch: 0012 cost = 0.004669, acc = 0.719037\n",
        "train:: Epoch: 0013 cost = 0.003713, acc = 0.766322\n",
        "valid:: Epoch: 0013 cost = 0.004641, acc = 0.728211\n",
        "train:: Epoch: 0014 cost = 0.003638, acc = 0.769959\n",
        "valid:: Epoch: 0014 cost = 0.005130, acc = 0.708716\n",
        "train:: Epoch: 0015 cost = 0.003591, acc = 0.775854\n",
        "valid:: Epoch: 0015 cost = 0.004853, acc = 0.722477\n",
        "train:: Epoch: 0016 cost = 0.003537, acc = 0.779195\n",
        "valid:: Epoch: 0016 cost = 0.004530, acc = 0.748853\n",
        "train:: Epoch: 0017 cost = 0.003468, acc = 0.786070\n",
        "valid:: Epoch: 0017 cost = 0.004969, acc = 0.729358\n",
        "train:: Epoch: 0018 cost = 0.003400, acc = 0.789143\n",
        "valid:: Epoch: 0018 cost = 0.004735, acc = 0.707569\n",
        "train:: Epoch: 0019 cost = 0.003371, acc = 0.791029\n",
        "valid:: Epoch: 0019 cost = 0.004883, acc = 0.738532\n",
        "train:: Epoch: 0020 cost = 0.003312, acc = 0.795231\n",
        "valid:: Epoch: 0020 cost = 0.005051, acc = 0.705275\n",
        "train:: Epoch: 0021 cost = 0.003258, acc = 0.799774\n",
        "valid:: Epoch: 0021 cost = 0.004609, acc = 0.738532\n",
        "train:: Epoch: 0022 cost = 0.003251, acc = 0.801333\n",
        "valid:: Epoch: 0022 cost = 0.005300, acc = 0.716743\n",
        "train:: Epoch: 0023 cost = 0.003186, acc = 0.806397\n",
        "valid:: Epoch: 0023 cost = 0.005136, acc = 0.732798\n",
        "train:: Epoch: 0024 cost = 0.003164, acc = 0.808193\n",
        "valid:: Epoch: 0024 cost = 0.004915, acc = 0.748853\n",
        "train:: Epoch: 0025 cost = 0.003162, acc = 0.807154\n",
        "valid:: Epoch: 0025 cost = 0.005657, acc = 0.701835\n",
        "train:: Epoch: 0026 cost = 0.003094, acc = 0.812202\n",
        "valid:: Epoch: 0026 cost = 0.004950, acc = 0.754587\n",
        "train:: Epoch: 0027 cost = 0.003060, acc = 0.815201\n",
        "valid:: Epoch: 0027 cost = 0.005012, acc = 0.738532\n",
        "train:: Epoch: 0028 cost = 0.003032, acc = 0.816686\n",
        "valid:: Epoch: 0028 cost = 0.005080, acc = 0.724771\n",
        "train:: Epoch: 0029 cost = 0.002989, acc = 0.820680\n",
        "valid:: Epoch: 0029 cost = 0.004741, acc = 0.735092\n",
        "train:: Epoch: 0030 cost = 0.002963, acc = 0.822328\n",
        "valid:: Epoch: 0030 cost = 0.006050, acc = 0.693807\n",
        "train:: Epoch: 0031 cost = 0.002931, acc = 0.823368\n",
        "valid:: Epoch: 0031 cost = 0.005211, acc = 0.729358\n",
        "train:: Epoch: 0032 cost = 0.002881, acc = 0.826367\n",
        "valid:: Epoch: 0032 cost = 0.005319, acc = 0.717890\n",
        "train:: Epoch: 0033 cost = 0.002865, acc = 0.826575\n",
        "valid:: Epoch: 0033 cost = 0.005474, acc = 0.737385\n",
        "train:: Epoch: 0034 cost = 0.002856, acc = 0.830049\n",
        "valid:: Epoch: 0034 cost = 0.005913, acc = 0.728211\n",
        "train:: Epoch: 0035 cost = 0.002807, acc = 0.833197\n",
        "valid:: Epoch: 0035 cost = 0.005829, acc = 0.740826\n",
        "train:: Epoch: 0036 cost = 0.002784, acc = 0.833494\n",
        "valid:: Epoch: 0036 cost = 0.005323, acc = 0.751147\n",
        "train:: Epoch: 0037 cost = 0.002759, acc = 0.836152\n",
        "valid:: Epoch: 0037 cost = 0.005726, acc = 0.730505\n",
        "train:: Epoch: 0038 cost = 0.002736, acc = 0.836701\n",
        "valid:: Epoch: 0038 cost = 0.005862, acc = 0.720183\n",
        "train:: Epoch: 0039 cost = 0.002696, acc = 0.840116\n",
        "valid:: Epoch: 0039 cost = 0.005092, acc = 0.754587\n",
        "train:: Epoch: 0040 cost = 0.002675, acc = 0.841022\n",
        "valid:: Epoch: 0040 cost = 0.005334, acc = 0.753440\n",
        "train:: Epoch: 0041 cost = 0.002658, acc = 0.843086\n",
        "valid:: Epoch: 0041 cost = 0.005361, acc = 0.747706\n",
        "train:: Epoch: 0042 cost = 0.002640, acc = 0.842982\n",
        "valid:: Epoch: 0042 cost = 0.005408, acc = 0.740826\n",
        "train:: Epoch: 0043 cost = 0.002625, acc = 0.845031\n",
        "valid:: Epoch: 0043 cost = 0.005344, acc = 0.741972\n",
        "train:: Epoch: 0044 cost = 0.002600, acc = 0.845714\n",
        "valid:: Epoch: 0044 cost = 0.005625, acc = 0.739679\n",
        "train:: Epoch: 0045 cost = 0.002575, acc = 0.849812\n",
        "valid:: Epoch: 0045 cost = 0.006035, acc = 0.727064\n",
        "train:: Epoch: 0046 cost = 0.002528, acc = 0.850451\n",
        "valid:: Epoch: 0046 cost = 0.005553, acc = 0.719037\n",
        "train:: Epoch: 0047 cost = 0.002527, acc = 0.850302\n",
        "valid:: Epoch: 0047 cost = 0.005731, acc = 0.735092\n",
        "train:: Epoch: 0048 cost = 0.002498, acc = 0.852544\n",
        "valid:: Epoch: 0048 cost = 0.005318, acc = 0.725917\n",
        "train:: Epoch: 0049 cost = 0.002487, acc = 0.854667\n",
        "valid:: Epoch: 0049 cost = 0.005767, acc = 0.731651\n",
        "train:: Epoch: 0050 cost = 0.002475, acc = 0.855113\n",
        "valid:: Epoch: 0050 cost = 0.005406, acc = 0.759174"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FKuB_7aI6fk"
      },
      "source": [
        "Problem 5.2 (bonus) (10 points) You can go one step further by using word vectors obtained from pretrained language models. Can you import the word embeddings from bert-base-uncased model (via Hugging Face's transformers: https://huggingface.co/transformers/pretrained_models.html) into your model and improve it further? Report the accuracy on the dev data here. If the score is now higher, explain where the improvement is coming from.\n",
        "\n",
        "**Answer 5.2** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yTBi2PrTTo_"
      },
      "source": [
        "."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}