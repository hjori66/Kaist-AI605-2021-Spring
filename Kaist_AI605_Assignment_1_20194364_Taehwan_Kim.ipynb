{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaist AI605 Assignment 1_20194364 Taehwan Kim.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjori66/Kaist-AI605-2021-Spring/blob/main/Kaist_AI605_Assignment_1_20194364_Taehwan_Kim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbGnNWI1lRy_"
      },
      "source": [
        "# KAIST AI605 Assignment 1: Text Classification with RNNs\n",
        "Authors: Hyeong-Gwon Hong (honggudrnjs@kaist.ac.kr) and Minjoon Seo (minjoon@kaist.ac.kr)\n",
        "\n",
        "**Due Date:** March 31 (Wed) 11:00pm, 2021\n",
        "\n",
        "## Assignment Objectives\n",
        "- Verify theoretically and empirically why gating mechanism (LSTM, GRU) helps in Recurrent Neural Networks (RNNs)\n",
        "- Design an LSTM-based text classification model from scratch using PyTorch.\n",
        "- Apply the classification model to a popular classification task, Stanford Sentiment Treebank v2 (SST-2).\n",
        "- Achieve higher accuracy by applying common machine learning strategies, including Dropout.\n",
        "- Utilize pretrained word embedding (e.g. GloVe) to leverage self-supervision over a large text corpus.\n",
        "- (Bonus) Use Hugging Face library (`transformers`) to leverage self-supervision via large language models.\n",
        "\n",
        "## Your Submission\n",
        "Your submission will be a link to a Colab notebook that has all written answers and is fully executable. You will submtit your assignment via KLMS. Use in-line LaTeX (see below) for mathematical expressions. Collaboration among students is allowed but it is not a group assignment so make sure your answer and code are your own. Make sure to mention your collaborators in yoru assignment with their names and their student ids.\n",
        "\n",
        "## Grading\n",
        "The entire assignment is out of 100 points. There are four bonus questions with 10 points each (two bonus questions added on Mar 19). Your final score can be higher than 100 points.\n",
        "\n",
        "\n",
        "## Environment\n",
        "You will only use Python 3.7 and PyTorch 1.8, which is already available on Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYxEp1XMpxem",
        "outputId": "3a696389-0272-4a24-b876-be38709d94cf"
      },
      "source": [
        "from platform import python_version\n",
        "import torch\n",
        "\n",
        "print(\"python\", python_version())\n",
        "print(\"torch\", torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python 3.7.10\n",
            "torch 1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB7xyzIgnnkA"
      },
      "source": [
        "## 1. Limitations of Vanilla RNNs\n",
        "In Lecture 04 and 05, we saw how RNNs suffer from exploding or vanishing gradients. We mathematically showed that, if the recurrent relation is\n",
        "$$ \\textbf{h}_t = \\sigma (\\textbf{V}\\textbf{h}_{t-1} + \\textbf{U}\\textbf{x}_t + \\textbf{b}) $$\n",
        "then\n",
        "$$ \\frac{\\partial \\textbf{h}_t}{\\partial \\textbf{h}_{t-1}} = \\text{diag}(\\sigma' (\\textbf{V}\\textbf{h}_{t-1} + \\textbf{U}\\textbf{x}_t + \\textbf{b}))\\textbf{V}$$\n",
        "so\n",
        "$$\\frac{\\partial \\textbf{h}_T}{\\partial \\textbf{h}_1} \\propto \\textbf{V}^{T-1}$$\n",
        "which means this term will be very close to zero if the norm of $\\bf{V}$ is smaller than 1 and really big otherwise.\n",
        "\n",
        "**Problem 1.1** *(10 points)* Explain how exploding gradient can be mitigated if we use gradient clipping.\n",
        "\n",
        "**Answer 1.1** The definition of the gradient clipping is followed.\n",
        "\n",
        "$$ \\begin{aligned}\n",
        "\\frac{\\partial \\textbf{h}}{\\partial \\theta} \\leftarrow &\\left\\{\\begin{array}{ll}\n",
        "\\frac{\\text { threshold }}{\\|\\hat{g}\\|} \\hat{g} & \\text { if }\\|\\hat{g}\\| \\geq \\text { threshold }\n",
        "\\\\\n",
        "\\hat{g} & \\text { otherwise }\n",
        "\\end{array}\\right\n",
        ".\\\\\n",
        "& \\text { where } \\hat{g}=\\frac{\\partial \\textbf{h}}{\\partial \\theta}\n",
        "\\end{aligned} $$\n",
        "\n",
        "If the gradient exploded, weights of the model can be NaN value (either overflow or underflow). So, rescaling the error derivative before propagating it backward through the network to update the weights can be one of the solution. If we do that, we can decrease the likelihood of an over or underflow.\n",
        "\n",
        "\n",
        "**Problem 1.2** *(10 points)* Explain how vanishing gradient can be mitigated if we use LSTM. See the Lecture 04 and 05 slides for the definition of LSTM.\n",
        "\n",
        "**Answer 1.2** The formulation of LSTM is followed.\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "f_{t} &=\\sigma_{g}\\left(W_{f} x_{t}+U_{f} h_{t-1}+b_{f}\\right) \\\\\n",
        "i_{t} &=\\sigma_{g}\\left(W_{i} x_{t}+U_{i} h_{t-1}+b_{i}\\right) \\\\\n",
        "o_{t} &=\\sigma_{g}\\left(W_{o} x_{t}+U_{o} h_{t-1}+b_{o}\\right) \\\\\n",
        "\\tilde{c}_{t} &=\\sigma_{c}\\left(W_{c} x_{t}+U_{c} h_{t-1}+b_{c}\\right) \\\\\n",
        "c_{t} &=f_{t} \\circ c_{t-1}+i_{t} \\circ \\tilde{c}_{t} \\\\\n",
        "h_{t} &=o_{t} \\circ \\sigma_{h}\\left(c_{t}\\right)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Then,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial c_{T}}{\\partial c_{t}}=\n",
        "\\frac{\\partial c_{T}}{\\partial c_{T-1}} * \n",
        "\\frac{\\partial c_{T-1}}{\\partial c_{T-2}} * \n",
        "\\ldots * \n",
        "\\frac{\\partial c_{t+1}}{\\partial c_{t}}\n",
        "$$\n",
        "and\n",
        "$$\n",
        "\\frac{\\partial c_{T}}{\\partial c_{t}}=\\prod_{i=t+1}^{T} f_{i}\n",
        "$$\n",
        "\n",
        "Now, $f_{i}$ is sigmoid function. so, it is larger than 0 and \"smaller than 1\". If $f_{i}$ was closed to 1, cell state ($c_{i}$) considers the long term memory. Otherwise, it doesn't consider the long term memory. This formulation mitigates the vanishing gradient. \n",
        "\n",
        "Similary, \n",
        "$$\n",
        "\\frac{\\partial c_{T}}{\\partial \\tilde{c}_{t}}=\\prod_{j=t+1}^{T} i_{j} \\text { and } \\frac{\\partial h_{T}}{\\partial h_{t}}\n",
        "$$\n",
        "mitigates the vanishing, too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0AmoAT3wA1J"
      },
      "source": [
        "## 2. Creating Vocabulary from Training Data\n",
        "Creating the vocabulary is the first step for every natural language processing model. In this section, you will use Stanford Sentiment Treebank v2, a popular dataset for sentiment classification, to create your vocabulary.\n",
        "\n",
        "### Obtaining SST-2 via GLUE\n",
        "General Language Understanding Evaluation (GLUE) benchmark is a collection of tools for evaluating the performance of models across a diverse set of existing natural language understanding (NLU) tasks. See GLUE website (https://gluebenchmark.com/) and the GLUE paper (https://openreview.net/pdf?id=rJ4km2R5t7) for more details. GLUE provides an easy way to access the datasets, including SST-2.\n",
        "You can download SST-2 dataset by following the steps below:\n",
        "\n",
        "1. Clone GitHub repository:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK0S_VTJxds4",
        "outputId": "4b14ea73-5f78-4b46-d142-e7f087e99b6b"
      },
      "source": [
        "!git clone https://github.com/nyu-mll/GLUE-baselines.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GLUE-baselines'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 891 (delta 1), reused 2 (delta 0), pack-reused 886\u001b[K\n",
            "Receiving objects: 100% (891/891), 1.48 MiB | 9.00 MiB/s, done.\n",
            "Resolving deltas: 100% (610/610), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8eWbt2yxb3H"
      },
      "source": [
        "2. Download SST-2 only:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6drFIvgxxjgI",
        "outputId": "7c209ee0-a87c-4e37-f409-7b3e8061fb27"
      },
      "source": [
        "%cd GLUE-baselines/\n",
        "!python download_glue_data.py --data_dir glue_data --tasks SST"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/GLUE-baselines\n",
            "Downloading and extracting SST...\n",
            "\tCompleted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAVQyYWkxib6"
      },
      "source": [
        "Your training, dev, and test data can be found at `glue_data/SST-2`. Note that each file is in a tsv format, where the first column is the sentence and the second column is the label (either 0 or 1, where 1 means positive sentiment). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElsgL-Piz7ck",
        "outputId": "6caec1ab-4d36-4965-fd93-5b2574209609"
      },
      "source": [
        "!head -10 glue_data/SST-2/train.tsv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence\tlabel\n",
            "hide new secretions from the parental units \t0\n",
            "contains no wit , only labored gags \t0\n",
            "that loves its characters and communicates something rather beautiful about human nature \t1\n",
            "remains utterly satisfied to remain the same throughout \t0\n",
            "on the worst revenge-of-the-nerds clichés the filmmakers could dredge up \t0\n",
            "that 's far too tragic to merit such superficial treatment \t0\n",
            "demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , personal film with an emotional wallop . \t1\n",
            "of saucy \t1\n",
            "a depressed fifteen-year-old 's suicidal poetry \t0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s0T6qk6x78s"
      },
      "source": [
        "**Problem 2.1** *(10 points)* Using space tokenizer, create the vocabulary for the training data and report the vocabulary size here. Make sure that you add an `UNK` token to the vocabulary to account for words (during inference time) that you haven't seen. See below for an example with a short text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOsxkEpyxTW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bcd6f53-b369-40f7-96cd-dc5220e4c307"
      },
      "source": [
        "# Space tokenization\n",
        "text = \"Hello world!\"\n",
        "tokens = text.split(' ')\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hello', 'world!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iCTn95_pK7i",
        "outputId": "d71e9dbe-8666-4a46-e24f-3f819536bf4d"
      },
      "source": [
        "# Constructing vocabulary with `UNK`\n",
        "vocab = ['UNK'] + list(set(text.split(' ')))\n",
        "word2id = {word: id_ for id_, word in enumerate(vocab)}\n",
        "print(vocab)\n",
        "print(word2id['Hello'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['UNK', 'world!', 'Hello']\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsfTJ1_XFDxR",
        "outputId": "af95935b-1842-49af-b18d-e35668be2788"
      },
      "source": [
        "# Constructing vocabulary using space tokenizer and 'UNK'\n",
        "import pandas as pd\n",
        "\n",
        "def make_vocab(fname):\n",
        "    df = pd.read_csv(fname, sep='\\t')\n",
        "    tokens = list()\n",
        "    token_occur = dict()\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        for token in row['sentence'].strip().split(' '):\n",
        "            if token in token_occur:\n",
        "                token_occur[token] += 1\n",
        "            else:\n",
        "                token_occur[token] = 1\n",
        "                tokens.append(token)\n",
        "\n",
        "    vocab = ['UNK'] + tokens\n",
        "    return vocab\n",
        "\n",
        "vocab = make_vocab('glue_data/SST-2/train.tsv')\n",
        "print(\"The size of the vocabulary is \", len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of the vocabulary is  14817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqVv57zy1OZ0"
      },
      "source": [
        "**Problem 2.2** *(10 points)* Using all words in the training data will make the vocabulary very big. Reduce its size by only including words that occur at least 2 times. How does the size of the vocabulary change?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq1GvSHXJGEF",
        "outputId": "b3e723df-d13a-450a-aea0-b3d522fdd331"
      },
      "source": [
        "# Constructing reduced vocabulary (occur at least twice)\n",
        "import pandas as pd\n",
        "\n",
        "def make_reduced_vocab(fname, min_occur=0):\n",
        "    df = pd.read_csv(fname, sep='\\t')\n",
        "    # tokens = list()\n",
        "    token_occur = dict()\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        for token in row['sentence'].strip().split(' '):\n",
        "            if token in token_occur:\n",
        "                token_occur[token] += 1\n",
        "            else:\n",
        "                token_occur[token] = 1\n",
        "                # tokens.append(token)\n",
        "\n",
        "    vocab = ['UNK', 'PAD']\n",
        "    for token, occur in token_occur.items():\n",
        "        if occur >= min_occur:\n",
        "            vocab.append(token)\n",
        "    word2id = {word: id_ for id_, word in enumerate(vocab)}\n",
        "    return vocab, word2id\n",
        "\n",
        "train_fname = 'glue_data/SST-2/train.tsv'\n",
        "dev_fname = 'glue_data/SST-2/dev.tsv'\n",
        "vocab, word2id = make_reduced_vocab(train_fname)\n",
        "reduced_vocab, word2id = make_reduced_vocab(train_fname, min_occur=2)\n",
        "print(len(vocab))\n",
        "print(len(reduced_vocab))\n",
        "print(\"The size of the vocabulary change is \", len(vocab) - len(reduced_vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14818\n",
            "14311\n",
            "The size of the vocabulary change is  507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDQbmM3W2Im3"
      },
      "source": [
        "## 3. Text Classification Baselines\n",
        "\n",
        "You can now use the vocabulary constructed from the training data to create an embedding matrix. You will use the embedding matrix to map each input sequence of tokens to a list of embedding vectors. One of the simplest baseline is to go through one layer of neural network and then average the outputs, and finally classify the average embedding: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFIAvGS5pQXC",
        "outputId": "f437a804-6b39-4a12-9cc8-dfa6786dbb9b"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "input_ = \"hi world!\"\n",
        "input_tokens = input_.split(' ')\n",
        "input_ids = [word2id[word] if word in word2id else 0 for word in input_tokens]\n",
        "input_tensor = torch.LongTensor([input_ids]) # the first dimension is minibatch size\n",
        "print(input_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vUmITCFqMit",
        "outputId": "256b04dc-7dac-4e74-9766-c7ab247c11ec"
      },
      "source": [
        "# One layer, average pooling and classification\n",
        "class Baseline(nn.Module):\n",
        "  def __init__(self, d):\n",
        "    super(Baseline, self).__init__()\n",
        "    self.embedding = nn.Embedding(len(vocab), d)\n",
        "    self.layer = nn.Linear(d, d, bias=True)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.class_layer = nn.Linear(d, 2, bias=True)\n",
        "\n",
        "  def forward(self, input_tensor):\n",
        "    emb = self.embedding(input_tensor)\n",
        "    out = self.relu(self.layer(emb))\n",
        "    avg = out.mean(1)\n",
        "    logits = self.class_layer(avg)\n",
        "    return logits\n",
        "\n",
        "d = 3 # usually bigger, e.g. 128\n",
        "baseline = Baseline(d)\n",
        "logits = baseline(input_tensor)\n",
        "softmax = nn.Softmax(1)\n",
        "print(softmax(logits)) # probability for each class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4992, 0.5008]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9UuMWCG9YNs"
      },
      "source": [
        "Now we will compute the loss, which is the negative log probability of the input text's label being the target label (`1`), which in fact turns out to be equivalent to the cross entropy (https://en.wikipedia.org/wiki/Cross_entropy) between the probability distribution and a one-hot distribution of the target label (note that we use `logits` instead of `softmax(logits)` as the input to the cross entropy, which allow us to avoid numerical instability). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nxgYNzQqaPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4330d025-b105-450c-f8a3-461313ab6667"
      },
      "source": [
        "cel = nn.CrossEntropyLoss()\n",
        "label = torch.LongTensor([1]) # The ground truth label for \"hi world!\" is positive.\n",
        "loss = cel(logits, label) # Loss, a.k.a L\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6915, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKR99jZ2-wZW"
      },
      "source": [
        "Once we have the loss defined, only one step remains! We compute the gradients of parameters with respective to the loss and update. Fortunately, PyTorch does this for us in a very convenient way. Note that we used only one example to update the model, which is basically a Stochastic Gradient Descent (SGD) with minibatch size of 1. A recommended minibatch size in this exercise is at least 16. It is also recommended that you reuse your training data at least 10 times (i.e. 10 *epochs*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8JjhgQ071d6"
      },
      "source": [
        "optimizer = torch.optim.SGD(baseline.parameters(), lr=0.1)\n",
        "optimizer.zero_grad() # reset process\n",
        "loss.backward() # compute gradients\n",
        "optimizer.step() # update parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8M0fhFf_LbG"
      },
      "source": [
        "Once you have done this, all weight parameters will have `grad` attributes that contain their gradients with respect to the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpwOavsD8mpn",
        "outputId": "7b620f23-86d1-4ea6-9f11-271826797015"
      },
      "source": [
        "print(baseline.layer.weight.grad) # dL/dw of weights in the linear layer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RZMjI5HOEqg"
      },
      "source": [
        "**Problem 3.1** *(10 points)* Properly train this average-pooling baseline model on SST-2 and report the model's accuracy on the dev data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss89gtyFwFPj"
      },
      "source": [
        "# Constructing the dataset\n",
        "\n",
        "vocab, word2id = make_reduced_vocab(train_fname, min_occur=2)\n",
        "vocab_size = len(vocab)\n",
        "batch_size = 128\n",
        "shuffle = False\n",
        "\n",
        "def seq2id(seq, word2id):\n",
        "    sentence = seq.strip().split(' ')\n",
        "    return [word2id[word] if word in word2id else 0 for word in sentence]\n",
        "\n",
        "train_df = pd.read_csv(train_fname, sep='\\t')\n",
        "train_src = [seq2id(seq, word2id) for seq in train_df['sentence'].tolist()]\n",
        "train_tgt = train_df['label'].tolist()\n",
        "\n",
        "dev_df = pd.read_csv(dev_fname, sep='\\t')\n",
        "dev_src = [seq2id(seq, word2id) for seq in dev_df['sentence'].tolist()]\n",
        "dev_tgt = dev_df['label'].tolist()\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, src, tgt, batch_size, pad_idx, shuffle=False):\n",
        "        assert len(src) == len(tgt)\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "        self.size = len(src)\n",
        "        self.batch_size = batch_size\n",
        "        self.pad_idx = pad_idx\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.index = 0\n",
        "        if self.shuffle:\n",
        "            index = list(range(self.size))\n",
        "            random.shuffle(index)\n",
        "\n",
        "            shuffle_src = list()\n",
        "            shuffle_tgt = list()\n",
        "\n",
        "            for i in index:\n",
        "                shuffle_src.append(self.src[i])\n",
        "                shuffle_tgt.append(self.tgt[i])\n",
        "\n",
        "            self.src = shuffle_src\n",
        "            self.tgt = shuffle_tgt\n",
        "\n",
        "        return self\n",
        "\n",
        "    def pad(self, batch):\n",
        "        max_len = 0\n",
        "        for seq in batch:\n",
        "            if max_len < len(seq):\n",
        "                max_len = len(seq)\n",
        "\n",
        "        for i in range(len(batch)):\n",
        "            batch[i] += [self.pad_idx] * (max_len - len(batch[i]))\n",
        "        seq_lens = torch.LongTensor([(batch[i] + [self.pad_idx]).index(self.pad_idx) for i in range(len(batch))])\n",
        "\n",
        "        return batch, seq_lens\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.batch_size * self.index >= self.size:\n",
        "            raise StopIteration\n",
        "\n",
        "        src_batch = self.src[self.batch_size * self.index : self.batch_size * (self.index+1)]\n",
        "        tgt_batch = self.tgt[self.batch_size * self.index : self.batch_size * (self.index+1)]\n",
        "\n",
        "        padded_src_batch, src_seq_lens = self.pad(src_batch)\n",
        "\n",
        "        self.index += 1\n",
        "\n",
        "        return padded_src_batch, src_seq_lens, tgt_batch\n",
        "\n",
        "train_data_loader = DataLoader(train_src, train_tgt, batch_size=batch_size, pad_idx=1, shuffle=shuffle)\n",
        "dev_data_loader = DataLoader(dev_src, dev_tgt, batch_size=batch_size, pad_idx=1, shuffle=shuffle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2yaWThpgpWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b2f118-fe16-4c44-fbd3-a81318ce958f"
      },
      "source": [
        "# Training the baseline model on SST-2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "d = 128 # usually bigger, e.g. 128\n",
        "baseline = Baseline(d).to(device)\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(baseline.parameters(), lr=0.1)\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0.0\n",
        "    train_data_num = 0\n",
        "    for i, (source, src_seq_lens, target) in enumerate(train_data_loader):\n",
        "        train_tensor_src = torch.LongTensor(source).to(device)\n",
        "        train_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "        logits = baseline(train_tensor_src)\n",
        "\n",
        "        optimizer.zero_grad() # reset process\n",
        "        loss = cel(logits, train_tensor_tgt) # Loss, a.k.a L\n",
        "        loss.backward() # compute gradients\n",
        "        optimizer.step() # update parameters\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, train_preds = torch.max(logits, 1)\n",
        "        train_accuracy += (train_preds == train_tensor_tgt).sum().float()\n",
        "\n",
        "        train_data_num += train_tensor_tgt.shape[0]\n",
        "\n",
        "    print('train:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(train_loss / train_data_num), \n",
        "                'acc =', '{:.6f}'.format(train_accuracy / train_data_num))\n",
        "    \n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0\n",
        "            valid_accuracy = 0.0\n",
        "            valid_data_num = 0\n",
        "            for i, (source, src_seq_lens, target) in enumerate(dev_data_loader):\n",
        "                dev_tensor_src = torch.LongTensor(source).to(device)\n",
        "                dev_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "                logits = baseline(dev_tensor_src)\n",
        "                loss = cel(logits, dev_tensor_tgt) # Loss, a.k.a L\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                _, valid_preds = torch.max(logits, 1)\n",
        "                valid_accuracy += (valid_preds == dev_tensor_tgt).sum().float()\n",
        "\n",
        "                valid_data_num += dev_tensor_tgt.shape[0]\n",
        "                \n",
        "            print('valid:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(valid_loss / valid_data_num), \n",
        "                'acc =', '{:.6f}'.format(valid_accuracy / valid_data_num))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:: Epoch: 0001 cost = 0.005350, acc = 0.560736\n",
            "valid:: Epoch: 0001 cost = 0.005533, acc = 0.534404\n",
            "train:: Epoch: 0002 cost = 0.005285, acc = 0.578004\n",
            "valid:: Epoch: 0002 cost = 0.005398, acc = 0.581422\n",
            "train:: Epoch: 0003 cost = 0.005201, acc = 0.600143\n",
            "valid:: Epoch: 0003 cost = 0.005245, acc = 0.628440\n",
            "train:: Epoch: 0004 cost = 0.005105, acc = 0.620573\n",
            "valid:: Epoch: 0004 cost = 0.005113, acc = 0.653670\n",
            "train:: Epoch: 0005 cost = 0.005002, acc = 0.637975\n",
            "valid:: Epoch: 0005 cost = 0.005010, acc = 0.670872\n",
            "train:: Epoch: 0006 cost = 0.004898, acc = 0.653566\n",
            "valid:: Epoch: 0006 cost = 0.004923, acc = 0.693807\n",
            "train:: Epoch: 0007 cost = 0.004801, acc = 0.666291\n",
            "valid:: Epoch: 0007 cost = 0.004841, acc = 0.701835\n",
            "train:: Epoch: 0008 cost = 0.004708, acc = 0.677263\n",
            "valid:: Epoch: 0008 cost = 0.004761, acc = 0.705275\n",
            "train:: Epoch: 0009 cost = 0.004618, acc = 0.687107\n",
            "valid:: Epoch: 0009 cost = 0.004687, acc = 0.699541\n",
            "train:: Epoch: 0010 cost = 0.004532, acc = 0.697263\n",
            "valid:: Epoch: 0010 cost = 0.004619, acc = 0.702982\n",
            "train:: Epoch: 0011 cost = 0.004442, acc = 0.707345\n",
            "valid:: Epoch: 0011 cost = 0.004555, acc = 0.702982\n",
            "train:: Epoch: 0012 cost = 0.004356, acc = 0.717947\n",
            "valid:: Epoch: 0012 cost = 0.004500, acc = 0.708716\n",
            "train:: Epoch: 0013 cost = 0.004269, acc = 0.728979\n",
            "valid:: Epoch: 0013 cost = 0.004441, acc = 0.722477\n",
            "train:: Epoch: 0014 cost = 0.004183, acc = 0.738511\n",
            "valid:: Epoch: 0014 cost = 0.004387, acc = 0.724771\n",
            "train:: Epoch: 0015 cost = 0.004103, acc = 0.747034\n",
            "valid:: Epoch: 0015 cost = 0.004338, acc = 0.727064\n",
            "train:: Epoch: 0016 cost = 0.004025, acc = 0.754948\n",
            "valid:: Epoch: 0016 cost = 0.004283, acc = 0.743119\n",
            "train:: Epoch: 0017 cost = 0.003939, acc = 0.763322\n",
            "valid:: Epoch: 0017 cost = 0.004236, acc = 0.743119\n",
            "train:: Epoch: 0018 cost = 0.003861, acc = 0.770791\n",
            "valid:: Epoch: 0018 cost = 0.004194, acc = 0.745413\n",
            "train:: Epoch: 0019 cost = 0.003785, acc = 0.777161\n",
            "valid:: Epoch: 0019 cost = 0.004155, acc = 0.747706\n",
            "train:: Epoch: 0020 cost = 0.003716, acc = 0.783471\n",
            "valid:: Epoch: 0020 cost = 0.004168, acc = 0.735092\n",
            "train:: Epoch: 0021 cost = 0.003647, acc = 0.790955\n",
            "valid:: Epoch: 0021 cost = 0.004093, acc = 0.758027\n",
            "train:: Epoch: 0022 cost = 0.003577, acc = 0.796463\n",
            "valid:: Epoch: 0022 cost = 0.004067, acc = 0.761468\n",
            "train:: Epoch: 0023 cost = 0.003512, acc = 0.802313\n",
            "valid:: Epoch: 0023 cost = 0.004046, acc = 0.760321\n",
            "train:: Epoch: 0024 cost = 0.003467, acc = 0.807035\n",
            "valid:: Epoch: 0024 cost = 0.004026, acc = 0.753440\n",
            "train:: Epoch: 0025 cost = 0.003395, acc = 0.811697\n",
            "valid:: Epoch: 0025 cost = 0.004011, acc = 0.759174\n",
            "train:: Epoch: 0026 cost = 0.003336, acc = 0.816716\n",
            "valid:: Epoch: 0026 cost = 0.003995, acc = 0.763761\n",
            "train:: Epoch: 0027 cost = 0.003281, acc = 0.820948\n",
            "valid:: Epoch: 0027 cost = 0.003977, acc = 0.767202\n",
            "train:: Epoch: 0028 cost = 0.003230, acc = 0.824556\n",
            "valid:: Epoch: 0028 cost = 0.003975, acc = 0.768349\n",
            "train:: Epoch: 0029 cost = 0.003180, acc = 0.828045\n",
            "valid:: Epoch: 0029 cost = 0.003972, acc = 0.772936\n",
            "train:: Epoch: 0030 cost = 0.003142, acc = 0.831133\n",
            "valid:: Epoch: 0030 cost = 0.003976, acc = 0.768349\n",
            "train:: Epoch: 0031 cost = 0.003099, acc = 0.834474\n",
            "valid:: Epoch: 0031 cost = 0.003987, acc = 0.767202\n",
            "train:: Epoch: 0032 cost = 0.003048, acc = 0.837251\n",
            "valid:: Epoch: 0032 cost = 0.003994, acc = 0.769495\n",
            "train:: Epoch: 0033 cost = 0.003007, acc = 0.839760\n",
            "valid:: Epoch: 0033 cost = 0.003997, acc = 0.770642\n",
            "train:: Epoch: 0034 cost = 0.002965, acc = 0.842715\n",
            "valid:: Epoch: 0034 cost = 0.004009, acc = 0.770642\n",
            "train:: Epoch: 0035 cost = 0.002929, acc = 0.844823\n",
            "valid:: Epoch: 0035 cost = 0.004025, acc = 0.772936\n",
            "train:: Epoch: 0036 cost = 0.002937, acc = 0.845031\n",
            "valid:: Epoch: 0036 cost = 0.004106, acc = 0.766055\n",
            "train:: Epoch: 0037 cost = 0.002871, acc = 0.847926\n",
            "valid:: Epoch: 0037 cost = 0.004085, acc = 0.772936\n",
            "train:: Epoch: 0038 cost = 0.002840, acc = 0.849901\n",
            "valid:: Epoch: 0038 cost = 0.004119, acc = 0.767202\n",
            "train:: Epoch: 0039 cost = 0.002798, acc = 0.853272\n",
            "valid:: Epoch: 0039 cost = 0.004124, acc = 0.768349\n",
            "train:: Epoch: 0040 cost = 0.002764, acc = 0.855647\n",
            "valid:: Epoch: 0040 cost = 0.004142, acc = 0.772936\n",
            "train:: Epoch: 0041 cost = 0.002733, acc = 0.857503\n",
            "valid:: Epoch: 0041 cost = 0.004157, acc = 0.775229\n",
            "train:: Epoch: 0042 cost = 0.002714, acc = 0.858350\n",
            "valid:: Epoch: 0042 cost = 0.004157, acc = 0.772936\n",
            "train:: Epoch: 0043 cost = 0.002676, acc = 0.861067\n",
            "valid:: Epoch: 0043 cost = 0.004182, acc = 0.774083\n",
            "train:: Epoch: 0044 cost = 0.002649, acc = 0.862492\n",
            "valid:: Epoch: 0044 cost = 0.004204, acc = 0.772936\n",
            "train:: Epoch: 0045 cost = 0.002628, acc = 0.863502\n",
            "valid:: Epoch: 0045 cost = 0.004210, acc = 0.772936\n",
            "train:: Epoch: 0046 cost = 0.002598, acc = 0.865403\n",
            "valid:: Epoch: 0046 cost = 0.004244, acc = 0.774083\n",
            "train:: Epoch: 0047 cost = 0.002572, acc = 0.867318\n",
            "valid:: Epoch: 0047 cost = 0.004276, acc = 0.774083\n",
            "train:: Epoch: 0048 cost = 0.002547, acc = 0.869129\n",
            "valid:: Epoch: 0048 cost = 0.004306, acc = 0.775229\n",
            "train:: Epoch: 0049 cost = 0.002524, acc = 0.870688\n",
            "valid:: Epoch: 0049 cost = 0.004336, acc = 0.778670\n",
            "train:: Epoch: 0050 cost = 0.002501, acc = 0.872381\n",
            "valid:: Epoch: 0050 cost = 0.004368, acc = 0.780963\n",
            "train:: Epoch: 0051 cost = 0.002479, acc = 0.873287\n",
            "valid:: Epoch: 0051 cost = 0.004394, acc = 0.778670\n",
            "train:: Epoch: 0052 cost = 0.002457, acc = 0.874712\n",
            "valid:: Epoch: 0052 cost = 0.004434, acc = 0.779817\n",
            "train:: Epoch: 0053 cost = 0.002436, acc = 0.875870\n",
            "valid:: Epoch: 0053 cost = 0.004460, acc = 0.779817\n",
            "train:: Epoch: 0054 cost = 0.002416, acc = 0.877118\n",
            "valid:: Epoch: 0054 cost = 0.004491, acc = 0.777523\n",
            "train:: Epoch: 0055 cost = 0.002396, acc = 0.878380\n",
            "valid:: Epoch: 0055 cost = 0.004503, acc = 0.777523\n",
            "train:: Epoch: 0056 cost = 0.002377, acc = 0.879345\n",
            "valid:: Epoch: 0056 cost = 0.004537, acc = 0.776376\n",
            "train:: Epoch: 0057 cost = 0.002358, acc = 0.880577\n",
            "valid:: Epoch: 0057 cost = 0.004564, acc = 0.776376\n",
            "train:: Epoch: 0058 cost = 0.002351, acc = 0.881275\n",
            "valid:: Epoch: 0058 cost = 0.004593, acc = 0.776376\n",
            "train:: Epoch: 0059 cost = 0.002324, acc = 0.882879\n",
            "valid:: Epoch: 0059 cost = 0.004609, acc = 0.778670\n",
            "train:: Epoch: 0060 cost = 0.002307, acc = 0.884052\n",
            "valid:: Epoch: 0060 cost = 0.004633, acc = 0.779817\n",
            "train:: Epoch: 0061 cost = 0.002290, acc = 0.884720\n",
            "valid:: Epoch: 0061 cost = 0.004661, acc = 0.780963\n",
            "train:: Epoch: 0062 cost = 0.002273, acc = 0.885834\n",
            "valid:: Epoch: 0062 cost = 0.004683, acc = 0.782110\n",
            "train:: Epoch: 0063 cost = 0.002260, acc = 0.886323\n",
            "valid:: Epoch: 0063 cost = 0.004696, acc = 0.782110\n",
            "train:: Epoch: 0064 cost = 0.002241, acc = 0.887393\n",
            "valid:: Epoch: 0064 cost = 0.004720, acc = 0.783257\n",
            "train:: Epoch: 0065 cost = 0.002226, acc = 0.888610\n",
            "valid:: Epoch: 0065 cost = 0.004754, acc = 0.784404\n",
            "train:: Epoch: 0066 cost = 0.002211, acc = 0.889664\n",
            "valid:: Epoch: 0066 cost = 0.004780, acc = 0.783257\n",
            "train:: Epoch: 0067 cost = 0.002197, acc = 0.890451\n",
            "valid:: Epoch: 0067 cost = 0.004808, acc = 0.782110\n",
            "train:: Epoch: 0068 cost = 0.002188, acc = 0.890912\n",
            "valid:: Epoch: 0068 cost = 0.004817, acc = 0.786697\n",
            "train:: Epoch: 0069 cost = 0.002170, acc = 0.891743\n",
            "valid:: Epoch: 0069 cost = 0.004857, acc = 0.783257\n",
            "train:: Epoch: 0070 cost = 0.002155, acc = 0.892723\n",
            "valid:: Epoch: 0070 cost = 0.004888, acc = 0.783257\n",
            "train:: Epoch: 0071 cost = 0.002143, acc = 0.893332\n",
            "valid:: Epoch: 0071 cost = 0.004930, acc = 0.784404\n",
            "train:: Epoch: 0072 cost = 0.002128, acc = 0.894208\n",
            "valid:: Epoch: 0072 cost = 0.004956, acc = 0.784404\n",
            "train:: Epoch: 0073 cost = 0.002115, acc = 0.895277\n",
            "valid:: Epoch: 0073 cost = 0.004996, acc = 0.782110\n",
            "train:: Epoch: 0074 cost = 0.002102, acc = 0.895826\n",
            "valid:: Epoch: 0074 cost = 0.005024, acc = 0.779817\n",
            "train:: Epoch: 0075 cost = 0.002089, acc = 0.896569\n",
            "valid:: Epoch: 0075 cost = 0.005053, acc = 0.778670\n",
            "train:: Epoch: 0076 cost = 0.002077, acc = 0.897118\n",
            "valid:: Epoch: 0076 cost = 0.005081, acc = 0.779817\n",
            "train:: Epoch: 0077 cost = 0.002071, acc = 0.897430\n",
            "valid:: Epoch: 0077 cost = 0.005106, acc = 0.778670\n",
            "train:: Epoch: 0078 cost = 0.002054, acc = 0.898380\n",
            "valid:: Epoch: 0078 cost = 0.005128, acc = 0.778670\n",
            "train:: Epoch: 0079 cost = 0.002042, acc = 0.899167\n",
            "valid:: Epoch: 0079 cost = 0.005155, acc = 0.777523\n",
            "train:: Epoch: 0080 cost = 0.002030, acc = 0.899865\n",
            "valid:: Epoch: 0080 cost = 0.005176, acc = 0.778670\n",
            "train:: Epoch: 0081 cost = 0.002019, acc = 0.900815\n",
            "valid:: Epoch: 0081 cost = 0.005196, acc = 0.778670\n",
            "train:: Epoch: 0082 cost = 0.002008, acc = 0.901320\n",
            "valid:: Epoch: 0082 cost = 0.005216, acc = 0.778670\n",
            "train:: Epoch: 0083 cost = 0.001997, acc = 0.901958\n",
            "valid:: Epoch: 0083 cost = 0.005236, acc = 0.778670\n",
            "train:: Epoch: 0084 cost = 0.001986, acc = 0.902552\n",
            "valid:: Epoch: 0084 cost = 0.005268, acc = 0.777523\n",
            "train:: Epoch: 0085 cost = 0.001975, acc = 0.902998\n",
            "valid:: Epoch: 0085 cost = 0.005295, acc = 0.777523\n",
            "train:: Epoch: 0086 cost = 0.001965, acc = 0.903443\n",
            "valid:: Epoch: 0086 cost = 0.005319, acc = 0.777523\n",
            "train:: Epoch: 0087 cost = 0.001955, acc = 0.904319\n",
            "valid:: Epoch: 0087 cost = 0.005346, acc = 0.778670\n",
            "train:: Epoch: 0088 cost = 0.001945, acc = 0.904824\n",
            "valid:: Epoch: 0088 cost = 0.005361, acc = 0.778670\n",
            "train:: Epoch: 0089 cost = 0.001935, acc = 0.905611\n",
            "valid:: Epoch: 0089 cost = 0.005375, acc = 0.778670\n",
            "train:: Epoch: 0090 cost = 0.001925, acc = 0.906086\n",
            "valid:: Epoch: 0090 cost = 0.005409, acc = 0.777523\n",
            "train:: Epoch: 0091 cost = 0.001916, acc = 0.906591\n",
            "valid:: Epoch: 0091 cost = 0.005438, acc = 0.777523\n",
            "train:: Epoch: 0092 cost = 0.001907, acc = 0.907229\n",
            "valid:: Epoch: 0092 cost = 0.005454, acc = 0.776376\n",
            "train:: Epoch: 0093 cost = 0.001897, acc = 0.907541\n",
            "valid:: Epoch: 0093 cost = 0.005484, acc = 0.775229\n",
            "train:: Epoch: 0094 cost = 0.001888, acc = 0.907898\n",
            "valid:: Epoch: 0094 cost = 0.005507, acc = 0.775229\n",
            "train:: Epoch: 0095 cost = 0.001879, acc = 0.908358\n",
            "valid:: Epoch: 0095 cost = 0.005530, acc = 0.776376\n",
            "train:: Epoch: 0096 cost = 0.001871, acc = 0.908952\n",
            "valid:: Epoch: 0096 cost = 0.005546, acc = 0.777523\n",
            "train:: Epoch: 0097 cost = 0.001862, acc = 0.909293\n",
            "valid:: Epoch: 0097 cost = 0.005586, acc = 0.775229\n",
            "train:: Epoch: 0098 cost = 0.001853, acc = 0.909679\n",
            "valid:: Epoch: 0098 cost = 0.005598, acc = 0.776376\n",
            "train:: Epoch: 0099 cost = 0.001845, acc = 0.910303\n",
            "valid:: Epoch: 0099 cost = 0.005627, acc = 0.776376\n",
            "train:: Epoch: 0100 cost = 0.001837, acc = 0.910867\n",
            "valid:: Epoch: 0100 cost = 0.005651, acc = 0.776376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neN_jLl2XOJO"
      },
      "source": [
        "I used d = 128, batch_size = 128, epoch = 100, for the baseline. The result is followed.\n",
        "\n",
        "After 30 Iteration, It converges. (Validation Loss begins to increase)\n",
        "train:: Epoch: 0030 cost = 0.003190 ,acc = 0.823991\n",
        "valid:: Epoch: 0030 cost = 0.003767 ,acc = 0.770642"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejqZv3GNOHPl"
      },
      "source": [
        "**Problem 3.2** *(10 points)* Implement a recurrent neural network (without using PyTorch's RNN module) where the output of the linear layer not only depends on the current input but also the previous output. Report the model's accuracy on the dev data. Is it better or worse than the baseline? Why?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "xr18IO7s6XS8",
        "outputId": "f33d6f72-eaed-482b-d56c-1a5cea02ab89"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# One RNN layer and classification\n",
        "class RNNNode(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(RNNNode, self).__init__()\n",
        "\n",
        "        self.W_h2h = torch.nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.W_h2y = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "    \n",
        "    def forward(self, input, hidden, src_batch_sizes):\n",
        "        h_t = hidden.squeeze(0)\n",
        "        h_last = h_t\n",
        "        y_list = list()\n",
        "        batch_size = int(src_batch_sizes[0])\n",
        "        for i, batch in enumerate(src_batch_sizes):\n",
        "            batch = int(batch)\n",
        "            token = input[i][:batch, :]\n",
        "            combined_input = torch.cat([token, h_t[:batch, :]], dim=1)\n",
        "            h_last[:batch, :] = h_t = self.tanh(self.W_h2h(combined_input))\n",
        "            y_t = self.W_h2y(h_t)\n",
        "            y_list.append(nn.ZeroPad2d((0, 0, batch_size - batch, 0))(y_t)) # Zero-padding\n",
        "        y = torch.stack(y_list, dim=0) # \n",
        "        return y, h_last.unsqueeze(0)\n",
        "\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, n_layers):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "\n",
        "        # nn.RNN\n",
        "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers)\n",
        "\n",
        "        # my RNN\n",
        "        # self.rnn = RNNNode(input_size=embedding_dim, hidden_size=hidden_dim)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * n_layers, 2)\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "\n",
        "    def forward(self, input_tensor, src_seq_lens, hidden):\n",
        "        emb = self.embedding(input_tensor) # emb.shape = batch * len * hidden\n",
        "        emb = emb.transpose(0, 1) # emb.shape = len * batch * hidden\n",
        "\n",
        "        # nn.RNN\n",
        "        packed = pack_padded_sequence(emb, src_seq_lens.tolist(), batch_first=False)\n",
        "        outs, hidden = self.rnn(packed, hidden) # h0 = zero initialization\n",
        "        outs, out_lens = pad_packed_sequence(outs, batch_first=False)\n",
        "\n",
        "        # my RNN\n",
        "        # print(\"input shape : \", emb.shape, hidden.shape) # len * batch * emb, 1 * batch * hidden\n",
        "        # src_batch_sizes = seqs2batches(src_seq_lens)\n",
        "        # outs, hidden = self.rnn(emb, hidden, src_batch_sizes) # h0 = zero initialization\n",
        "        # print(\"output shape : \", outs.shape, hidden.shape) # len * batch * hidden, 1 * batch * hidden\n",
        "\n",
        "        logits = self.fc(hidden.squeeze(0))\n",
        "        # logits = self.fc(outs[-1])\n",
        "        return logits\n",
        "\n",
        "\n",
        "def seqs2batches(src_seq_lens):\n",
        "    \"\"\"\n",
        "    This is same with batches2seqs() \n",
        "    \"\"\"\n",
        "    assert src_seq_lens is not None\n",
        "    assert src_seq_lens[-1] > 0\n",
        "    src_batch_sizes = torch.zeros(int(src_seq_lens[0]))\n",
        "    pointer = int(src_seq_lens[0]) - 1\n",
        "    for i, seq_len in enumerate(src_seq_lens.tolist() + [0]):\n",
        "        while seq_len <= pointer:\n",
        "            src_batch_sizes[pointer] = i\n",
        "            pointer -= 1\n",
        "    return src_batch_sizes\n",
        "\n",
        "\n",
        "# Training the baseline model on SST-2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "embedding_dim = 256 # usually bigger, e.g. 128\n",
        "hidden_dim = 128\n",
        "n_layers = 1\n",
        "rnnmodel = RNNModel(embedding_dim, hidden_dim, n_layers).to(device)\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(rnnmodel.parameters(), lr=0.1)\n",
        "\n",
        "epochs = 150\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0.0\n",
        "    train_data_num = 0\n",
        "    for i, (source, src_seq_lens, target) in enumerate(train_data_loader):\n",
        "        train_tensor_src = torch.LongTensor(source).to(device)\n",
        "        train_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "\n",
        "        sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "        train_sorted_batch = train_tensor_src[sorted_indices]\n",
        "\n",
        "        # print(src_seq_lens.shape, src_batch_sizes.shape, seqs2batches(src_batch_sizes).shape)\n",
        "        h0 = torch.zeros(n_layers, train_sorted_batch.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "        # logits = rnnmodel(train_tensor_src, src_seq_lens, h0)\n",
        "        logits = rnnmodel(train_sorted_batch, sorted_seq_lens, h0)\n",
        "\n",
        "        # print(train_tensor_src.shape, train_tensor_tgt.shape, logits.shape)\n",
        "\n",
        "        optimizer.zero_grad() # reset process\n",
        "        loss = cel(logits, train_tensor_tgt) # Loss, a.k.a L\n",
        "        loss.backward() # compute gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), 5) # gradent clipping\n",
        "        optimizer.step() # update parameters\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, train_preds = torch.max(logits, 1)\n",
        "        train_accuracy += (train_preds == train_tensor_tgt).sum().float()\n",
        "\n",
        "        train_data_num += train_tensor_tgt.shape[0]\n",
        "\n",
        "    print('train:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(train_loss / train_data_num), \n",
        "                'acc =', '{:.6f}'.format(train_accuracy / train_data_num))\n",
        "    \n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0\n",
        "            valid_accuracy = 0.0\n",
        "            valid_data_num = 0\n",
        "            for i, (source, src_seq_lens, target) in enumerate(dev_data_loader):\n",
        "                dev_tensor_src = torch.LongTensor(source).to(device)\n",
        "                dev_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "            \n",
        "                sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "                dev_sorted_batch = dev_tensor_src[sorted_indices]\n",
        "\n",
        "                h0 = torch.zeros(n_layers, dev_sorted_batch.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "                logits = rnnmodel(dev_sorted_batch, sorted_seq_lens, h0)\n",
        "\n",
        "                loss = cel(logits, dev_tensor_tgt) # Loss, a.k.a L\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                _, valid_preds = torch.max(logits, 1)\n",
        "                valid_accuracy += (valid_preds == dev_tensor_tgt).sum().float()\n",
        "\n",
        "                valid_data_num += dev_tensor_tgt.shape[0]\n",
        "                \n",
        "            print('valid:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(valid_loss / valid_data_num), \n",
        "                'acc =', '{:.6f}'.format(valid_accuracy / valid_data_num))\n",
        "        \n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train:: Epoch: 0001 cost = 0.005422, acc = 0.542577\n",
            "valid:: Epoch: 0001 cost = 0.005589, acc = 0.503440\n",
            "train:: Epoch: 0002 cost = 0.005398, acc = 0.547105\n",
            "valid:: Epoch: 0002 cost = 0.005594, acc = 0.488532\n",
            "train:: Epoch: 0003 cost = 0.005388, acc = 0.549852\n",
            "valid:: Epoch: 0003 cost = 0.005603, acc = 0.491972\n",
            "train:: Epoch: 0004 cost = 0.005376, acc = 0.552287\n",
            "valid:: Epoch: 0004 cost = 0.005614, acc = 0.489679\n",
            "train:: Epoch: 0005 cost = 0.005364, acc = 0.557024\n",
            "valid:: Epoch: 0005 cost = 0.005627, acc = 0.494266\n",
            "train:: Epoch: 0006 cost = 0.005350, acc = 0.561434\n",
            "valid:: Epoch: 0006 cost = 0.005643, acc = 0.489679\n",
            "train:: Epoch: 0007 cost = 0.005335, acc = 0.565042\n",
            "valid:: Epoch: 0007 cost = 0.005663, acc = 0.490826\n",
            "train:: Epoch: 0008 cost = 0.005319, acc = 0.569660\n",
            "valid:: Epoch: 0008 cost = 0.005688, acc = 0.489679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2fd83166c919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reset process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_tensor_tgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Loss, a.k.a L\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;31m# torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), 5) # gradent clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ92ZQUVczxo"
      },
      "source": [
        "(The loss is not really decreasing and the accuracy is poor...\n",
        "It is much worse than the baseline. (Either cases, nn.RNN or my code)\n",
        "\n",
        "...\n",
        "train:: Epoch: 0019 cost = 0.005243 ,acc = 0.588739\n",
        "train:: Epoch: 0020 cost = 0.005223 ,acc = 0.591694\n",
        "valid:: Epoch: 0020 cost = 0.005724 ,acc = 0.512615\n",
        "\n",
        "This is because of the "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyU1H34rOJS7"
      },
      "source": [
        "**Problem 3.3 (bonus)** *(10 points)* Show that the cross entropy computed above is equivalent to the negative log likelihood of the probability distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-O9D26U_aEB"
      },
      "source": [
        "**Problem 3.4 (bonus)** *(10 points)* Why is it numerically unstable if you compute log on top of softmax?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBLmpKJRAd1h"
      },
      "source": [
        "## 4. Text Classification with LSTM and Dropout\n",
        "\n",
        "Now it is time to improve your baselines! Replace your RNN module with an LSTM module. See Lecture slides 04 and 05 for the formal definition of LSTMs. \n",
        "\n",
        "You will also use Dropout, which randomly makes each dimension zero with the probability of `p` and scale it by `1/(1-p)` if it is not zero during training. Put it either at the input or the output of the LSTM to prevent it from overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8H0F-csCCk0",
        "outputId": "a28bbce3-19b6-48da-ceb2-41c4eaa74d97"
      },
      "source": [
        "a = torch.FloatTensor([0.1, 0.3, 0.5, 0.7, 0.9])\n",
        "dropout = nn.Dropout(0.5) # p=0.5\n",
        "print(dropout(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2000, 0.0000, 0.0000, 1.4000, 1.8000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAduhDj-Iva2"
      },
      "source": [
        "Problem 4.1 (20 points) Implement and use LSTM (without using PyTorch's LSTM module) instead of vanilla RNN to improve your model. Report the accuracy on the dev data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "ZMF_9_0MKe8m",
        "outputId": "34f45334-0182-4428-9467-14c01e8514a0"
      },
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# One LSTM layer and classification\n",
        "class LSTMNode(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(LSTMNode, self).__init__()\n",
        "\n",
        "        self.W_ft = torch.nn.Linear(input_size + hidden_size, hidden_size) # forget gate\n",
        "        self.W_it = torch.nn.Linear(input_size + hidden_size, hidden_size) # input gate\n",
        "        self.W_ot = torch.nn.Linear(input_size + hidden_size, hidden_size) # output gate\n",
        "        self.W_ct = torch.nn.Linear(input_size + hidden_size, hidden_size) # cell state\n",
        "        self.W_ht = torch.nn.Linear(hidden_size, hidden_size) # hidden state\n",
        "        self.W_h2y = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "    \n",
        "    def forward(self, input, hidden, cell, src_batch_sizes):\n",
        "        h_t = hidden.squeeze(0)\n",
        "        c_t = cell.squeeze(0)\n",
        "        y_list = list()\n",
        "        batch_size = int(src_batch_sizes[0])\n",
        "\n",
        "        for i, batch in enumerate(src_batch_sizes):\n",
        "            batch = int(batch)\n",
        "            token = input[i][:batch, :]\n",
        "            combined_input = torch.cat([token, h_t[:batch, :]], dim=1)\n",
        "\n",
        "            f_t = self.sigmoid(self.W_ft(combined_input))\n",
        "            i_t = self.sigmoid(self.W_it(combined_input))\n",
        "            o_t = self.sigmoid(self.W_ot(combined_input))\n",
        "            c_hat_t = self.tanh(self.W_ct(combined_input))\n",
        "\n",
        "            c_t[:batch, :] = f_t*c_t[:batch, :] + i_t*c_hat_t\n",
        "            h_t[:batch, :] = o_t*self.tanh(c_t_next)\n",
        "\n",
        "        return c_t, h_t\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "\n",
        "        # nn.LSTM\n",
        "        # self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim)\n",
        "\n",
        "        # my LSTM\n",
        "        self.lstm = LSTMNode(input_size=embedding_dim, hidden_size=hidden_dim)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim, 2, bias=True)\n",
        "\n",
        "    def forward(self, input_tensor, src_seq_lens, hidden, cell):\n",
        "        emb = self.embedding(input_tensor) # emb.shape = batch * len * hidden\n",
        "        emb = emb.transpose(0, 1) # emb.shape = len * batch * hidden\n",
        "\n",
        "        # nn.LSTM\n",
        "        # packed = pack_padded_sequence(emb, src_seq_lens.tolist(), batch_first=False)\n",
        "        # outs, hidden = self.lstm(packed, hidden) # h0 = zero initialization\n",
        "        # outs, out_lens = pad_packed_sequence(outs, batch_first=False)\n",
        "\n",
        "        # my LSTM\n",
        "        # print(\"input shape : \", emb.shape, hidden.shape) # len * batch * emb, 1 * batch * hidden\n",
        "        src_batch_sizes = seqs2batches(src_seq_lens)\n",
        "        outs, hidden = self.lstm(emb, hidden, cell, src_batch_sizes) # h0 = zero initialization\n",
        "        # print(\"output shape : \", outs.shape, hidden.shape) # len * batch * hidden, 1 * batch * hidden\n",
        "\n",
        "        logits = self.fc(hidden.transpose(0, 1).view(hidden.shape[1], -1))\n",
        "        # logits = self.fc(outs[-1])\n",
        "        return logits\n",
        "\n",
        "\n",
        "def seqs2batches(src_seq_lens):\n",
        "    \"\"\"\n",
        "    This is same with batches2seqs() \n",
        "    \"\"\"\n",
        "    assert src_seq_lens is not None\n",
        "    assert src_seq_lens[-1] > 0\n",
        "    src_batch_sizes = torch.zeros(int(src_seq_lens[0]))\n",
        "    pointer = int(src_seq_lens[0]) - 1\n",
        "    for i, seq_len in enumerate(src_seq_lens.tolist() + [0]):\n",
        "        while seq_len <= pointer:\n",
        "            src_batch_sizes[pointer] = i\n",
        "            pointer -= 1\n",
        "    return src_batch_sizes\n",
        "\n",
        "\n",
        "# Training the baseline model on SST-2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "embedding_dim = 128 # usually bigger, e.g. 128\n",
        "hidden_dim = 128\n",
        "rnnmodel = LSTMModel(embedding_dim, hidden_dim).to(device)\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(rnnmodel.parameters(), lr=0.1)\n",
        "\n",
        "epochs = 150\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0.0\n",
        "    train_data_num = 0\n",
        "    for i, (source, src_seq_lens, target) in enumerate(train_data_loader):\n",
        "        train_tensor_src = torch.LongTensor(source).to(device)\n",
        "        train_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "\n",
        "        sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "        train_sorted_batch = train_tensor_src[sorted_indices]\n",
        "\n",
        "        # print(src_seq_lens.shape, src_batch_sizes.shape, seqs2batches(src_batch_sizes).shape)\n",
        "        h0 = torch.zeros(1, train_sorted_batch.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "        logits = rnnmodel(train_sorted_batch, sorted_seq_lens, h0)\n",
        "\n",
        "        # print(train_tensor_src.shape, train_tensor_tgt.shape, logits.shape)\n",
        "\n",
        "        optimizer.zero_grad() # reset process\n",
        "        loss = cel(logits, train_tensor_tgt) # Loss, a.k.a L\n",
        "        loss.backward() # compute gradients\n",
        "        # torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), 5) # gradent clipping\n",
        "        optimizer.step() # update parameters\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, train_preds = torch.max(logits, 1)\n",
        "        train_accuracy += (train_preds == train_tensor_tgt).sum().float()\n",
        "\n",
        "        train_data_num += train_tensor_tgt.shape[0]\n",
        "\n",
        "    print('train:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(train_loss / train_data_num), \n",
        "                'acc =', '{:.6f}'.format(train_accuracy / train_data_num))\n",
        "    \n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0\n",
        "            valid_accuracy = 0.0\n",
        "            valid_data_num = 0\n",
        "            for i, (source, src_seq_lens, target) in enumerate(dev_data_loader):\n",
        "                dev_tensor_src = torch.LongTensor(source).to(device)\n",
        "                dev_tensor_tgt = torch.LongTensor(target).to(device)\n",
        "            \n",
        "                sorted_seq_lens, sorted_indices = torch.sort(src_seq_lens, descending=True)\n",
        "                dev_sorted_batch = dev_tensor_src[sorted_indices]\n",
        "\n",
        "                h0 = torch.zeros(1, dev_sorted_batch.shape[0], hidden_dim, requires_grad=True).to(device)\n",
        "                logits = rnnmodel(dev_sorted_batch, sorted_seq_lens, h0)\n",
        "\n",
        "                loss = cel(logits, dev_tensor_tgt) # Loss, a.k.a L\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                _, valid_preds = torch.max(logits, 1)\n",
        "                valid_accuracy += (valid_preds == dev_tensor_tgt).sum().float()\n",
        "\n",
        "                valid_data_num += dev_tensor_tgt.shape[0]\n",
        "                \n",
        "            print('valid:: Epoch:', '%04d' % (epoch + 1), \n",
        "                'cost =', '{:.6f},'.format(valid_loss / valid_data_num), \n",
        "                'acc =', '{:.6f}'.format(valid_accuracy / valid_data_num))\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-f0dc01ad243d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m \u001b[0;31m# usually bigger, e.g. 128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mrnnmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mcel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-95-f0dc01ad243d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, embedding_dim, hidden_dim)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# my LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-95-f0dc01ad243d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_size, hidden_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_ot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_ct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_ht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'output_size' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHDodvqvIx4W"
      },
      "source": [
        "Problem 4.2 (10 points) Use Dropout on LSTM (either at input or output). Report the accuracy on the dev data and briefly describe how it differs from 4.1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dbUZ0wCIzHq"
      },
      "source": [
        "Problem 4.3 (bonus) (10 points) Consider implementing bidirectional LSTM and two layers of LSTM to further improve your model. Report your accuracy on dev data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855DrT78DXps"
      },
      "source": [
        "## 5. Pretrained Word Vectors\n",
        "The last step is to use pretrained vocabulary and word vectors. The prebuilt vocabulary will replace the vocabulary you built with SST-2 training data, and the word vectors will replace the embedding vectors. You will observe the power of leveraging self-supservised pretrained models.\n",
        "\n",
        "**Problem 5.1** *(10 points)* Go to https://nlp.stanford.edu/projects/glove/ and download `glove.6B.zip`. Use these pretrained word vectors to further improve your model from 4.2. Report the model's accuracy on the dev data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FKuB_7aI6fk"
      },
      "source": [
        "Problem 5.2 (bonus) (10 points) You can go one step further by using word vectors obtained from pretrained language models. Can you import the word embeddings from bert-base-uncased model (via Hugging Face's transformers: https://huggingface.co/transformers/pretrained_models.html) into your model and improve it further? Report the accuracy on the dev data here. If the score is now higher, explain where the improvement is coming from."
      ]
    }
  ]
}