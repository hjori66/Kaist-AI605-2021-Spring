{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KAIST AI605 Assignment 2_20194364.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "175819bd3f5c4ca58a4d72db4076bedd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_182e93143167407ab1d2942b828fb325",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_82fc39b2a53f43eab188fb21b078bc9f",
              "IPY_MODEL_b21b0aa73c55452e88998632b828771d"
            ]
          }
        },
        "182e93143167407ab1d2942b828fb325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82fc39b2a53f43eab188fb21b078bc9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ec56032d086c419f805664c76f469ea7",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdd9f2a5aa3b4760aa3ff5fc45d6a0f1"
          }
        },
        "b21b0aa73c55452e88998632b828771d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_548e33dd42dd4182bb3fdfc779e52925",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.03k/? [00:01&lt;00:00, 3.00kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e32b10fcf53d4d63b4cd6a34f2b17c5b"
          }
        },
        "ec56032d086c419f805664c76f469ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdd9f2a5aa3b4760aa3ff5fc45d6a0f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "548e33dd42dd4182bb3fdfc779e52925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e32b10fcf53d4d63b4cd6a34f2b17c5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bbc7e487a19c4762b5bb8ebca2f7203a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a57e0e01a744cda91b59c99d4b5e75e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_da0a5cfda34f4ed1b319377d8d205d01",
              "IPY_MODEL_0bd5c6dd5c7341f99834ff05b91f3537"
            ]
          }
        },
        "3a57e0e01a744cda91b59c99d4b5e75e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da0a5cfda34f4ed1b319377d8d205d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9e043b8d7bb45be8c869ba79203be5e",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 955,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 955,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d58fca7bd844fe2b573b1f595390704"
          }
        },
        "0bd5c6dd5c7341f99834ff05b91f3537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b706dd3c513449c6af8580d65d971997",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.19k/? [00:01&lt;00:00, 1.64kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6614604ea8b04b70bfd522b5b1e9da52"
          }
        },
        "d9e043b8d7bb45be8c869ba79203be5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d58fca7bd844fe2b573b1f595390704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b706dd3c513449c6af8580d65d971997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6614604ea8b04b70bfd522b5b1e9da52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56e128be787d433ea98e6d720b5914e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bcdf3ade83264159a63dddc479af286a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c6792178ff9a4522bb75d82d160e55c6",
              "IPY_MODEL_bbeb6f85bef94fd681296fe9488e2c79"
            ]
          }
        },
        "bcdf3ade83264159a63dddc479af286a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6792178ff9a4522bb75d82d160e55c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eea73274970343d6a3cc3dfc99f0625f",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 8116577,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8116577,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd274f910de04176b42dc5e6e1bcc436"
          }
        },
        "bbeb6f85bef94fd681296fe9488e2c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65a509dfe73e463c9f6f7046d9f3ec3a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30.3M/? [00:01&lt;00:00, 28.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aeb57804c3a84f48acf0b9bce939bcd6"
          }
        },
        "eea73274970343d6a3cc3dfc99f0625f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd274f910de04176b42dc5e6e1bcc436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65a509dfe73e463c9f6f7046d9f3ec3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aeb57804c3a84f48acf0b9bce939bcd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9fb7c9c011141669594da9ec3003f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6fa4f97d1f4841c2bf5dc4321797b19b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65f046877a824f2c87e3a8a30556bc46",
              "IPY_MODEL_8173ed65404a4164bf98dcc7e9ed5167"
            ]
          }
        },
        "6fa4f97d1f4841c2bf5dc4321797b19b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65f046877a824f2c87e3a8a30556bc46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1c9b2315129043e0b2048ba17aa1667d",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1054280,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1054280,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee2d23fcf2414e17b86cbd9561bd3e55"
          }
        },
        "8173ed65404a4164bf98dcc7e9ed5167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50126fb07ff64d77b922d1519aaab6b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.85M/? [00:00&lt;00:00, 16.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_797f85ff19364765946f6124eed87c8b"
          }
        },
        "1c9b2315129043e0b2048ba17aa1667d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee2d23fcf2414e17b86cbd9561bd3e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50126fb07ff64d77b922d1519aaab6b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "797f85ff19364765946f6124eed87c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73a939a47602489fabdd2f87b7466965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2753f18c4223402189ea57177d6cc7f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c253bf6e5fc54a36bf8b63f232dbfd1f",
              "IPY_MODEL_9dc98568e8e141e48286d7be0722efbe"
            ]
          }
        },
        "2753f18c4223402189ea57177d6cc7f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c253bf6e5fc54a36bf8b63f232dbfd1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8b718765a4040e7b81d410847801eb9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d1c28ffaa2947b1b48554470b760f13"
          }
        },
        "9dc98568e8e141e48286d7be0722efbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc75836985444b8cb2095d8f948fe0ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87599/0 [00:07&lt;00:00, 18360.74 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a891dd13d5a94d49abcdb2e128b82ff1"
          }
        },
        "a8b718765a4040e7b81d410847801eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d1c28ffaa2947b1b48554470b760f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc75836985444b8cb2095d8f948fe0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a891dd13d5a94d49abcdb2e128b82ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b86d9c904db4ce79165891147aac5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_599bf8a9a63848deb44745a6533f0886",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b86b892400de47bab9cdc0e1510f97cd",
              "IPY_MODEL_6ab628c30043421c950ff285f069df4a"
            ]
          }
        },
        "599bf8a9a63848deb44745a6533f0886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b86b892400de47bab9cdc0e1510f97cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a358082a1d43455289807b0d3ecef4f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ebce487a324744edb7eeb2e8f4e907a9"
          }
        },
        "6ab628c30043421c950ff285f069df4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_249c3c0c2c5b428daf99f428648b1163",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10570/0 [00:00&lt;00:00, 67.87 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69b684f5bdab49278d8abf0b10560724"
          }
        },
        "a358082a1d43455289807b0d3ecef4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ebce487a324744edb7eeb2e8f4e907a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "249c3c0c2c5b428daf99f428648b1163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69b684f5bdab49278d8abf0b10560724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8696fd5d7a2c46cab197c3a57b825fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a5f0b0c08b44525819576e1ba2c38f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e77884808254fb083a5817991863038",
              "IPY_MODEL_303be251bef047f7bc091a7e6a85f269"
            ]
          }
        },
        "0a5f0b0c08b44525819576e1ba2c38f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e77884808254fb083a5817991863038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2f1996c8136a4e70a15a75a48b1ae0d8",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1726,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1726,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_503d7040c4c348b9a3dc7d6fc8fe6032"
          }
        },
        "303be251bef047f7bc091a7e6a85f269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_596ef7946bb043898c096864452b5bf4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.51k/? [00:00&lt;00:00, 5.54kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4779b0410b24f498e69a1fc02ce92a1"
          }
        },
        "2f1996c8136a4e70a15a75a48b1ae0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "503d7040c4c348b9a3dc7d6fc8fe6032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "596ef7946bb043898c096864452b5bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4779b0410b24f498e69a1fc02ce92a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "647cca86c92c4dbdb9e9e6ed699a62b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5341c612d11048ec896fc31e4dd4b4a0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_53c82621c8864e88b411a955de971e61",
              "IPY_MODEL_0d9dfbe7e3244df39768aa4694e25498"
            ]
          }
        },
        "5341c612d11048ec896fc31e4dd4b4a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53c82621c8864e88b411a955de971e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e1ece884bc374fbfafd916c29a0cb69c",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1132,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1132,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00bbd1b0340d4beba26c27fba984c354"
          }
        },
        "0d9dfbe7e3244df39768aa4694e25498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35b770b0b2cc4073bd51ef5c6cab5034",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.35k/? [12:31&lt;00:00, 4.45B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35d2a3fef79c4b4888297c7d257c39d5"
          }
        },
        "e1ece884bc374fbfafd916c29a0cb69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00bbd1b0340d4beba26c27fba984c354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35b770b0b2cc4073bd51ef5c6cab5034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35d2a3fef79c4b4888297c7d257c39d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d531efa1f7be4516bdb40dfb54d301ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d711ace88ea14b4a8f1cc13c2067e27a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8dd237a9c22b465d8d28aae8376d2d88",
              "IPY_MODEL_a816dfc2b49a4ccb9affa787879be877"
            ]
          }
        },
        "d711ace88ea14b4a8f1cc13c2067e27a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8dd237a9c22b465d8d28aae8376d2d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ccfa05a5220348f8bae5a28cde8692e2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8944ec8077b4aec84bf788f2d5400e3"
          }
        },
        "a816dfc2b49a4ccb9affa787879be877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1125c62667ec4b0cb546b1e38c1f2f8d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [4:47:08&lt;00:00, 172.28s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_187db8890da649d6845a6b99a325c800"
          }
        },
        "ccfa05a5220348f8bae5a28cde8692e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8944ec8077b4aec84bf788f2d5400e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1125c62667ec4b0cb546b1e38c1f2f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "187db8890da649d6845a6b99a325c800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjori66/Kaist-AI605-2021-Spring/blob/main/KAIST_AI605_Assignment_2_20194364.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReonT_YasRSx"
      },
      "source": [
        "# KAIST AI605 Assignment 2: Token Classification with RNNs and Attention\n",
        "Author: Minjoon Seo (minjoon@kaist.ac.kr)\n",
        "\n",
        "TA in charge: Taehyung Kwon (taehyung.kwon@kaist.ac.kr)\n",
        "\n",
        "**Due date**:  April 19 (Mon) 11:00pm, 2021  \n",
        "\n",
        "\n",
        "Your name: Taehwan Kim\n",
        "\n",
        "Your student ID: 20194364\n",
        "\n",
        "Your collaborators: -\n",
        "\n",
        "## Assignment Objectives\n",
        "- Verify theoretically and empirically how Transformer's attention mechanism works for sequence modeling task.\n",
        "- Implement Transformer's encoder attention layer from scratch using PyTorch.\n",
        "- Design an Attention-based token classification model using PyTorch.\n",
        "- Apply the token classification model to a popular machine reading comprehension task, Stanford Question Answering Dataset (SQuAD).\n",
        "- (Bonus) Analyze pros and cons between using RNN + attention versus purely attention.\n",
        "\n",
        "## Your Submission\n",
        "Your submission will be a link to a Colab notebook that has all written answers and is fully executable. You will submit your assignment via KLMS. Use in-line LaTeX (see below) for mathematical expressions. Collaboration among students is allowed but it is not a group assignment so make sure your answer and code are your own. Also make sure to mention your collaborators in your assignment with their names and their student ids.\n",
        "\n",
        "## Grading\n",
        "The entire assignment is out of 100 points. There are two bonus questions with 30 points altogether. Your final score can be higher than 100 points.\n",
        "\n",
        "\n",
        "## Environment\n",
        "You will only use Python 3.7 and PyTorch 1.8, which is already available on Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qwta269rqLQ",
        "outputId": "8a952186-86dc-4441-e63f-1cce9586bc2b"
      },
      "source": [
        "from platform import python_version\n",
        "import torch\n",
        "\n",
        "print(\"python\", python_version())\n",
        "print(\"torch\", torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python 3.7.10\n",
            "torch 1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTm5eq4NwQZs"
      },
      "source": [
        "## 1. Transformer's Attention Layer\n",
        "\n",
        "We will first start with going over a few concepts that you learned in your high school statistics class. The variance of a random variable $X$, $\\text{Var}(X)$ is defined as $\\text{E}[(X-\\mu)^2]$ where $\\mu$ is the mean of $X$. Furthermore, given two independent random variables $X$ and $Y$ and a constant $a$,\n",
        "$$ \\text{Var}(X+Y) = \\text{Var}(X) + \\text{Var}(Y), \\quad \\ldots \\; \\text{(1)}$$ \n",
        "$$ \\text{Var}(aX) = a^2\\text{Var}(X), \\quad \\ldots \\; \\text{(2)}$$\n",
        "$$ \\text{Var}(XY) = \\text{E}(X^2)\\text{E}(Y^2) - [\\text{E}(X)]^2[\\text{E}(Y)]^2. \\quad \\ldots \\; \\text{(3)}$$\n",
        "\n",
        "**Problem 1.1** *(10 points)* Suppose we are given two sets of $n$ random variables, $X_1 \\dots X_n$ and $Y_1 \\dots Y_n$, where all of these $2n$ variables are mutually independent and have a mean of $0$ and a variance of $1$. Prove that\n",
        "$$\\text{Var}\\left(\\sum_i^n X_i Y_i\\right) = n.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDO1QDJOXza8"
      },
      "source": [
        "There is a typo in the formula $\\text{(2)}$. I changed it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3ULLzK0NOPA"
      },
      "source": [
        "**Answer 1.1** \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "  \\text{Var}\\left(\\sum_i^n X_i Y_i\\right)\n",
        "  &= \\sum_i^n \\text{Var} \\left(X_i Y_i\\right) \\quad \\because \\text{(1), independence} \\\\\n",
        "  &= \\sum_i^n \\left[\\text{E}(X_i^2)\\text{E}(Y_i^2) - [\\text{E}(X_i)]^2[\\text{E}(Y_i)]^2 \\right] \\quad \\because \\text{(3)} \\\\\n",
        "  &= \\sum_i^n \\left[\\text{E}((X_i-0)^2)\\text{E}((Y_i-0)^2)\\right] \\\\\n",
        "  &= \\sum_i^n \\left[\\text{E}((X_i-[\\text{E}(X_i)])^2)\\text{E}((Y_i-[\\text{E}(Y_i)])^2)\\right] \\\\\n",
        "  &= \\sum_i^n \\left[\\text{Var}(X_i) \\text{Var}(Y_i)\\right] \\\\\n",
        "  &= \\sum_i^n \\left[1\\right] = n \\\\\n",
        "\\end{align}\n",
        "\\\\\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KIelEM56jn_"
      },
      "source": [
        "In Lecture 08 and 09, we discussed how the attention is computed in Transformer via the following equation,\n",
        "$$ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V.$$\n",
        "**Problem 1.2** *(10 points)*  Suppose $Q$ and $K$ are matrices of independent variables each of which has a mean of $0$ and a variance of $1$. Using what you learned from Problem 1.1., show that\n",
        "$$\\text{Var}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right) = 1.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wNoM7FtW0gi"
      },
      "source": [
        "**Answer 1.2** \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "  \\text{Var}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)\n",
        "  &= \\left(\\frac{1}{\\sqrt{d_k}}\\right)^2 \\text{Var}\\left(QK^\\top\\right)  \\quad \\because \\text{(2)} \\\\\n",
        "  &= \\frac{1}{d_k} \\text{Var}\\left(QK^\\top\\right) \\\\\n",
        "\\end{align}\n",
        "\\\\\n",
        "\\\\\n",
        "$$\n",
        "\n",
        "Then, we can focus on the one element of $QK$, $\\left(QK\\right)_{ij}$ without loss of generality.\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "  \\frac{1}{d_k} \\text{Var}\\left(\\left(QK\\right)_{ij}^\\top\\right)\n",
        "  &= \\frac{1}{d_k} \\text{Var}\\left(\\sum_{t}^{d_k} \\left(Q_{it} K_{tj}\\right) \\right) \\\\\n",
        "  &= \\frac{1}{d_k} \\left(\\sum_{t}^{d_k} \\text{Var}\\left(Q_{it} K_{tj}\\right) \\right) \\quad \\because \\text{(1), } Q_{it} \\text{ and } Y_{tj} \\text{ are mutually independent} \\\\\n",
        "  &= \\frac{1}{d_k} \\left(d_k\\right) = 1 \\quad \\because \\text{Problem 1.1} \\\\\n",
        "\\end{align}\n",
        "\\\\\n",
        "$$\n",
        "\n",
        "Therefore, \n",
        "\n",
        "$$\n",
        "\\text{Var}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right) = 1.\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU3a3FEu6loq"
      },
      "source": [
        "\n",
        "**Problem 1.3** *(10 points)* What would happen if the assumption that the variance of $Q$ and $K$ is $1$ does not hold? Consider each case of it being higher and lower than $1$ and conjecture what it implies, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS4xjbWnmZL7"
      },
      "source": [
        "**Answer 1.3** \\\n",
        "\n",
        "If the variance of $Q_{ij}$ and $K_{ij}$ is higher than 1 for all i and j, then\n",
        "\n",
        "$$\n",
        "\\text{Var}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right) > 1.\n",
        "$$\n",
        "\n",
        "Then, the variance of the output of the decoder becomes larger.\n",
        "If we use the softmax function on this output, then the final result might be \"too\" sharp. (Actually, this is not true, because of the residual connection) \\\n",
        "So, I guess that the model overfits faster than original model.\n",
        "\n",
        "\\\n",
        "\n",
        "Otherwse, if the variance of $Q_{ij}$ and $K_{ij}$ is lower than 1 for all i and j, then\n",
        "\n",
        "$$\n",
        "\\text{Var}\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right) < 1.\n",
        "$$\n",
        "\n",
        "Then, the variance of the output of the decoder becomes smaller.\n",
        "If we use the softmax function on this output, then the final result might be \"too\" smooth. \n",
        "\\\n",
        "So, I guess that the early training would be more unstable than normal although we use the bigger learning rate. The training time would be longer than the original version. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtGo8MAt7By2"
      },
      "source": [
        "## 2. Preprocessing SQuAD\n",
        "\n",
        "We will use `datasets` package offered by Hugging Face, which allows us to easily download various language datasets, including Stanford Question Answering Dataset (SQuAD).\n",
        "\n",
        "First, install the package:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEGhK5tO8DcT",
        "outputId": "dd93c619-0c17-48e5-8e03-0754a24ed1ab"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/d6/a3d2c55b940a7c556e88f5598b401990805fc0f0a28b2fc9870cf0b8c761/datasets-1.6.0-py3-none-any.whl (202kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20kB 13.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 30kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 61kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 102kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 112kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 122kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 133kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 143kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 153kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 163kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 174kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 184kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 194kB 6.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 44.4MB/s \n",
            "\u001b[?25hCollecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 53.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Collecting huggingface-hub<0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: pyarrow>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, fsspec, huggingface-hub, datasets\n",
            "Successfully installed datasets-1.6.0 fsspec-2021.4.0 huggingface-hub-0.0.8 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lrJLeSG8Xkl"
      },
      "source": [
        "Then, download SQuAD and print the first example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288,
          "referenced_widgets": [
            "175819bd3f5c4ca58a4d72db4076bedd",
            "182e93143167407ab1d2942b828fb325",
            "82fc39b2a53f43eab188fb21b078bc9f",
            "b21b0aa73c55452e88998632b828771d",
            "ec56032d086c419f805664c76f469ea7",
            "bdd9f2a5aa3b4760aa3ff5fc45d6a0f1",
            "548e33dd42dd4182bb3fdfc779e52925",
            "e32b10fcf53d4d63b4cd6a34f2b17c5b",
            "bbc7e487a19c4762b5bb8ebca2f7203a",
            "3a57e0e01a744cda91b59c99d4b5e75e",
            "da0a5cfda34f4ed1b319377d8d205d01",
            "0bd5c6dd5c7341f99834ff05b91f3537",
            "d9e043b8d7bb45be8c869ba79203be5e",
            "3d58fca7bd844fe2b573b1f595390704",
            "b706dd3c513449c6af8580d65d971997",
            "6614604ea8b04b70bfd522b5b1e9da52",
            "56e128be787d433ea98e6d720b5914e1",
            "bcdf3ade83264159a63dddc479af286a",
            "c6792178ff9a4522bb75d82d160e55c6",
            "bbeb6f85bef94fd681296fe9488e2c79",
            "eea73274970343d6a3cc3dfc99f0625f",
            "dd274f910de04176b42dc5e6e1bcc436",
            "65a509dfe73e463c9f6f7046d9f3ec3a",
            "aeb57804c3a84f48acf0b9bce939bcd6",
            "b9fb7c9c011141669594da9ec3003f05",
            "6fa4f97d1f4841c2bf5dc4321797b19b",
            "65f046877a824f2c87e3a8a30556bc46",
            "8173ed65404a4164bf98dcc7e9ed5167",
            "1c9b2315129043e0b2048ba17aa1667d",
            "ee2d23fcf2414e17b86cbd9561bd3e55",
            "50126fb07ff64d77b922d1519aaab6b7",
            "797f85ff19364765946f6124eed87c8b",
            "73a939a47602489fabdd2f87b7466965",
            "2753f18c4223402189ea57177d6cc7f2",
            "c253bf6e5fc54a36bf8b63f232dbfd1f",
            "9dc98568e8e141e48286d7be0722efbe",
            "a8b718765a4040e7b81d410847801eb9",
            "5d1c28ffaa2947b1b48554470b760f13",
            "dc75836985444b8cb2095d8f948fe0ce",
            "a891dd13d5a94d49abcdb2e128b82ff1",
            "3b86d9c904db4ce79165891147aac5fc",
            "599bf8a9a63848deb44745a6533f0886",
            "b86b892400de47bab9cdc0e1510f97cd",
            "6ab628c30043421c950ff285f069df4a",
            "a358082a1d43455289807b0d3ecef4f3",
            "ebce487a324744edb7eeb2e8f4e907a9",
            "249c3c0c2c5b428daf99f428648b1163",
            "69b684f5bdab49278d8abf0b10560724"
          ]
        },
        "id": "ePc6IF9I8Jg1",
        "outputId": "2427783a-a671-4d8f-cd7f-b86ecaf0ba6a"
      },
      "source": [
        "from datasets import load_dataset\n",
        "squad_dataset = load_dataset('squad')\n",
        "print(squad_dataset['train'][0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "175819bd3f5c4ca58a4d72db4076bedd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1877.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbc7e487a19c4762b5bb8ebca2f7203a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=955.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.75 MiB, post-processed: Unknown size, total: 119.27 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56e128be787d433ea98e6d720b5914e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=8116577.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9fb7c9c011141669594da9ec3003f05",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1054280.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73a939a47602489fabdd2f87b7466965",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b86d9c904db4ce79165891147aac5fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a. Subsequent calls will reuse this data.\n",
            "{'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']}, 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'id': '5733be284776f41900661182', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'title': 'University_of_Notre_Dame'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIzhbD6a81Q6"
      },
      "source": [
        "Here, `answer_start` corresponds to the character-level start position of the answer, and `text` is the answer text itself. You will note that `answer_start` and `text` fields are given as lists but they only contain one item each. In fact, you can safely assume that this is the case for the training data. During evaluation, however, you will utilize several possible answers so that your evaluation can be compared against all of them. So your code need to handle multiple-answers case as well.\n",
        "\n",
        "As we discussed in Lecture 05, we want to formulate this task as a token classification problem. That is, we want to find which token of the context corresponds to the start position of the answer, and which corresponds to the end.\n",
        "\n",
        "**Problem 2.1** *(10 points)* Write `preprocess()` function that takes a SQuAD example as the input and outputs space-tokenized context and question, as well as the start and end token position of the answer if it has the answer field. That is, a pseudo code would look like:\n",
        "```python\n",
        "def preprocess(example):\n",
        "  out = {'context': ['each', 'token'], \n",
        "         'question': ['each', 'token']}\n",
        "  if 'answers' not in example:\n",
        "    return out\n",
        "  out['answers'] = [{'start': 3, 'end': 5}]\n",
        "  return out\n",
        "```\n",
        "Verify that this code works by comparing between the original answer text and the concatenation of the answer tokens from start to end in training data. Report the percentage of the questions that have exact match."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiBkG_u_1D2l"
      },
      "source": [
        "**Answer 2.1**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtoL89-n1H1a",
        "outputId": "4d2e6607-51a9-406d-ab52-56f226be1c94"
      },
      "source": [
        "def preprocess(example):\n",
        "    def tokenizer(sentence):\n",
        "        if sentence is None:\n",
        "            return list()\n",
        "        return sentence.split()\n",
        "    out = dict()\n",
        "\n",
        "    answer = example['answers']['text'][0]\n",
        "    answer_start = example['answers']['answer_start'][0]\n",
        "    answer_end = answer_start + len(answer)\n",
        "    context = example['context']\n",
        "    question = example['question']\n",
        "\n",
        "    out['context'] = tokenizer(context)\n",
        "    out['question'] = tokenizer(question)\n",
        "\n",
        "    if (answer_start == 0 or context[answer_start-1] == ' ') \\\n",
        "        and (answer_end == len(context) or context[answer_end] == ' '):\n",
        "        n_tokens_before_answer = len(tokenizer(context[:answer_start]))\n",
        "        n_tokens_answer = len(tokenizer(answer))\n",
        "        out['answers'] = [{'start': n_tokens_before_answer, 'end': n_tokens_before_answer+n_tokens_answer}]\n",
        "\n",
        "    return out\n",
        "\n",
        "n_exact_match = 0.0\n",
        "for i, example in enumerate(squad_dataset['train']):\n",
        "    out = preprocess(example)\n",
        "    if 'answers' in out.keys():\n",
        "        n_exact_match += 1\n",
        "\n",
        "print(\"number of answers that have exact match : \", n_exact_match)\n",
        "print(\"number of training data : \", len(squad_dataset['train']))\n",
        "print(\"the percentage of the exact match : \", n_exact_match / len(squad_dataset['train']))\n",
        "\n",
        "# number of answers that have exact match : 45983.0\n",
        "# number of training data : 87599\n",
        "# the percentage of the exact match : 0.5249260836310917 -> pretty low\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of answers that have exact match :  45983.0\n",
            "number of training data :  87599\n",
            "the percentage of the exact match :  0.5249260836310917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wikI9OxVCL0E"
      },
      "source": [
        "We want to maximize the percentage of the exact match. You might see a low percentage however, due to bad tokenization. For instance, such space-based tokenization will fail to separate between \"world\" and \"!\" in \"hello world!\". \n",
        "\n",
        "**Problem 2.2** *(10 points)* Write an advanced tokenization model that always separates non-alphabet characters as independent tokens. For instance, \"hello1 world!!\" will be tokenized into \"hello\", \"1\", \"world\", \"!\", and \"!\". Using this new tokenizer, re-run the `preprocess` function and report the exact match percentage. How does the ratio change?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0SqpETMGUkW"
      },
      "source": [
        "**Answer 2.2**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UHzcv-7GWla"
      },
      "source": [
        "def find_nonalpha_list(dataset):\n",
        "    nonalpha_list = list()\n",
        "    for example in dataset:\n",
        "        for c in example['context']:\n",
        "            if not c.isalpha() and c not in nonalpha_list:\n",
        "                nonalpha_list.append(c)\n",
        "        for c in example['question']:\n",
        "            if not c.isalpha() and c not in nonalpha_list:\n",
        "                nonalpha_list.append(c)\n",
        "    return nonalpha_list\n",
        "\n",
        "\n",
        "def preprocess(example, nonalpha_list):\n",
        "    def tokenizer(sentence, nonalpha_list):\n",
        "        if sentence is None:\n",
        "            return list()\n",
        "\n",
        "        for nonalpha_token in nonalpha_list:\n",
        "            sentence = sentence.replace(nonalpha_token, ' ' + nonalpha_token + ' ')\n",
        "\n",
        "        sentence = ' '.join(sentence.split())\n",
        "        return sentence.split()\n",
        "    out = dict()\n",
        "\n",
        "    answer = example['answers']['text'][0]\n",
        "    answer_start = example['answers']['answer_start'][0]\n",
        "    answer_end = answer_start + len(answer)\n",
        "    context = example['context']\n",
        "    question = example['question']\n",
        "\n",
        "    out['context'] = tokenizer(context, nonalpha_list)\n",
        "    out['question'] = tokenizer(question, nonalpha_list)\n",
        "\n",
        "    if (answer_start == 0 or context[answer_start-1] in nonalpha_list) \\\n",
        "        and (answer_end == len(context) or context[answer_end] in nonalpha_list):\n",
        "        n_tokens_before_answer = len(tokenizer(context[:answer_start], nonalpha_list))\n",
        "        n_tokens_answer = len(tokenizer(answer, nonalpha_list))\n",
        "        out['answers'] = [{'start': n_tokens_before_answer, 'end': n_tokens_before_answer+n_tokens_answer-1}]\n",
        "\n",
        "    return out\n",
        "\n",
        "# train_dataset = squad_dataset['train']\n",
        "# nonalpha_list = find_nonalpha_list(train_dataset)\n",
        "# print(\"nonalpha_list : \", nonalpha_list)\n",
        "\n",
        "# n_exact_match = 0.0\n",
        "# for i, example in enumerate(squad_dataset['train']):\n",
        "#   out = preprocess(example, nonalpha_list)\n",
        "#   if 'answers' in out.keys():\n",
        "#     n_exact_match += 1\n",
        "\n",
        "# print(\"number of answers that have exact match : \", n_exact_match)\n",
        "# print(\"number of training data : \", len(squad_dataset['train']))\n",
        "# print(\"the percentage of the exact match : \", n_exact_match / len(squad_dataset['train']))\n",
        "\n",
        "\n",
        "# nonalpha_list :  [',', ' ', '.', \"'\", '\"', '1', '8', '5', '(', '3', ')', '?', '-', '7', '6', '9', '2', '0', ';', '–', '&', '4', '%', '$', '[', ']', '/', ':', '#', '—', '!', '“', '’', '”', '<', '\\u200b', '̃', '£', '½', '+', '¢', '−', '°', '>', '€', '《', '》', '±', '~', '¥', '²', '❤', '=', '\\u200e', '͡', '́', '`', '्', 'ु', 'ः', 'ॊ', 'ि', 'ा', '\\u200d', '\\u200c', '*', '‘', '\\u3000', '•', '§', '⁄', '\\n', '̯', '̩', '…', '·', 'ָ', 'ִ', 'ׁ', 'ַ', 'ּ', 'ְ', 'ّ', '⟨', '◌', '⟩', '˭', '̤', '♠', '∅', '̞', '×', '̥', '′', '″', '\\ufeff', '_', 'ֿ', '´', '^', '̧', '̄', '→', '‑', '，', '₹', '\\u202f', '♯', '₂', '₥', '⁊', '\\u2009', '{', '}', '|', '@', '̪', '‚', '›', 'ׂ', 'ֵ', 'ِ', 'ْ', 'َ', '̍', '˥', '˨', '˩', '¡', '√', '¿', 'ာ', 'း', 'ُ', '≥', '˚', '≈', '⋅', 'ี', '︘', '�', '～', '〜', '̀', 'ོ', '་', '˧', 'ಾ', 'ು', '್', 'া', '্', 'ಿ', '∗', '∈', '≡', '∖', '№', '÷', 'ٔ', '¶', 'ิ', '₤', '♆', '⅓', '∝', '¼', 'ٍ', 'ֹ', '̌', '。', '̠', '₯']\n",
        "# number of answers that have exact match :  87108.0\n",
        "# number of training data :  87599\n",
        "# the percentage of the exact match :  0.9943949131839405 -> now, it is OK\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJtJXDSvDpE8"
      },
      "source": [
        "## 3. LSTM Baseline for SQuAD\n",
        "\n",
        "We will bring and reuse our model from Assignment 1. There are two key differences, however. First, we need to classify each token instead of the entire sentence. Second, we have two inputs (context and question) instead of just one.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX3hFmUAVD9K",
        "outputId": "497e50f8-0f88-4b09-aa9b-04fb614008f0"
      },
      "source": [
        "# My model from Assignment 1 is too slow to use it.\n",
        "# I will use torchtext and torch.nn.lstm in the assignment 2.\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "from torchtext.legacy.data import BucketIterator\n",
        "\n",
        "\n",
        "class SQuAD1Dataset(data.Dataset):\n",
        "  \"\"\"\n",
        "  Defines a dataset for squad1.0.\n",
        "  \"\"\"\n",
        "  \n",
        "  @staticmethod\n",
        "  def sort_key(ex):\n",
        "    return data.interleave_keys(len(ex.context), len(ex.question))\n",
        "\n",
        "  def __init__(self, data_list, fields, max_length=None, **kwargs):\n",
        "    if not isinstance(fields[0], (tuple, list)):\n",
        "      fields = [('context', fields[0]), \n",
        "                ('question', fields[1]), \n",
        "                ('answer_start', fields[2]), \n",
        "                ('answer_end', fields[3])\n",
        "                ]\n",
        "\n",
        "    examples = []\n",
        "    nonalpha_list = find_nonalpha_list(data_list)\n",
        "    for example in data_list:\n",
        "        out = preprocess(example, nonalpha_list)\n",
        "        # use data if the answer exists\n",
        "        if max_length and max_length < max(len(out['context']), len(out['question'])):\n",
        "            continue\n",
        "        if 'answers' in out.keys():\n",
        "            examples.append(data.Example.fromlist([out['context'], \n",
        "                                                   out['question'], \n",
        "                                                   out['answers'][0]['start'], \n",
        "                                                   out['answers'][0]['end']], \n",
        "                                                  fields))\n",
        "\n",
        "    super(SQuAD1Dataset, self).__init__(examples, fields, **kwargs)\n",
        "\n",
        "\n",
        "class SQuAD1Dataloader():\n",
        "  \"\"\"\n",
        "  Make the dataloader for SQuAD 1.0\n",
        "  \"\"\"\n",
        "  def __init__(self, train_data=None, valid_data=None, batch_size=64, device='cpu', \n",
        "                max_length=255, min_freq=2, fix_length=None,\n",
        "                use_bos=True, use_eos=True, shuffle=True\n",
        "              ):\n",
        "\n",
        "    super(SQuAD1Dataloader, self).__init__()\n",
        "\n",
        "    self.text = data.Field(sequential=True, use_vocab=True, batch_first=True, \n",
        "                           include_lengths=True, fix_length=fix_length, \n",
        "                           init_token='<BOS>' if use_bos else None, \n",
        "                           eos_token='<EOS>' if use_eos else None\n",
        "                          )\n",
        "    # self.context = data.Field(sequential=True, use_vocab=True, batch_first=True, \n",
        "    #                        include_lengths=True, fix_length=fix_length, \n",
        "    #                        init_token='<BOS>' if use_bos else None, \n",
        "    #                        eos_token='<EOS>' if use_eos else None\n",
        "    #                       )\n",
        "    # self.question = data.Field(sequential=True, use_vocab=True, batch_first=True, \n",
        "    #                            include_lengths=True, fix_length=fix_length, \n",
        "    #                            init_token='<BOS>' if use_bos else None, \n",
        "    #                            eos_token='<EOS>' if use_eos else None\n",
        "    #                           )\n",
        "    self.answer_start = data.Field(sequential = False, use_vocab = False)\n",
        "    self.answer_end = data.Field(sequential = False, use_vocab = False)\n",
        "    \n",
        "    train = SQuAD1Dataset(data_list=train_data, \n",
        "                          fields = [('context', self.text),\n",
        "                                    ('question', self.text),\n",
        "                                    ('answer_start', self.answer_start),\n",
        "                                    ('answer_end', self.answer_end)\n",
        "                                    ], \n",
        "                          max_length = max_length\n",
        "                          )\n",
        "    valid = SQuAD1Dataset(data_list=valid_data, \n",
        "                          fields = [('context', self.text),\n",
        "                                    ('question', self.text),\n",
        "                                    ('answer_start', self.answer_start),\n",
        "                                    ('answer_end', self.answer_end)\n",
        "                                    ], \n",
        "                          max_length = max_length\n",
        "                          )\n",
        "    \n",
        "    self.train_iter = data.BucketIterator(train, batch_size=batch_size,\n",
        "                                          device=device,\n",
        "                                          shuffle=shuffle,\n",
        "                                          sort_key=lambda x: len(x.question) + (max_length * len(x.context)), \n",
        "                                          sort_within_batch = True\n",
        "                                          )\n",
        "    self.valid_iter = data.BucketIterator(valid, batch_size=batch_size,\n",
        "                                          device=device,\n",
        "                                          shuffle=shuffle,\n",
        "                                          sort_key=lambda x: len(x.question) + (max_length * len(x.context)), \n",
        "                                          sort_within_batch = True\n",
        "                                          )\n",
        "    \n",
        "    self.text.build_vocab(train)\n",
        "    # self.context.build_vocab(train)\n",
        "    # self.question.build_vocab(train)\n",
        "\n",
        "\n",
        "# train_data, test_data = torchtext.datasets.SQuAD1(root='.data', split=('train', 'dev'))\n",
        "\n",
        "# TEXT = data.Field(init_token='<SOS>', eos_token='<EOS>', lower=True)\n",
        "# LABEL = data.LabelField(dtype = torch.long)\n",
        "\n",
        "# train_data, test_data = data.TabularDataset.splits(\n",
        "#   path='glue_data/SST-2', train='train.tsv', test='dev.tsv', format='tsv',\n",
        "#   fields=[('text', TEXT), ('label', LABEL)], skip_header=True\n",
        "# )\n",
        "\n",
        "train_dataset = squad_dataset['train']\n",
        "valid_dataset = squad_dataset['validation']\n",
        "\n",
        "print('# of train data : {}'.format(len(train_dataset)))\n",
        "print('# of vaild data : {}'.format(len(valid_dataset)))\n",
        "\n",
        "batch_size = 128\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "max_length = 255\n",
        "min_freq = 2\n",
        "print(\"device : \", device)\n",
        "\n",
        "loader = SQuAD1Dataloader(train_dataset, valid_dataset, batch_size=batch_size, \n",
        "                          device=device, max_length=max_length, min_freq=min_freq)\n",
        "print('\\nFinish making the dataloader')\n",
        "print(\"batch_size : \", batch_size)\n",
        "print(\"max_length : \", max_length)\n",
        "print('# of used train data ~ {}'.format((len(loader.train_iter)) * batch_size))\n",
        "print('# of used vaild data ~ {}'.format((len(loader.valid_iter)) * batch_size))\n",
        "\n",
        "vocab = loader.text.vocab\n",
        "print('# of vocab : {}'.format(len(vocab)))\n",
        "\n",
        "# # of train data : 87599\n",
        "# # of vaild data : 10570\n",
        "# device :  cuda\n",
        "\n",
        "# Finish making the dataloader\n",
        "# batch_size :  128\n",
        "# max_length :  255\n",
        "# # of used train data ~ 81536\n",
        "# # of used vaild data ~ 9856\n",
        "# # of vocab : 86580"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of train data : 87599\n",
            "# of vaild data : 10570\n",
            "device :  cuda\n",
            "\n",
            "Finish making the dataloader\n",
            "batch_size :  128\n",
            "max_length :  255\n",
            "# of used train data ~ 81536\n",
            "# of used vaild data ~ 9856\n",
            "# of vocab : 86580\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhrgT3Xc11yw"
      },
      "source": [
        "\n",
        "Before resolving these differences, you will need to define your evaluation function to correctly evaluate how well your model is doing. Note that the evaluation was very straightforward in Assignment 1's sentiment classification (it is either positive or negative) while it is a bit complicated in SQuAD. We will use the evaluation function provided by `datasets`. You can access to it via the following code.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLMA7wXjHkxP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "8696fd5d7a2c46cab197c3a57b825fbe",
            "0a5f0b0c08b44525819576e1ba2c38f4",
            "5e77884808254fb083a5817991863038",
            "303be251bef047f7bc091a7e6a85f269",
            "2f1996c8136a4e70a15a75a48b1ae0d8",
            "503d7040c4c348b9a3dc7d6fc8fe6032",
            "596ef7946bb043898c096864452b5bf4",
            "c4779b0410b24f498e69a1fc02ce92a1",
            "647cca86c92c4dbdb9e9e6ed699a62b4",
            "5341c612d11048ec896fc31e4dd4b4a0",
            "53c82621c8864e88b411a955de971e61",
            "0d9dfbe7e3244df39768aa4694e25498",
            "e1ece884bc374fbfafd916c29a0cb69c",
            "00bbd1b0340d4beba26c27fba984c354",
            "35b770b0b2cc4073bd51ef5c6cab5034",
            "35d2a3fef79c4b4888297c7d257c39d5"
          ]
        },
        "outputId": "cd81df75-9471-47aa-a28c-d5d71e1f99a5"
      },
      "source": [
        "from datasets import load_metric\n",
        "squad_metric = load_metric('squad')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8696fd5d7a2c46cab197c3a57b825fbe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1726.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "647cca86c92c4dbdb9e9e6ed699a62b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1132.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7smOVxqXJxyB"
      },
      "source": [
        "You can also easily learn about how to use the function by simply typing the function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr7rl9ihHsdx",
        "outputId": "00d6f6cd-ac3c-488c-943c-1f3f1f086f67"
      },
      "source": [
        "squad_metric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metric(name: \"squad\", features: {'predictions': {'id': Value(dtype='string', id=None), 'prediction_text': Value(dtype='string', id=None)}, 'references': {'id': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}}, usage: \"\"\"\n",
              "Computes SQuAD scores (F1 and EM).\n",
              "Args:\n",
              "    predictions: List of question-answers dictionaries with the following key-values:\n",
              "        - 'id': id of the question-answer pair as given in the references (see below)\n",
              "        - 'prediction_text': the text of the answer\n",
              "    references: List of question-answers dictionaries with the following key-values:\n",
              "        - 'id': id of the question-answer pair (see above),\n",
              "        - 'answers': a Dict in the SQuAD dataset format\n",
              "            {\n",
              "                'text': list of possible texts for the answer, as a list of strings\n",
              "                'answer_start': list of start positions for the answer, as a list of ints\n",
              "            }\n",
              "            Note that answer_start values are not taken into account to compute the metric.\n",
              "Returns:\n",
              "    'exact_match': Exact match (the normalized answer exactly match the gold answer)\n",
              "    'f1': The F-score of predicted tokens versus the gold answer\n",
              "Examples:\n",
              "\n",
              "    >>> predictions = [{'prediction_text': '1976', 'id': '56e10a3be3433e1400422b22'}]\n",
              "    >>> references = [{'answers': {'answer_start': [97], 'text': ['1976']}, 'id': '56e10a3be3433e1400422b22'}]\n",
              "    >>> squad_metric = datasets.load_metric(\"squad\")\n",
              "    >>> results = squad_metric.compute(predictions=predictions, references=references)\n",
              "    >>> print(results)\n",
              "    {'exact_match': 100.0, 'f1': 100.0}\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh72l3MtJW6D"
      },
      "source": [
        "**Problem 3.1** *(10 points)* Let's resolve the first issue here. Hence, for now, assume that your only input is context and you want to obtain the answer without seeing the question. While this may seem to be a non-sense, actually it can be considered as modeling the prior $\\text{Prob}(a|c)$ before observing $q$ (we ultimately want $\\text{Prob}(a|q,c)$). Transform your model into a token classification model by imposing $\\text{softmax}$ over the tokens instead of predefined classes. You will need to do this twice for each of start and end. Report the accuracy (using the metric above) on `squad_dataset['validation']`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PShlCxLcGai_"
      },
      "source": [
        "**Answer 3.1**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d531efa1f7be4516bdb40dfb54d301ea",
            "d711ace88ea14b4a8f1cc13c2067e27a",
            "8dd237a9c22b465d8d28aae8376d2d88",
            "a816dfc2b49a4ccb9affa787879be877",
            "ccfa05a5220348f8bae5a28cde8692e2",
            "f8944ec8077b4aec84bf788f2d5400e3",
            "1125c62667ec4b0cb546b1e38c1f2f8d",
            "187db8890da649d6845a6b99a325c800"
          ]
        },
        "id": "Gtkm4TsgGcem",
        "outputId": "6a40b0de-43f9-42bc-b260-8430e3c864f5"
      },
      "source": [
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class ClassificationLSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, n_layers, n_label, emb_dropout, rnn_dropout, bidirectional, enable_layer_norm, device):\n",
        "        super(ClassificationLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, \n",
        "                            hidden_size=hidden_dim, \n",
        "                            num_layers=n_layers, \n",
        "                            dropout=rnn_dropout, \n",
        "                            bidirectional=bidirectional)\n",
        "      \n",
        "        n_direction = 2 if bidirectional else 1\n",
        "        self.fc_start = nn.Linear(hidden_dim*n_direction, n_label, bias=True)\n",
        "        self.fc_end = nn.Linear(hidden_dim*n_direction, n_label, bias=True)\n",
        "\n",
        "        # Layer_normalization\n",
        "        if enable_layer_norm:\n",
        "            self.enable_layer_norm = enable_layer_norm\n",
        "            self.emb_layer_norm = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "        self.fc_dropout = nn.Dropout(rnn_dropout)\n",
        "        self.bidirectional = bidirectional\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, input_tensor, src_seq_lens):\n",
        "        emb = self.embedding(input_tensor) # emb.shape = batch * len * hidden\n",
        "\n",
        "        # Layer_normalization\n",
        "        if self.enable_layer_norm:\n",
        "            emb = self.emb_layer_norm(emb)\n",
        "\n",
        "        emb = self.emb_dropout(emb)\n",
        "        emb = emb.transpose(0, 1) # emb.shape = len * batch * hidden\n",
        "\n",
        "        # n_direction = 2 if bidirectional else 1\n",
        "        # hidden = torch.zeros(n_layers*n_direction, context.shape[0], hidden_dim, requires_grad=True).to(self.device)\n",
        "        # cell = torch.zeros(n_layers*n_direction, context.shape[0], hidden_dim, requires_grad=True).to(self.device)\n",
        "\n",
        "        # nn.LSTM\n",
        "        packed = pack_padded_sequence(emb, src_seq_lens.tolist(), batch_first=False)\n",
        "        outs, (hidden, cell) = self.lstm(packed)\n",
        "        outs, out_lens = pad_packed_sequence(outs, batch_first=False)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            hidden = torch.stack([hidden[-2], hidden[-1]], dim=0)\n",
        "        else:\n",
        "            hidden = hidden[-1].unsqueeze(dim=0)\n",
        "        hidden = hidden.transpose(0, 1)\n",
        "        hidden = hidden.contiguous().view(hidden.shape[0], -1)\n",
        "\n",
        "        hidden = self.fc_dropout(hidden)\n",
        "        logits_start = self.fc_start(hidden)\n",
        "        logits_end = self.fc_end(hidden)\n",
        "        return (logits_start, logits_end)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device : \", device)\n",
        "\n",
        "# Vocabulary\n",
        "vocab = loader.text.vocab\n",
        "print('# of vocab : {}'.format(len(vocab)))\n",
        "\n",
        "# Construct the LSTM Model\n",
        "embedding_dim = 128 # usually bigger, e.g. 128\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "n_label = max_length\n",
        "emb_dropout = 0.5\n",
        "rnn_dropout = 0.5\n",
        "bidirectional = True\n",
        "enable_layer_norm = True\n",
        "rnnmodel = ClassificationLSTMModel(embedding_dim, hidden_dim, n_layers, n_label, emb_dropout, rnn_dropout, bidirectional, enable_layer_norm, device).to(device)\n",
        "\n",
        "print(\"batch_size : \", batch_size)\n",
        "print(\"max_length : \", max_length)\n",
        "print(\"embedding_dim : \", embedding_dim)\n",
        "print(\"hidden_dim : \", hidden_dim)\n",
        "print(\"n_layers : \", n_layers)\n",
        "print(\"emb_dropout : \", emb_dropout)\n",
        "print(\"rnn_dropout_and_fc_dropout : \", rnn_dropout)\n",
        "if bidirectional:\n",
        "    print(\"bidirectional : True\")\n",
        "else:\n",
        "    print(\"bidirectional : False\")\n",
        "if enable_layer_norm:\n",
        "    print(\"enable_layer_norm : True\")\n",
        "else:\n",
        "    print(\"enable_layer_norm : False\")\n",
        "\n",
        "# Construct the data loader\n",
        "train_iter = loader.train_iter\n",
        "valid_iter = loader.valid_iter\n",
        "\n",
        "# Training\n",
        "learning_rate = 1e-3\n",
        "print(\"learning_rate : \", learning_rate)\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(rnnmodel.parameters(), lr=1e-1)\n",
        "optimizer = torch.optim.Adam(rnnmodel.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 100\n",
        "max_norm = 5\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0.0\n",
        "    train_data_num = 0\n",
        "    for i, train_batch in enumerate(train_iter):\n",
        "        context, context_length = train_batch.context\n",
        "        question, question_length = train_batch.question # Unused\n",
        "        answer_start = train_batch.answer_start\n",
        "        answer_end = train_batch.answer_end\n",
        "\n",
        "        logits_start, logits_end = rnnmodel(context, context_length)\n",
        "\n",
        "        optimizer.zero_grad() # reset process\n",
        "        loss = cel(logits_start, answer_start) + cel(logits_end, answer_end) # Loss, a.k.a L\n",
        "        loss.backward() # compute gradients\n",
        "        # print(torch.norm(rnnmodel.lstm.weight_hh_l0.grad), loss.item())\n",
        "        torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), max_norm) # gradent clipping\n",
        "        optimizer.step() # update parameters\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, train_start_preds = torch.max(logits_start, 1)\n",
        "        _, train_end_preds = torch.max(logits_end, 1)\n",
        "        train_accuracy += ((train_start_preds == answer_start) * (train_end_preds == answer_end)).sum().float()\n",
        "\n",
        "        train_data_num += context.shape[0]\n",
        "\n",
        "    print('train:: Epoch:', '%04d' % (epoch + 1), \n",
        "          'cost =', '{:.6f},'.format(train_loss / train_data_num), \n",
        "          'acc =', '{:.6f}'.format(train_accuracy / train_data_num))\n",
        "        \n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0\n",
        "            valid_accuracy = 0.0\n",
        "            valid_data_num = 0\n",
        "            for i, valid_batch in enumerate(valid_iter):\n",
        "                context, context_length = valid_batch.context\n",
        "                question, question_length = valid_batch.question # Unused\n",
        "                answer_start = valid_batch.answer_start\n",
        "                answer_end = valid_batch.answer_end\n",
        "\n",
        "                logits_start, logits_end = rnnmodel(context, context_length)\n",
        "\n",
        "                loss = cel(logits_start, answer_start) + cel(logits_end, answer_end) # Loss, a.k.a L\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                _, valid_start_preds = torch.max(logits_start, 1)\n",
        "                _, valid_end_preds = torch.max(logits_end, 1)\n",
        "                valid_accuracy += ((valid_start_preds == answer_start) * (valid_end_preds == answer_end)).sum().float()\n",
        "\n",
        "                valid_data_num += context.shape[0]\n",
        "                \n",
        "            print('valid:: Epoch:', '%04d' % (epoch + 1), \n",
        "                  'cost =', '{:.6f},'.format(valid_loss / valid_data_num), \n",
        "                  'acc =', '{:.6f}'.format(valid_accuracy / valid_data_num))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device :  cuda\n",
            "# of vocab : 86580\n",
            "batch_size :  128\n",
            "max_length :  255\n",
            "embedding_dim :  128\n",
            "hidden_dim :  256\n",
            "n_layers :  2\n",
            "emb_dropout :  0.5\n",
            "rnn_dropout_and_fc_dropout :  0.5\n",
            "bidirectional : True\n",
            "enable_layer_norm : True\n",
            "learning_rate :  0.001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d531efa1f7be4516bdb40dfb54d301ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "train:: Epoch: 0001 cost = 0.079719, acc = 0.005006\n",
            "valid:: Epoch: 0001 cost = 0.079650, acc = 0.008038\n",
            "train:: Epoch: 0002 cost = 0.079238, acc = 0.011238\n",
            "valid:: Epoch: 0002 cost = 0.079378, acc = 0.010887\n",
            "train:: Epoch: 0003 cost = 0.078947, acc = 0.014428\n",
            "valid:: Epoch: 0003 cost = 0.079393, acc = 0.015263\n",
            "train:: Epoch: 0004 cost = 0.078671, acc = 0.016857\n",
            "valid:: Epoch: 0004 cost = 0.079381, acc = 0.015364\n",
            "train:: Epoch: 0005 cost = 0.078378, acc = 0.019323\n",
            "valid:: Epoch: 0005 cost = 0.079433, acc = 0.017603\n",
            "train:: Epoch: 0006 cost = 0.078045, acc = 0.020894\n",
            "valid:: Epoch: 0006 cost = 0.079437, acc = 0.017705\n",
            "train:: Epoch: 0007 cost = 0.077747, acc = 0.023041\n",
            "valid:: Epoch: 0007 cost = 0.079812, acc = 0.020045\n",
            "train:: Epoch: 0008 cost = 0.077469, acc = 0.023544\n",
            "valid:: Epoch: 0008 cost = 0.079682, acc = 0.018010\n",
            "train:: Epoch: 0009 cost = 0.077185, acc = 0.025225\n",
            "valid:: Epoch: 0009 cost = 0.079765, acc = 0.020350\n",
            "train:: Epoch: 0010 cost = 0.076885, acc = 0.025838\n",
            "valid:: Epoch: 0010 cost = 0.079957, acc = 0.018824\n",
            "train:: Epoch: 0011 cost = 0.076621, acc = 0.027041\n",
            "valid:: Epoch: 0011 cost = 0.080207, acc = 0.020147\n",
            "train:: Epoch: 0012 cost = 0.076348, acc = 0.027728\n",
            "valid:: Epoch: 0012 cost = 0.080395, acc = 0.018926\n",
            "train:: Epoch: 0013 cost = 0.076129, acc = 0.027875\n",
            "valid:: Epoch: 0013 cost = 0.080784, acc = 0.017501\n",
            "train:: Epoch: 0014 cost = 0.075900, acc = 0.029175\n",
            "valid:: Epoch: 0014 cost = 0.080661, acc = 0.018417\n",
            "train:: Epoch: 0015 cost = 0.075648, acc = 0.029568\n",
            "valid:: Epoch: 0015 cost = 0.080756, acc = 0.019129\n",
            "train:: Epoch: 0016 cost = 0.075424, acc = 0.029985\n",
            "valid:: Epoch: 0016 cost = 0.080773, acc = 0.018722\n",
            "train:: Epoch: 0017 cost = 0.075172, acc = 0.030574\n",
            "valid:: Epoch: 0017 cost = 0.081082, acc = 0.017908\n",
            "train:: Epoch: 0018 cost = 0.075015, acc = 0.030881\n",
            "valid:: Epoch: 0018 cost = 0.081028, acc = 0.018010\n",
            "train:: Epoch: 0019 cost = 0.074765, acc = 0.031911\n",
            "valid:: Epoch: 0019 cost = 0.081345, acc = 0.016687\n",
            "train:: Epoch: 0020 cost = 0.074561, acc = 0.032157\n",
            "valid:: Epoch: 0020 cost = 0.081278, acc = 0.018926\n",
            "train:: Epoch: 0021 cost = 0.074393, acc = 0.032144\n",
            "valid:: Epoch: 0021 cost = 0.081425, acc = 0.020350\n",
            "train:: Epoch: 0022 cost = 0.074144, acc = 0.033101\n",
            "valid:: Epoch: 0022 cost = 0.081690, acc = 0.019027\n",
            "train:: Epoch: 0023 cost = 0.073928, acc = 0.033960\n",
            "valid:: Epoch: 0023 cost = 0.081763, acc = 0.015873\n",
            "train:: Epoch: 0024 cost = 0.073700, acc = 0.033482\n",
            "valid:: Epoch: 0024 cost = 0.082191, acc = 0.018112\n",
            "train:: Epoch: 0025 cost = 0.073510, acc = 0.033923\n",
            "valid:: Epoch: 0025 cost = 0.082253, acc = 0.017705\n",
            "train:: Epoch: 0026 cost = 0.073301, acc = 0.035445\n",
            "valid:: Epoch: 0026 cost = 0.082065, acc = 0.016178\n",
            "train:: Epoch: 0027 cost = 0.073076, acc = 0.035163\n",
            "valid:: Epoch: 0027 cost = 0.082315, acc = 0.016789\n",
            "train:: Epoch: 0028 cost = 0.072873, acc = 0.035052\n",
            "valid:: Epoch: 0028 cost = 0.082418, acc = 0.019434\n",
            "train:: Epoch: 0029 cost = 0.072638, acc = 0.035433\n",
            "valid:: Epoch: 0029 cost = 0.082743, acc = 0.015975\n",
            "train:: Epoch: 0030 cost = 0.072445, acc = 0.036917\n",
            "valid:: Epoch: 0030 cost = 0.082855, acc = 0.017705\n",
            "train:: Epoch: 0031 cost = 0.072213, acc = 0.036083\n",
            "valid:: Epoch: 0031 cost = 0.082990, acc = 0.015466\n",
            "train:: Epoch: 0032 cost = 0.072049, acc = 0.036120\n",
            "valid:: Epoch: 0032 cost = 0.082953, acc = 0.017501\n",
            "train:: Epoch: 0033 cost = 0.071790, acc = 0.036929\n",
            "valid:: Epoch: 0033 cost = 0.083026, acc = 0.015771\n",
            "train:: Epoch: 0034 cost = 0.071635, acc = 0.037543\n",
            "valid:: Epoch: 0034 cost = 0.083353, acc = 0.015670\n",
            "train:: Epoch: 0035 cost = 0.071350, acc = 0.036856\n",
            "valid:: Epoch: 0035 cost = 0.083687, acc = 0.015364\n",
            "train:: Epoch: 0036 cost = 0.071143, acc = 0.037825\n",
            "valid:: Epoch: 0036 cost = 0.083532, acc = 0.016891\n",
            "train:: Epoch: 0037 cost = 0.070985, acc = 0.038770\n",
            "valid:: Epoch: 0037 cost = 0.083732, acc = 0.018213\n",
            "train:: Epoch: 0038 cost = 0.070785, acc = 0.038046\n",
            "valid:: Epoch: 0038 cost = 0.084026, acc = 0.015975\n",
            "train:: Epoch: 0039 cost = 0.070519, acc = 0.038892\n",
            "valid:: Epoch: 0039 cost = 0.083995, acc = 0.014550\n",
            "train:: Epoch: 0040 cost = 0.070321, acc = 0.039359\n",
            "valid:: Epoch: 0040 cost = 0.084225, acc = 0.015568\n",
            "train:: Epoch: 0041 cost = 0.070135, acc = 0.039408\n",
            "valid:: Epoch: 0041 cost = 0.084440, acc = 0.016178\n",
            "train:: Epoch: 0042 cost = 0.069919, acc = 0.039506\n",
            "valid:: Epoch: 0042 cost = 0.084370, acc = 0.016077\n",
            "train:: Epoch: 0043 cost = 0.069715, acc = 0.038046\n",
            "valid:: Epoch: 0043 cost = 0.084654, acc = 0.014042\n",
            "train:: Epoch: 0044 cost = 0.069473, acc = 0.038610\n",
            "valid:: Epoch: 0044 cost = 0.084682, acc = 0.015466\n",
            "train:: Epoch: 0045 cost = 0.069291, acc = 0.040082\n",
            "valid:: Epoch: 0045 cost = 0.085121, acc = 0.015263\n",
            "train:: Epoch: 0046 cost = 0.069124, acc = 0.040365\n",
            "valid:: Epoch: 0046 cost = 0.085040, acc = 0.014550\n",
            "train:: Epoch: 0047 cost = 0.068907, acc = 0.040168\n",
            "valid:: Epoch: 0047 cost = 0.085240, acc = 0.013329\n",
            "train:: Epoch: 0048 cost = 0.068691, acc = 0.039444\n",
            "valid:: Epoch: 0048 cost = 0.085457, acc = 0.014347\n",
            "train:: Epoch: 0049 cost = 0.068497, acc = 0.039788\n",
            "valid:: Epoch: 0049 cost = 0.085222, acc = 0.013940\n",
            "train:: Epoch: 0050 cost = 0.068314, acc = 0.040193\n",
            "valid:: Epoch: 0050 cost = 0.085263, acc = 0.014652\n",
            "train:: Epoch: 0051 cost = 0.068039, acc = 0.041788\n",
            "valid:: Epoch: 0051 cost = 0.085717, acc = 0.012414\n",
            "train:: Epoch: 0052 cost = 0.067880, acc = 0.040512\n",
            "valid:: Epoch: 0052 cost = 0.086054, acc = 0.013940\n",
            "train:: Epoch: 0053 cost = 0.067714, acc = 0.041481\n",
            "valid:: Epoch: 0053 cost = 0.085866, acc = 0.012210\n",
            "train:: Epoch: 0054 cost = 0.067517, acc = 0.041223\n",
            "valid:: Epoch: 0054 cost = 0.086145, acc = 0.011803\n",
            "train:: Epoch: 0055 cost = 0.067323, acc = 0.040684\n",
            "valid:: Epoch: 0055 cost = 0.086198, acc = 0.011803\n",
            "train:: Epoch: 0056 cost = 0.067128, acc = 0.041874\n",
            "valid:: Epoch: 0056 cost = 0.086805, acc = 0.014245\n",
            "train:: Epoch: 0057 cost = 0.066964, acc = 0.041800\n",
            "valid:: Epoch: 0057 cost = 0.086723, acc = 0.011701\n",
            "train:: Epoch: 0058 cost = 0.066730, acc = 0.041481\n",
            "valid:: Epoch: 0058 cost = 0.086781, acc = 0.012312\n",
            "train:: Epoch: 0059 cost = 0.066488, acc = 0.042377\n",
            "valid:: Epoch: 0059 cost = 0.086566, acc = 0.011905\n",
            "train:: Epoch: 0060 cost = 0.066327, acc = 0.041236\n",
            "valid:: Epoch: 0060 cost = 0.086938, acc = 0.012922\n",
            "train:: Epoch: 0061 cost = 0.066135, acc = 0.041481\n",
            "valid:: Epoch: 0061 cost = 0.087213, acc = 0.011701\n",
            "train:: Epoch: 0062 cost = 0.066004, acc = 0.040671\n",
            "valid:: Epoch: 0062 cost = 0.086973, acc = 0.010887\n",
            "train:: Epoch: 0063 cost = 0.065810, acc = 0.041984\n",
            "valid:: Epoch: 0063 cost = 0.087064, acc = 0.011294\n",
            "train:: Epoch: 0064 cost = 0.065632, acc = 0.041113\n",
            "valid:: Epoch: 0064 cost = 0.087024, acc = 0.011294\n",
            "train:: Epoch: 0065 cost = 0.065440, acc = 0.041702\n",
            "valid:: Epoch: 0065 cost = 0.087528, acc = 0.012719\n",
            "train:: Epoch: 0066 cost = 0.065249, acc = 0.042806\n",
            "valid:: Epoch: 0066 cost = 0.087667, acc = 0.012515\n",
            "train:: Epoch: 0067 cost = 0.065142, acc = 0.042401\n",
            "valid:: Epoch: 0067 cost = 0.087668, acc = 0.012007\n",
            "train:: Epoch: 0068 cost = 0.064943, acc = 0.041604\n",
            "valid:: Epoch: 0068 cost = 0.087368, acc = 0.010786\n",
            "train:: Epoch: 0069 cost = 0.064725, acc = 0.043199\n",
            "valid:: Epoch: 0069 cost = 0.087979, acc = 0.010989\n",
            "train:: Epoch: 0070 cost = 0.064581, acc = 0.042058\n",
            "valid:: Epoch: 0070 cost = 0.088080, acc = 0.012210\n",
            "train:: Epoch: 0071 cost = 0.064406, acc = 0.042696\n",
            "valid:: Epoch: 0071 cost = 0.088006, acc = 0.011396\n",
            "train:: Epoch: 0072 cost = 0.064290, acc = 0.042696\n",
            "valid:: Epoch: 0072 cost = 0.088117, acc = 0.010989\n",
            "train:: Epoch: 0073 cost = 0.064096, acc = 0.043800\n",
            "valid:: Epoch: 0073 cost = 0.088480, acc = 0.010175\n",
            "train:: Epoch: 0074 cost = 0.063889, acc = 0.043162\n",
            "valid:: Epoch: 0074 cost = 0.088283, acc = 0.011193\n",
            "train:: Epoch: 0075 cost = 0.063840, acc = 0.042401\n",
            "valid:: Epoch: 0075 cost = 0.088330, acc = 0.010989\n",
            "train:: Epoch: 0076 cost = 0.063621, acc = 0.043886\n",
            "valid:: Epoch: 0076 cost = 0.088876, acc = 0.010073\n",
            "train:: Epoch: 0077 cost = 0.063477, acc = 0.042978\n",
            "valid:: Epoch: 0077 cost = 0.088833, acc = 0.010277\n",
            "train:: Epoch: 0078 cost = 0.063303, acc = 0.043555\n",
            "valid:: Epoch: 0078 cost = 0.088496, acc = 0.009972\n",
            "train:: Epoch: 0079 cost = 0.063126, acc = 0.043824\n",
            "valid:: Epoch: 0079 cost = 0.088656, acc = 0.009768\n",
            "train:: Epoch: 0080 cost = 0.062957, acc = 0.043763\n",
            "valid:: Epoch: 0080 cost = 0.088897, acc = 0.009666\n",
            "train:: Epoch: 0081 cost = 0.062857, acc = 0.043690\n",
            "valid:: Epoch: 0081 cost = 0.088817, acc = 0.010786\n",
            "train:: Epoch: 0082 cost = 0.062662, acc = 0.043285\n",
            "valid:: Epoch: 0082 cost = 0.089020, acc = 0.010379\n",
            "train:: Epoch: 0083 cost = 0.062469, acc = 0.044107\n",
            "valid:: Epoch: 0083 cost = 0.089633, acc = 0.010175\n",
            "train:: Epoch: 0084 cost = 0.062414, acc = 0.044340\n",
            "valid:: Epoch: 0084 cost = 0.089347, acc = 0.009870\n",
            "train:: Epoch: 0085 cost = 0.062270, acc = 0.044021\n",
            "valid:: Epoch: 0085 cost = 0.089068, acc = 0.010175\n",
            "train:: Epoch: 0086 cost = 0.062053, acc = 0.044769\n",
            "valid:: Epoch: 0086 cost = 0.089629, acc = 0.008751\n",
            "train:: Epoch: 0087 cost = 0.061939, acc = 0.044597\n",
            "valid:: Epoch: 0087 cost = 0.089941, acc = 0.009259\n",
            "train:: Epoch: 0088 cost = 0.061797, acc = 0.044781\n",
            "valid:: Epoch: 0088 cost = 0.090159, acc = 0.009870\n",
            "train:: Epoch: 0089 cost = 0.061682, acc = 0.043763\n",
            "valid:: Epoch: 0089 cost = 0.089776, acc = 0.009666\n",
            "train:: Epoch: 0090 cost = 0.061539, acc = 0.044671\n",
            "valid:: Epoch: 0090 cost = 0.089842, acc = 0.009361\n",
            "train:: Epoch: 0091 cost = 0.061364, acc = 0.044548\n",
            "valid:: Epoch: 0091 cost = 0.089855, acc = 0.007733\n",
            "train:: Epoch: 0092 cost = 0.061210, acc = 0.044659\n",
            "valid:: Epoch: 0092 cost = 0.089773, acc = 0.009768\n",
            "train:: Epoch: 0093 cost = 0.061072, acc = 0.044536\n",
            "valid:: Epoch: 0093 cost = 0.090024, acc = 0.007937\n",
            "train:: Epoch: 0094 cost = 0.060912, acc = 0.045579\n",
            "valid:: Epoch: 0094 cost = 0.090582, acc = 0.009666\n",
            "train:: Epoch: 0095 cost = 0.060885, acc = 0.044671\n",
            "valid:: Epoch: 0095 cost = 0.090201, acc = 0.010786\n",
            "train:: Epoch: 0096 cost = 0.060731, acc = 0.045358\n",
            "valid:: Epoch: 0096 cost = 0.090722, acc = 0.010684\n",
            "train:: Epoch: 0097 cost = 0.060562, acc = 0.044892\n",
            "valid:: Epoch: 0097 cost = 0.090731, acc = 0.009565\n",
            "train:: Epoch: 0098 cost = 0.060423, acc = 0.045947\n",
            "valid:: Epoch: 0098 cost = 0.090701, acc = 0.009666\n",
            "train:: Epoch: 0099 cost = 0.060300, acc = 0.046806\n",
            "valid:: Epoch: 0099 cost = 0.090505, acc = 0.007530\n",
            "train:: Epoch: 0100 cost = 0.060127, acc = 0.046241\n",
            "valid:: Epoch: 0100 cost = 0.090698, acc = 0.007835\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZFVcZ0oTy8h"
      },
      "source": [
        "# Should match both the start index and the end index\n",
        "# Random :: 1/256 * 1/256 = 0.0000152587890625 Accuracy\n",
        "\n",
        "# device :  cuda\n",
        "# # of vocab : 86580\n",
        "# batch_size :  128\n",
        "# max_length :  255\n",
        "# embedding_dim :  128\n",
        "# hidden_dim :  256\n",
        "# n_layers :  2\n",
        "# bidirectional : True\n",
        "# learning_rate :  0.001\n",
        "\n",
        "# train:: Epoch: 0001 cost = 0.079758, acc = 0.004233\n",
        "# valid:: Epoch: 0001 cost = 0.079524, acc = 0.007123\n",
        "# train:: Epoch: 0002 cost = 0.079234, acc = 0.010294\n",
        "# valid:: Epoch: 0002 cost = 0.079435, acc = 0.010786\n",
        "# train:: Epoch: 0003 cost = 0.079000, acc = 0.014048\n",
        "# valid:: Epoch: 0003 cost = 0.079326, acc = 0.014652\n",
        "# train:: Epoch: 0004 cost = 0.078740, acc = 0.016686\n",
        "# valid:: Epoch: 0004 cost = 0.079321, acc = 0.015263\n",
        "# train:: Epoch: 0005 cost = 0.078444, acc = 0.018661\n",
        "# valid:: Epoch: 0005 cost = 0.079526, acc = 0.015975\n",
        "# train:: Epoch: 0006 cost = 0.078154, acc = 0.020550\n",
        "# valid:: Epoch: 0006 cost = 0.079506, acc = 0.016992\n",
        "# train:: Epoch: 0007 cost = 0.077840, acc = 0.021728\n",
        "# valid:: Epoch: 0007 cost = 0.079699, acc = 0.018519\n",
        "# train:: Epoch: 0008 cost = 0.077550, acc = 0.023434\n",
        "# valid:: Epoch: 0008 cost = 0.079824, acc = 0.019129\n",
        "# train:: Epoch: 0009 cost = 0.077251, acc = 0.024611\n",
        "# valid:: Epoch: 0009 cost = 0.079951, acc = 0.018315\n",
        "# train:: Epoch: 0010 cost = 0.076993, acc = 0.024722\n",
        "# valid:: Epoch: 0010 cost = 0.080069, acc = 0.019333 -> max valid acc ~1/50\n",
        "# train:: Epoch: 0011 cost = 0.076738, acc = 0.026550\n",
        "# valid:: Epoch: 0011 cost = 0.080116, acc = 0.018620"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr15BA5QKqTd"
      },
      "source": [
        "**Problem 3.2** *(10 points)*  Now let's resolve the second issue, by simply concatenating the two inputs into one sequence. The simplest way would be to append the the question at the start *OR* the end of the context. If you put it at the start, you will need to shift the start and the end positions of the answer accordingly. If you put it at the end, it will be necesary to use bidirectional LSTM for the context to be aware of what is ahead (though it is recommended to use bidirectional LSTM even if the question is appended at the start). Whichever you choose, carry it out and report the accuracy. How does it differ from 3.1?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_nAqQFEZ55R"
      },
      "source": [
        "# Put the question sentence before the context sentence (for Prob 3.2)\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "from torchtext.legacy.data import BucketIterator\n",
        "\n",
        "\n",
        "class SQuAD2Dataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    Defines a dataset for squad1.0. \n",
        "    Put the question sentence before the context sentence (for Prob 3.2)\n",
        "    \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return data.interleave_keys(len(ex.context_question))\n",
        "\n",
        "    def __init__(self, data_list, fields, max_length=None, **kwargs):\n",
        "        if not isinstance(fields[0], (tuple, list)):\n",
        "        fields = [('context_question', fields[0]), \n",
        "                  ('answer_start', fields[1]), \n",
        "                  ('answer_end', fields[2])\n",
        "                  ]\n",
        "\n",
        "        examples = []\n",
        "        nonalpha_list = find_nonalpha_list(data_list)\n",
        "        for example in data_list:\n",
        "        out = preprocess(example, nonalpha_list)\n",
        "        # use data if the answer exists\n",
        "        if max_length and max_length < max(len(out['context']), len(out['question'])):\n",
        "            continue\n",
        "        if 'answers' in out.keys():\n",
        "            examples.append(data.Example.fromlist([out['context']+out['question'], \n",
        "                                                   out['answers'][0]['start'], \n",
        "                                                   out['answers'][0]['end']], \n",
        "                                                  fields))\n",
        "\n",
        "        super(SQuAD2Dataset, self).__init__(examples, fields, **kwargs)\n",
        "\n",
        "\n",
        "class SQuAD2Dataloader():\n",
        "    \"\"\"\n",
        "    Make the dataloader for SQuAD 1.0\n",
        "    \"\"\"\n",
        "    def __init__(self, train_data=None, valid_data=None, batch_size=64, device='cpu', \n",
        "                    max_length=255, min_freq=2, fix_length=None,\n",
        "                    use_bos=True, use_eos=True, shuffle=True\n",
        "                ):\n",
        "\n",
        "        super(SQuAD2Dataloader, self).__init__()\n",
        "\n",
        "        self.text = data.Field(sequential=True, use_vocab=True, batch_first=True, \n",
        "                               include_lengths=True, fix_length=fix_length, \n",
        "                               init_token='<BOS>' if use_bos else None, \n",
        "                               eos_token='<EOS>' if use_eos else None\n",
        "                               )\n",
        "        # self.context = data.Field(sequential=True, use_vocab=True, batch_first=True, \n",
        "        #                        include_lengths=True, fix_length=fix_length, \n",
        "        #                        init_token='<BOS>' if use_bos else None, \n",
        "        #                        eos_token='<EOS>' if use_eos else None\n",
        "        #                       )\n",
        "        # self.question = data.Field(sequential=True, use_vocab=True, batch_first=True, \n",
        "        #                            include_lengths=True, fix_length=fix_length, \n",
        "        #                            init_token='<BOS>' if use_bos else None, \n",
        "        #                            eos_token='<EOS>' if use_eos else None\n",
        "        #                           )\n",
        "        self.answer_start = data.Field(sequential = False, use_vocab = False)\n",
        "        self.answer_end = data.Field(sequential = False, use_vocab = False)\n",
        "        \n",
        "        train = SQuAD2Dataset(data_list=train_data, \n",
        "                              fields = [('context_question', self.text),\n",
        "                                        ('answer_start', self.answer_start),\n",
        "                                        ('answer_end', self.answer_end)\n",
        "                                        ], \n",
        "                              max_length = max_length\n",
        "                              )\n",
        "        valid = SQuAD2Dataset(data_list=valid_data, \n",
        "                              fields = [('context_question', self.text),\n",
        "                                        ('answer_start', self.answer_start),\n",
        "                                        ('answer_end', self.answer_end)\n",
        "                                        ], \n",
        "                              max_length = max_length\n",
        "                              )\n",
        "        \n",
        "        self.train_iter = data.BucketIterator(train, batch_size=batch_size,\n",
        "                                              device=device,\n",
        "                                              shuffle=shuffle,\n",
        "                                              sort_key=lambda x: len(x.context_question), \n",
        "                                              sort_within_batch = True\n",
        "                                              )\n",
        "        self.valid_iter = data.BucketIterator(valid, batch_size=batch_size,\n",
        "                                              device=device,\n",
        "                                              shuffle=shuffle,\n",
        "                                              sort_key=lambda x: len(x.context_question), \n",
        "                                              sort_within_batch = True\n",
        "                                              )\n",
        "        \n",
        "        self.text.build_vocab(train)\n",
        "        # self.context.build_vocab(train)\n",
        "        # self.question.build_vocab(train)\n",
        "\n",
        "\n",
        "# train_data, test_data = torchtext.datasets.SQuAD1(root='.data', split=('train', 'dev'))\n",
        "\n",
        "# TEXT = data.Field(init_token='<SOS>', eos_token='<EOS>', lower=True)\n",
        "# LABEL = data.LabelField(dtype = torch.long)\n",
        "\n",
        "# train_data, test_data = data.TabularDataset.splits(\n",
        "#   path='glue_data/SST-2', train='train.tsv', test='dev.tsv', format='tsv',\n",
        "#   fields=[('text', TEXT), ('label', LABEL)], skip_header=True\n",
        "# )\n",
        "\n",
        "train_dataset = squad_dataset['train']\n",
        "valid_dataset = squad_dataset['validation']\n",
        "\n",
        "print('Put the question sentence before the context sentence (for Prob 3.2)')\n",
        "print('# of train data : {}'.format(len(train_dataset)))\n",
        "print('# of vaild data : {}'.format(len(valid_dataset)))\n",
        "\n",
        "batch_size = 128\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "max_length = 255\n",
        "min_freq = 2\n",
        "print(\"device : \", device)\n",
        "\n",
        "loader = SQuAD2Dataloader(train_dataset, valid_dataset, batch_size=batch_size, \n",
        "                          device=device, max_length=max_length, min_freq=min_freq)\n",
        "print('\\nFinish making the dataloader')\n",
        "print(\"batch_size : \", batch_size)\n",
        "print(\"max_length : \", max_length)\n",
        "print('# of used train data ~ {}'.format((len(loader.train_iter)) * batch_size))\n",
        "print('# of used vaild data ~ {}'.format((len(loader.valid_iter)) * batch_size))\n",
        "\n",
        "vocab = loader.text.vocab\n",
        "print('# of vocab : {}'.format(len(vocab)))\n",
        "\n",
        "# # of train data : 87599\n",
        "# # of vaild data : 10570\n",
        "# device :  cuda\n",
        "\n",
        "# Finish making the dataloader\n",
        "# batch_size :  128\n",
        "# max_length :  255\n",
        "# # of used train data ~ 81536\n",
        "# # of used vaild data ~ 9856\n",
        "# # of vocab : 86580"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXpHPdDLGdd0"
      },
      "source": [
        "**Answer 3.2**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGstR1-CGfr6"
      },
      "source": [
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class ClassificationLSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, n_layers, n_label, emb_dropout, rnn_dropout, bidirectional, enable_layer_norm, device):\n",
        "        super(ClassificationLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, \n",
        "                            hidden_size=hidden_dim, \n",
        "                            num_layers=n_layers, \n",
        "                            dropout=rnn_dropout, \n",
        "                            bidirectional=bidirectional)\n",
        "      \n",
        "        n_direction = 2 if bidirectional else 1\n",
        "        self.fc_start = nn.Linear(hidden_dim*n_direction, n_label, bias=True)\n",
        "        self.fc_end = nn.Linear(hidden_dim*n_direction, n_label, bias=True)\n",
        "\n",
        "        # Layer_normalization\n",
        "        if enable_layer_norm:\n",
        "            self.enable_layer_norm = enable_layer_norm\n",
        "            self.emb_layer_norm = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "        self.fc_dropout = nn.Dropout(rnn_dropout)\n",
        "        self.bidirectional = bidirectional\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, input_tensor, src_seq_lens):\n",
        "        emb = self.embedding(input_tensor) # emb.shape = batch * len * hidden\n",
        "\n",
        "        # Layer_normalization\n",
        "        if self.enable_layer_norm:\n",
        "            emb = self.emb_layer_norm(emb)\n",
        "\n",
        "        emb = self.emb_dropout(emb)\n",
        "        emb = emb.transpose(0, 1) # emb.shape = len * batch * hidden\n",
        "\n",
        "        # n_direction = 2 if bidirectional else 1\n",
        "        # hidden = torch.zeros(n_layers*n_direction, context.shape[0], hidden_dim, requires_grad=True).to(self.device)\n",
        "        # cell = torch.zeros(n_layers*n_direction, context.shape[0], hidden_dim, requires_grad=True).to(self.device)\n",
        "\n",
        "        # nn.LSTM\n",
        "        packed = pack_padded_sequence(emb, src_seq_lens.tolist(), batch_first=False)\n",
        "        outs, (hidden, cell) = self.lstm(packed)\n",
        "        outs, out_lens = pad_packed_sequence(outs, batch_first=False)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            hidden = torch.stack([hidden[-2], hidden[-1]], dim=0)\n",
        "        else:\n",
        "            hidden = hidden[-1].unsqueeze(dim=0)\n",
        "        hidden = hidden.transpose(0, 1)\n",
        "        hidden = hidden.contiguous().view(hidden.shape[0], -1)\n",
        "\n",
        "        hidden = self.fc_dropout(hidden)\n",
        "        logits_start = self.fc_start(hidden)\n",
        "        logits_end = self.fc_end(hidden)\n",
        "        return (logits_start, logits_end)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device : \", device)\n",
        "\n",
        "# Vocabulary\n",
        "vocab = loader.text.vocab\n",
        "print('# of vocab : {}'.format(len(vocab)))\n",
        "\n",
        "# Construct the LSTM Model\n",
        "embedding_dim = 128 # usually bigger, e.g. 128\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "n_label = max_length\n",
        "emb_dropout = 0.0\n",
        "rnn_dropout = 0.5\n",
        "bidirectional = True\n",
        "enable_layer_norm = True\n",
        "rnnmodel = ClassificationLSTMModel(embedding_dim, hidden_dim, n_layers, n_label, emb_dropout, rnn_dropout, bidirectional, enable_layer_norm, device).to(device)\n",
        "\n",
        "print(\"batch_size : \", batch_size)\n",
        "print(\"max_length : \", max_length)\n",
        "print(\"embedding_dim : \", embedding_dim)\n",
        "print(\"hidden_dim : \", hidden_dim)\n",
        "print(\"n_layers : \", n_layers)\n",
        "print(\"emb_dropout : \", emb_dropout)\n",
        "print(\"rnn_dropout_and_fc_dropout : \", rnn_dropout)\n",
        "if bidirectional:\n",
        "    print(\"bidirectional : True\")\n",
        "else:\n",
        "    print(\"bidirectional : False\")\n",
        "if enable_layer_norm:\n",
        "    print(\"enable_layer_norm : True\")\n",
        "else:\n",
        "    print(\"enable_layer_norm : False\")\n",
        "\n",
        "# Construct the data loader\n",
        "train_iter = loader.train_iter\n",
        "valid_iter = loader.valid_iter\n",
        "\n",
        "# Training\n",
        "learning_rate = 1e-3\n",
        "print(\"learning_rate : \", learning_rate)\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(rnnmodel.parameters(), lr=1e-1)\n",
        "optimizer = torch.optim.Adam(rnnmodel.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 100\n",
        "max_norm = 5\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0.0\n",
        "    train_data_num = 0\n",
        "    for i, train_batch in enumerate(train_iter):\n",
        "        con_que, con_que_length = train_batch.context_question # put question at the end of the context\n",
        "        answer_start = train_batch.answer_start\n",
        "        answer_end = train_batch.answer_end\n",
        "\n",
        "        logits_start, logits_end = rnnmodel(con_que, con_que_length)\n",
        "\n",
        "        optimizer.zero_grad() # reset process\n",
        "        loss = cel(logits_start, answer_start) + cel(logits_end, answer_end) # Loss, a.k.a L\n",
        "        loss.backward() # compute gradients\n",
        "        # print(torch.norm(rnnmodel.lstm.weight_hh_l0.grad), loss.item())\n",
        "        torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), max_norm) # gradent clipping\n",
        "        optimizer.step() # update parameters\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, train_start_preds = torch.max(logits_start, 1)\n",
        "        _, train_end_preds = torch.max(logits_end, 1)\n",
        "        train_accuracy += ((train_start_preds == answer_start) * (train_end_preds == answer_end)).sum().float()\n",
        "\n",
        "        train_data_num += con_que.shape[0]\n",
        "\n",
        "    print('train:: Epoch:', '%04d' % (epoch + 1), \n",
        "          'cost =', '{:.6f},'.format(train_loss / train_data_num), \n",
        "          'acc =', '{:.6f}'.format(train_accuracy / train_data_num))\n",
        "    \n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0\n",
        "            valid_accuracy = 0.0\n",
        "            valid_data_num = 0\n",
        "            for i, valid_batch in enumerate(valid_iter):\n",
        "                con_que, con_que_length = valid_batch.context_question # put question at the end of the context\n",
        "                answer_start = valid_batch.answer_start\n",
        "                answer_end = valid_batch.answer_end\n",
        "\n",
        "                logits_start, logits_end = rnnmodel(con_que, con_que_length)\n",
        "\n",
        "                loss = cel(logits_start, answer_start) + cel(logits_end, answer_end) # Loss, a.k.a L\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                _, valid_start_preds = torch.max(logits_start, 1)\n",
        "                _, valid_end_preds = torch.max(logits_end, 1)\n",
        "                valid_accuracy += ((valid_start_preds == answer_start) * (valid_end_preds == answer_end)).sum().float()\n",
        "\n",
        "                valid_data_num += con_que.shape[0]\n",
        "                \n",
        "            print('valid:: Epoch:', '%04d' % (epoch + 1), \n",
        "                  'cost =', '{:.6f},'.format(valid_loss / valid_data_num), \n",
        "                  'acc =', '{:.6f}'.format(valid_accuracy / valid_data_num))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEjTZSqGuAdy"
      },
      "source": [
        "device :  cuda\n",
        "# of vocab : 86580\n",
        "batch_size :  128\n",
        "max_length :  255\n",
        "embedding_dim :  256\n",
        "hidden_dim :  512\n",
        "n_layers :  2\n",
        "bidirectional : True\n",
        "learning_rate :  0.001\n",
        "13%\n",
        "13/100 [33:49<3:46:29, 156.21s/it]\n",
        "train:: Epoch: 0001 cost = 0.079619, acc = 0.006944\n",
        "valid:: Epoch: 0001 cost = 0.079696, acc = 0.012922\n",
        "train:: Epoch: 0002 cost = 0.079165, acc = 0.013582\n",
        "valid:: Epoch: 0002 cost = 0.079346, acc = 0.015466\n",
        "train:: Epoch: 0003 cost = 0.078792, acc = 0.017164\n",
        "valid:: Epoch: 0003 cost = 0.079322, acc = 0.016280\n",
        "train:: Epoch: 0004 cost = 0.078353, acc = 0.020182\n",
        "valid:: Epoch: 0004 cost = 0.079481, acc = 0.017908\n",
        "train:: Epoch: 0005 cost = 0.077817, acc = 0.022685\n",
        "valid:: Epoch: 0005 cost = 0.079363, acc = 0.019638\n",
        "train:: Epoch: 0006 cost = 0.077266, acc = 0.025286\n",
        "valid:: Epoch: 0006 cost = 0.079417, acc = 0.019027\n",
        "train:: Epoch: 0007 cost = 0.076714, acc = 0.026452\n",
        "valid:: Epoch: 0007 cost = 0.079670, acc = 0.018722\n",
        "train:: Epoch: 0008 cost = 0.076170, acc = 0.026881\n",
        "valid:: Epoch: 0008 cost = 0.080020, acc = 0.018112\n",
        "train:: Epoch: 0009 cost = 0.075587, acc = 0.029507\n",
        "valid:: Epoch: 0009 cost = 0.080270, acc = 0.020350\n",
        "train:: Epoch: 0010 cost = 0.075055, acc = 0.029605\n",
        "valid:: Epoch: 0010 cost = 0.080645, acc = 0.020045\n",
        "train:: Epoch: 0011 cost = 0.074553, acc = 0.031519\n",
        "valid:: Epoch: 0011 cost = 0.080962, acc = 0.017806\n",
        "train:: Epoch: 0012 cost = 0.074054, acc = 0.032329\n",
        "valid:: Epoch: 0012 cost = 0.081124, acc = 0.019129\n",
        "train:: Epoch: 0013 cost = 0.073636, acc = 0.032574\n",
        "valid:: Epoch: 0013 cost = 0.081502, acc = 0.018315"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKk9QKEz4qnN"
      },
      "source": [
        "device :  cuda\n",
        "# of vocab : 86580\n",
        "batch_size :  128\n",
        "max_length :  255\n",
        "embedding_dim :  128\n",
        "hidden_dim :  256\n",
        "n_layers :  2\n",
        "bidirectional : True\n",
        "learning_rate :  0.001\n",
        "23%\n",
        "23/100 [20:52<1:09:54, 54.47s/it]\n",
        "train:: Epoch: 0001 cost = 0.079600, acc = 0.007619\n",
        "valid:: Epoch: 0001 cost = 0.079375, acc = 0.015059\n",
        "train:: Epoch: 0002 cost = 0.078746, acc = 0.017029\n",
        "valid:: Epoch: 0002 cost = 0.079089, acc = 0.017094\n",
        "train:: Epoch: 0003 cost = 0.077435, acc = 0.024035\n",
        "valid:: Epoch: 0003 cost = 0.079096, acc = 0.020452\n",
        "train:: Epoch: 0004 cost = 0.074976, acc = 0.032267\n",
        "valid:: Epoch: 0004 cost = 0.080308, acc = 0.020045\n",
        "train:: Epoch: 0005 cost = 0.070933, acc = 0.041861\n",
        "valid:: Epoch: 0005 cost = 0.082924, acc = 0.015263\n",
        "train:: Epoch: 0006 cost = 0.064731, acc = 0.058449\n",
        "valid:: Epoch: 0006 cost = 0.087871, acc = 0.012210\n",
        "train:: Epoch: 0007 cost = 0.056475, acc = 0.090802\n",
        "valid:: Epoch: 0007 cost = 0.094999, acc = 0.008140\n",
        "train:: Epoch: 0008 cost = 0.047037, acc = 0.147779\n",
        "valid:: Epoch: 0008 cost = 0.104818, acc = 0.007326\n",
        "train:: Epoch: 0009 cost = 0.037530, acc = 0.239709\n",
        "valid:: Epoch: 0009 cost = 0.117320, acc = 0.005698\n",
        "train:: Epoch: 0010 cost = 0.028805, acc = 0.358301\n",
        "valid:: Epoch: 0010 cost = 0.130119, acc = 0.005393\n",
        "train:: Epoch: 0011 cost = 0.021250, acc = 0.492866\n",
        "valid:: Epoch: 0011 cost = 0.140989, acc = 0.004375\n",
        "train:: Epoch: 0012 cost = 0.015138, acc = 0.627100\n",
        "valid:: Epoch: 0012 cost = 0.153281, acc = 0.005698\n",
        "train:: Epoch: 0013 cost = 0.010398, acc = 0.749727\n",
        "valid:: Epoch: 0013 cost = 0.163834, acc = 0.003867\n",
        "train:: Epoch: 0014 cost = 0.007055, acc = 0.842112\n",
        "valid:: Epoch: 0014 cost = 0.173189, acc = 0.004375\n",
        "train:: Epoch: 0015 cost = 0.004955, acc = 0.898868\n",
        "valid:: Epoch: 0015 cost = 0.181411, acc = 0.003663\n",
        "train:: Epoch: 0016 cost = 0.003635, acc = 0.932202\n",
        "valid:: Epoch: 0016 cost = 0.189040, acc = 0.003968\n",
        "train:: Epoch: 0017 cost = 0.003136, acc = 0.939085\n",
        "valid:: Epoch: 0017 cost = 0.194765, acc = 0.004172\n",
        "train:: Epoch: 0018 cost = 0.003493, acc = 0.920534\n",
        "valid:: Epoch: 0018 cost = 0.198848, acc = 0.003765\n",
        "train:: Epoch: 0019 cost = 0.003538, acc = 0.912314\n",
        "valid:: Epoch: 0019 cost = 0.204216, acc = 0.003663\n",
        "train:: Epoch: 0020 cost = 0.002579, acc = 0.941907\n",
        "valid:: Epoch: 0020 cost = 0.209405, acc = 0.003460\n",
        "train:: Epoch: 0021 cost = 0.001781, acc = 0.964163\n",
        "valid:: Epoch: 0021 cost = 0.214543, acc = 0.004274\n",
        "train:: Epoch: 0022 cost = 0.001338, acc = 0.976125\n",
        "valid:: Epoch: 0022 cost = 0.218680, acc = 0.004172\n",
        "train:: Epoch: 0023 cost = 0.001490, acc = 0.968776\n",
        "valid:: Epoch: 0023 cost = 0.221427, acc = 0.004375"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LggHWu2hjPrc"
      },
      "source": [
        "device :  cuda\n",
        "# of vocab : 86580\n",
        "batch_size :  128\n",
        "max_length :  255\n",
        "embedding_dim :  128\n",
        "hidden_dim :  256\n",
        "n_layers :  2\n",
        "bidirectional : True\n",
        "learning_rate :  0.001\n",
        "11%\n",
        "11/100 [13:27<1:48:54, 73.42s/it]\n",
        "train:: Epoch: 0001 cost = 0.079707, acc = 0.005570\n",
        "valid:: Epoch: 0001 cost = 0.079532, acc = 0.007835\n",
        "train:: Epoch: 0002 cost = 0.079195, acc = 0.010968\n",
        "valid:: Epoch: 0002 cost = 0.079389, acc = 0.014042\n",
        "train:: Epoch: 0003 cost = 0.078919, acc = 0.014490\n",
        "valid:: Epoch: 0003 cost = 0.079269, acc = 0.014449\n",
        "train:: Epoch: 0004 cost = 0.078588, acc = 0.016992\n",
        "valid:: Epoch: 0004 cost = 0.079284, acc = 0.017705\n",
        "train:: Epoch: 0005 cost = 0.078201, acc = 0.019238\n",
        "valid:: Epoch: 0005 cost = 0.079297, acc = 0.016585\n",
        "train:: Epoch: 0006 cost = 0.077760, acc = 0.020992\n",
        "valid:: Epoch: 0006 cost = 0.079323, acc = 0.017806\n",
        "train:: Epoch: 0007 cost = 0.077337, acc = 0.022182\n",
        "valid:: Epoch: 0007 cost = 0.079581, acc = 0.016077\n",
        "train:: Epoch: 0008 cost = 0.076933, acc = 0.023213\n",
        "valid:: Epoch: 0008 cost = 0.079590, acc = 0.019333\n",
        "train:: Epoch: 0009 cost = 0.076559, acc = 0.024857\n",
        "valid:: Epoch: 0009 cost = 0.079766, acc = 0.018824\n",
        "train:: Epoch: 0010 cost = 0.076169, acc = 0.025556\n",
        "valid:: Epoch: 0010 cost = 0.079945, acc = 0.018315\n",
        "train:: Epoch: 0011 cost = 0.075802, acc = 0.026734\n",
        "valid:: Epoch: 0011 cost = 0.080164, acc = 0.017806"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76NH5MK7L1OG"
      },
      "source": [
        "## 4. LSTM + Attention for SQuAD\n",
        "\n",
        "**Problem 4.1** *(20 points)* Here, we will be appending an attention layer on top of LSTM outputs. We will use a single-head attention sublayer from Transformer. That is, you will implement \n",
        "$$ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d}}\\right)V,$$\n",
        "where $Q, K, V$ is obtained by the linear transformation of the hidden states of the LSTM outputs $H$, i.e. $Q = HW^Q, K=HW^K, V=HW^V$ ($W^Q, W^K, W^V \\in \\mathbb{R}^{d \\times d}$ are trainable weights). Note that the output of $\\text{Attention}$ layer has the same dimension as $H$, so you can directly append your token classification layer on top of it. Report the accuracy and compare it with 3.2.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoL0X9C2Gi0v"
      },
      "source": [
        "**Answer 4.1**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAvP_sFiGkYj"
      },
      "source": [
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class AttentionLSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, n_layers, n_label, emb_dropout, rnn_dropout, bidirectional, enable_layer_norm, device):\n",
        "        super(AttentionLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab), embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, \n",
        "                            hidden_size=hidden_dim, \n",
        "                            num_layers=n_layers, \n",
        "                            dropout=rnn_dropout, \n",
        "                            bidirectional=bidirectional)\n",
        "      \n",
        "        n_direction = 2 if bidirectional else 1\n",
        "        self.fc_start = nn.Linear(hidden_dim*n_direction, n_label, bias=True)\n",
        "        self.fc_end = nn.Linear(hidden_dim*n_direction, n_label, bias=True)\n",
        "\n",
        "        # Layer_normalization\n",
        "        if enable_layer_norm:\n",
        "            self.enable_layer_norm = enable_layer_norm\n",
        "            self.emb_layer_norm = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "        self.fc_dropout = nn.Dropout(rnn_dropout)\n",
        "        self.bidirectional = bidirectional\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, input_tensor, src_seq_lens):\n",
        "        emb = self.embedding(input_tensor) # emb.shape = batch * len * hidden\n",
        "\n",
        "        # Layer_normalization\n",
        "        if self.enable_layer_norm:\n",
        "            emb = self.emb_layer_norm(emb)\n",
        "\n",
        "        emb = self.emb_dropout(emb)\n",
        "        emb = emb.transpose(0, 1) # emb.shape = len * batch * hidden\n",
        "\n",
        "        # n_direction = 2 if bidirectional else 1\n",
        "        # hidden = torch.zeros(n_layers*n_direction, context.shape[0], hidden_dim, requires_grad=True).to(self.device)\n",
        "        # cell = torch.zeros(n_layers*n_direction, context.shape[0], hidden_dim, requires_grad=True).to(self.device)\n",
        "\n",
        "        # nn.LSTM\n",
        "        packed = pack_padded_sequence(emb, src_seq_lens.tolist(), batch_first=False)\n",
        "        outs, (hidden, cell) = self.lstm(packed)\n",
        "        outs, out_lens = pad_packed_sequence(outs, batch_first=False)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            hidden = torch.stack([hidden[-2], hidden[-1]], dim=0)\n",
        "        else:\n",
        "            hidden = hidden[-1].unsqueeze(dim=0)\n",
        "        hidden = hidden.transpose(0, 1)\n",
        "        hidden = hidden.contiguous().view(hidden.shape[0], -1)\n",
        "\n",
        "        hidden = self.fc_dropout(hidden)\n",
        "        logits_start = self.fc_start(hidden)\n",
        "        logits_end = self.fc_end(hidden)\n",
        "        return (logits_start, logits_end)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device : \", device)\n",
        "\n",
        "# Vocabulary\n",
        "vocab = loader.text.vocab\n",
        "print('# of vocab : {}'.format(len(vocab)))\n",
        "\n",
        "# Construct the LSTM Model\n",
        "embedding_dim = 128 # usually bigger, e.g. 128\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "n_label = max_length\n",
        "emb_dropout = 0.0\n",
        "rnn_dropout = 0.5\n",
        "bidirectional = True\n",
        "enable_layer_norm = True\n",
        "rnnmodel = AttentionLSTMModel(embedding_dim, hidden_dim, n_layers, n_label, emb_dropout, rnn_dropout, bidirectional, enable_layer_norm, device).to(device)\n",
        "\n",
        "print(\"batch_size : \", batch_size)\n",
        "print(\"max_length : \", max_length)\n",
        "print(\"embedding_dim : \", embedding_dim)\n",
        "print(\"hidden_dim : \", hidden_dim)\n",
        "print(\"n_layers : \", n_layers)\n",
        "print(\"emb_dropout : \", emb_dropout)\n",
        "print(\"rnn_dropout_and_fc_dropout : \", rnn_dropout)\n",
        "if bidirectional:\n",
        "    print(\"bidirectional : True\")\n",
        "else:\n",
        "    print(\"bidirectional : False\")\n",
        "if enable_layer_norm:\n",
        "    print(\"enable_layer_norm : True\")\n",
        "else:\n",
        "    print(\"enable_layer_norm : False\")\n",
        "\n",
        "# Construct the data loader\n",
        "train_iter = loader.train_iter\n",
        "valid_iter = loader.valid_iter\n",
        "\n",
        "# Training\n",
        "learning_rate = 1e-3\n",
        "print(\"learning_rate : \", learning_rate)\n",
        "\n",
        "cel = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(rnnmodel.parameters(), lr=1e-1)\n",
        "optimizer = torch.optim.Adam(rnnmodel.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 100\n",
        "max_norm = 5\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0.0\n",
        "    train_data_num = 0\n",
        "    for i, train_batch in enumerate(train_iter):\n",
        "        con_que, con_que_length = train_batch.context_question # put question at the end of the context\n",
        "        answer_start = train_batch.answer_start\n",
        "        answer_end = train_batch.answer_end\n",
        "\n",
        "        logits_start, logits_end = rnnmodel(con_que, con_que_length)\n",
        "\n",
        "        optimizer.zero_grad() # reset process\n",
        "        loss = cel(logits_start, answer_start) + cel(logits_end, answer_end) # Loss, a.k.a L\n",
        "        loss.backward() # compute gradients\n",
        "        # print(torch.norm(rnnmodel.lstm.weight_hh_l0.grad), loss.item())\n",
        "        torch.nn.utils.clip_grad_norm_(rnnmodel.parameters(), max_norm) # gradent clipping\n",
        "        optimizer.step() # update parameters\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, train_start_preds = torch.max(logits_start, 1)\n",
        "        _, train_end_preds = torch.max(logits_end, 1)\n",
        "        train_accuracy += ((train_start_preds == answer_start) * (train_end_preds == answer_end)).sum().float()\n",
        "\n",
        "        train_data_num += con_que.shape[0]\n",
        "\n",
        "    print('train:: Epoch:', '%04d' % (epoch + 1), \n",
        "          'cost =', '{:.6f},'.format(train_loss / train_data_num), \n",
        "          'acc =', '{:.6f}'.format(train_accuracy / train_data_num))\n",
        "    \n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        with torch.no_grad():\n",
        "            valid_loss = 0\n",
        "            valid_accuracy = 0.0\n",
        "            valid_data_num = 0\n",
        "            for i, valid_batch in enumerate(valid_iter):\n",
        "                con_que, con_que_length = valid_batch.context_question # put question at the end of the context\n",
        "                answer_start = valid_batch.answer_start\n",
        "                answer_end = valid_batch.answer_end\n",
        "\n",
        "                logits_start, logits_end = rnnmodel(con_que, con_que_length)\n",
        "\n",
        "                loss = cel(logits_start, answer_start) + cel(logits_end, answer_end) # Loss, a.k.a L\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                _, valid_start_preds = torch.max(logits_start, 1)\n",
        "                _, valid_end_preds = torch.max(logits_end, 1)\n",
        "                valid_accuracy += ((valid_start_preds == answer_start) * (valid_end_preds == answer_end)).sum().float()\n",
        "\n",
        "                valid_data_num += con_que.shape[0]\n",
        "                \n",
        "            print('valid:: Epoch:', '%04d' % (epoch + 1), \n",
        "                  'cost =', '{:.6f},'.format(valid_loss / valid_data_num), \n",
        "                  'acc =', '{:.6f}'.format(valid_accuracy / valid_data_num))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT_N1lJqQFY-"
      },
      "source": [
        "**Problem 4.2** *(10 points)* On top of the attention layer, let's add another layer of (bi-directional) LSTM. So this will look like a *sandwich* where the LSTM is bread and the attention is ham. How does it affect the accuracy? Explain why do you think this happens. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yi557rwGlSG"
      },
      "source": [
        "**Answer 4.2**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJv7a2fiGmTe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN6XQLYJRrR6"
      },
      "source": [
        "## 5. Attention is All You Need\n",
        "\n",
        "**Problem 5.1 (bonus)** *(20 points)*  Implement full Transformer encoder to entirely replace LSTMs. You are allowed to copy and paste code from [*Annotated Transformer*](https://nlp.seas.harvard.edu/2018/04/03/attention.html) (but nowhere else). Report the accuracy and explain what seems to happening with attetion-only model compared to LSTM+Attention model(s). \n",
        "\n",
        "**Problem 5.2 (bonus)** *(10 points)* Replace Transformer's sinusoidal position encoding with a fixed-length (of 256) position embedding. That is, you will create a 256-by-$d$ trainable parameter matrix for the position encoding that replaces the variable-length sinusoidal encoding. What is the clear disdvantage of this approach? Report the accuracy and compare it with 5.1. Note that this also has a clear advantage, as we will see in our future lecture on Pretrained Language Model, and more specifically, BERT (Devlin et al., 2018)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zesTXw0GpK2"
      },
      "source": [
        "**Answer 5.1**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_-YXpobIfUP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}